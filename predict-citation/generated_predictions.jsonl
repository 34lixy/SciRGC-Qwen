{"label": "There has also been significant work on #OTHEREFR; #REFR, such that even 3More details about the chunk parser can be found in #OTHEREFR. input urerance speech recognizer hypothesis L I POS tagger , prepro e. ,ngp p II II; chun par er II chunk sequence li II frame representation ", "predict": "The only new knowledge source that we had to build was the subcat dictionary (which was already implemented in the work of #REFR). "}
{"label": "More recently, another encoder?decoder model using an RNN was proposed in #REFR, where the decoder is conditioned on a representation of either a source sentence or a source context.", "predict": "Recently, a similar approach to the proposed RNN Encoder?Decoder was used in a machine translation setting in #REFR."}
{"label": "The idea is similar to Finkler and Neumann #OTHEREFR, though simplified for our purposes; #REFR in his VEX system also uses the method of giving sunple questions to the user (supposedly non-linguist) to learn about word is behaviour, but it is for English and primarily intended for assigning syntax properties rather than morphological.", "predict": "For details see #REFR."}
{"label": "In this section, we test our joint model on PKU and MSRA datesets provided by the Second Segmentation Bake-off #OTHEREFR #REFR.", "predict": "In this paper, we use the same PKU and MSRA datasets as used in the second SIGHAN bakeoff #REFR."}
{"label": "In the context of machine translation, the performance of system generally decreases with increase in the length of the sentence #REFR.", "predict": "#REFR have discussed the impact of the number of verb chunks on sentence complexity."}
{"label": "We perform experiments in two benchmark semantic parsing datasets: GeoQuery #OTHEREFR and ATIS #REFR.", "predict": "We evaluate our approach on two benchmark domains, the ATIS travel domain #REFR and the Freebase domain #OTHEREFR."}
{"label": "We used The Japanese parser KNP #OTHEREFR and The English nl-parser #REFR.", "predict": "The English parser outputs a Penn-style parse tree, and we converted that into a dependency structure using the Charniak parser #REFR."}
{"label": "Different work exploits distributional information in different forms, including context clustering models #OTHEREFR; #REFR and Bayesian Formally, the position feature is the context words with its relative position to the target word. models.", "predict": "Various models are proposed to measure the similarity between word contexts and candidate senses, including probabilistic models #OTHEREFR, graph-based models #REFR, Bayesian models #OTHEREFR."}
{"label": "There exists some work to remove noise from SMS #OTHEREFR #REFR.", "predict": "Several techniques have been proposed for cleaning noisy text #OTHEREFR; #REFR."}
{"label": "Research in summarization #OTHEREFR; #REFR has shown that, in genres with stereotypical structure, important sentences are often located at the beginning or end of paragraphs/documents.", "predict": "The intuition that is captured by the position-based metric is that a textual unit is more likely to be the topic of a text if it is located at the beginning or end of a text #REFR."}
{"label": "#REFR used monolingual recursive autoencoders for sentiment prediction, with or without parse tree information; this was perhaps the first use of a RAAM style approach on a large scale NLP task, albeit monolingual.", "predict": "#REFR used recursive autoencoders to learn representations for multi-word phrases."}
{"label": "The SMR technique works with statistical word classes #REFR instead of words themselves (particularly, we have used 200 classes in all experiments). ", "predict": "In this paper, we will focus on a particular implementation of this general framework, which is based on bilingual clustering #REFR and word ordering graphs #OTHEREFR."}
{"label": "Other metrics were also calculated (e.g. the V-Measure #REFR, and Average Entropy #OTHEREFR), but these results were excluded due to space constraints and the fact that their plots are similar to those shown.", "predict": "We also used V-measure #REFR which is a weighted average of the two metrics above."}
{"label": "We compare our model against a state-of-the-art statistical machine translation #OTHEREFR and an averaged perceptron edit model (PTEM) with identical features #REFR.", "predict": "The SMT system is a state-of-the-art statistical machine translation system #REFR, which achieves the best performance among the three systems."}
{"label": "As shown in [#REFR], a referring expression must communicate enough information to be able to uniquely identify the intended referent in the current discourse context, but avoiding the presence of redundant or otherwise unnecessary modifiers.", "predict": "#REFR show that, in their experiments, the best results were obtained by using a combination of the most similar descriptions for a given object, rather than the best description."}
{"label": "We evaluate our proposed model with the most commonly used metrics for coreference resolution: for the OntoNotes data sets MUC #OTHEREFR, CEAF #REFR and their average F1 as used in the CoNLL 2011 and 2012 shared tasks; for the ACE data sets MUC and B .", "predict": "We evaluate our system using the CEAF score #REFR."}
{"label": "Researchers at New Mexico State University have built an automatic algorithm \\[#REFR\\] for locating and disambiguating enus terms (head nouns) in sense definitions.", "predict": "This hierarchy is constructed from the LDOCE dictionary by using an automatic method #REFR for assigning genus senses to a sense definition."}
{"label": "Such methods can achieve better performance, reaching a tagging accuracy of up to 85% on unknown words for English \\[#REFR; Weischedel et al, 1993\\].", "predict": "These features are described in #REFR\\]."}
{"label": "Experiments on two Chinese treebanks showed that our approach outperformed the baseline system #REFR by 1.31%.", "predict": "We conducted experiments on two Chinese treebanks and showed that our approach improves conversion accuracy by 1.31% over a strong baseline, which is consistent with the result of #REFR."}
{"label": "Most existing works on sentiment summarization focus on predicting the overall rating on an entity #OTHEREFR; #REFR).", "predict": "Most existing summarization systems for product reviews focus on opinion summarization #OTHEREFR; #REFR."}
{"label": "#REFR propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types.", "predict": "#REFR and Miller et al #OTHEREFR use statistical parsing techniques to identify relations between entities."}
{"label": "Some success in this area has been demonstrated via generative models #OTHEREFR, which often benefit from wellchosen priors #REFR or posterior constraints #OTHEREFR.", "predict": "Recent years have seen the development of several generative models for grammar induction, including latent variable models #OTHEREFR, and shared logistic normal priors #REFR."}
{"label": "Much attention has recently been devoted to integer linear programming #OTHEREFR; #REFR, dependency parsing #OTHEREFR, among others.", "predict": "Integer linear programming #OTHEREFR; #REFR."}
{"label": "Our framework proceeds by using the standard procedure of performing word alignment using GIZA++ #OTHEREFR and obtaining phrases from the word alignment using heuristics #REFR and subsequently scoring them.", "predict": "Phrase extraction was performed using the grow-diag-final heuristic #REFR."}
{"label": "Recent years have witnessed burgeoning development of statistical machine translation research, notably phrase-based #REFR and syntax-based approaches #OTHEREFR.", "predict": "In recent years, there has been considerable progress in statistical machine translation #OTHEREFR; #REFR."}
{"label": "Our analysis more fully explains the positive results achieved by #REFR from reranking with prosodic features and suggests that the hypothesis that inserted prosodic punctuation breaks n-gram dependencies only partially explains the negative results of #OTHEREFR.", "predict": "We have also performed an oracle experiment, where we assume that the break indexes are correct, to understand the effect of prosodic information on parsing accuracy. #REFR have also reported improvements using prosodic features for parsing, but our results suggest that using prosodic features for parsing are not as effective as using latent variables for parsing."}
{"label": "We tried to incorporate the binned prosodic information described in the previous subsection in a manner that corresponds as closely as possible to the way that punctuation is represented in this corpus, because previous experiments have shown that punctuation improves parser performance #REFR.", "predict": "In this experiment we used the version of the Switchboard corpus with disfluency tags #REFR and sentence boundaries."}
{"label": "Measures of cross-language relatedness are useful for a large number of applications, including cross-language information retrieval #OTHEREFR, cross-language annotation and resource projections to a second language #REFR.", "predict": "Measuring cross-lingual semantic relatedness is important for many applications, such as cross-language information retrieval #OTHEREFR; #REFR, cross-lingual word sense disambiguation #OTHEREFR."}
{"label": "We distinguish social acts from ?social events? as described in #REFR: social events correspond to types of interactions among people, whereas a social act is associated with a fine-grained social goal and reflected in the specific choices of words and orthographic or prosodic cues at the level of a turn.", "predict": "Social acts are similar to other types of social events that have been studied in the literature #OTHEREFR; #REFR."}
{"label": "We used 600 million Japanese Web pages #OTHEREFR parsed by KNP #REFR as a corpus.", "predict": "We used an unsupervised case frame acquisition method #REFR to obtain templates."}
{"label": "While syntactical constraints have been proven to helpful in identifying good paraphrases #REFR, it is insufficient in our task because it cannot properly filter the candidates for the replacement.", "predict": "Previous work #OTHEREFR; #REFR mainly focuses on paraphrasing by substituting one phrase pair with another phrase pair."}
{"label": "Our approach can be considered a generalization of syntactic approaches to example-based machine translation #OTHEREFR; #REFR.", "predict": "Transfer rules have been widely studied in the literature #OTHEREFR; #REFR."}
{"label": "A general abstract model of incremental processing based on buffers and a processor was developed by #REFR and is illustrated in Figure 2.", "predict": "The Incremental Dialogue System (IDS) model #REFR is a framework for specifying the processing of incremental input in dialogue systems."}
{"label": "We also compare our method against Wang and #REFR?s Naive-Bayes Support Vector Machine (NBSVM), which has achieved state-of-the-art results (or close to it) on many datasets, and find that it performs competitively against NBSVM.", "predict": "The supervised tf-idf outperforms both the traditional tf-idf and the more sophisticated methods of #OTHEREFR and #REFR."}
{"label": "The proposal in this paper is grounded on the heterogeneity property of evaluation measures introduced in #REFR.", "predict": "#REFR define the heterogeneity property as follows:?For any given pair of summaries, there is at least one measure that gives a higher score to one of the summaries than to the other?."}
{"label": "The first task is to answer the closest-opposite questions from the GRE test provided by #REFR4.", "predict": "To evaluate the antonymy detection task, we use the SemEval 2007 question answering task dataset #REFR."}
{"label": "However, there are state-of-the-art unlexicalized parsers #REFR, to which we believe our binarization can be applied.", "predict": "In contrast, our binarization can be applied to the unlexicalized parser #REFR."}
{"label": "Examples of such systems include tutoring systems, intelligent assistants, and spoken translation systems #REFR.", "predict": "Targeted clarifications are especially beneficial in the context of tutoring spoken systems such as ITSPOKE #REFR, where users are asked to produce a short answer to a question."}
{"label": "There has been a substantial body of work on metaphor identification and interpretation #OTHEREFR; #REFR.", "predict": "The automatic identification of metaphors has been studied extensively by the research community #OTHEREFR; #REFR."}
{"label": "For a fair comparison, all aligners are trained on the same training corpora described in Section 3.2. berkeley aligner #REFR applies the co-training approach for training the IBM model 1 and HMM.", "predict": "berkeley aligner #REFR is one of the most popular word aligners in the MT community."}
{"label": "It is worth noting that the German parse trees #REFR tend to be broader and shallower than those for English.", "predict": "For the other language pairs, we use the settings reported by #REFR."}
{"label": "We identify and eliminate unimportant words, somewhat similar to Q&A retrieval #REFR.", "predict": "It is a well-known fact that key words or important words are not only more representative, but also have a much smaller vocabulary size than common words #OTHEREFR; #REFR."}
{"label": "BBN has developed a software package, the Learner, as a porting tool for non-expert users #REFR.", "predict": "In this paper, we discuss an experiment using the Learner, a software tool for acquiring information about a new task domain for Parlance, an ATN-based natural anguage system #REFR."}
{"label": "We proposed a variant of an online learning algorithm inspired by a batch learning algorithm of #REFR.", "predict": "We propose an online learning algorithm for SMT based on stochastic gradient descent #OTHEREFR; #REFR."}
{"label": "#REFR derive paraphrases from monolingual data using distributional similarity metrics.", "predict": "#REFR proposed a monolingual approach that extracts paraphrases based on distributional similarity between words."}
{"label": "Recently, there have been many advances in SRL #OTHEREFR; #REFR.", "predict": "While earlier systems #OTHEREFR; #REFR relied on shallow syntactic features, recent systems have also used semantic role features #OTHEREFR."}
{"label": "However, some recent approaches have explored ways of using annotated non-native text either by incorporating error-tagged data into the training process #OTHEREFR, or by using native language-specific error statistics #REFR.", "predict": "#REFR and Grefenstette et al #OTHEREFR propose approaches for adapting models to the writer?s first language (L1)."}
{"label": "Statistical Machine Translation #OTHEREFR and prediction of twitter responses #REFR.", "predict": "Machine Translation #OTHEREFR; #REFR."}
{"label": "Researchers have paid a lot of attention to datadriven dependency parsing in recent years #REFR.", "predict": "Data-driven dependency parsing has been successfully applied to many languages #OTHEREFR; #REFR."}
{"label": "The unsupervised data that we integrate has been created by automatic translations of parts of the Arabic LDC Gigaword corpus (mostly from the HYT collection) with a standard phrase-based system #REFR.", "predict": "The baseline system is a hierarchical phrase-based system #REFR which we trained with the freely available GIZA++ implementation of IBM Model 4 word alignments."}
{"label": "Although this approach can give inaccurate estimates, the counts given to the incorrect senses will disperse randomly throughout the hierarchy as noise, and by accumulating counts up the hierarchy we will tend to gather counts from the correct senses of related words #REFR.", "predict": "This approach is unsatisfactory, as #REFR and others have noted."}
{"label": "Our projection procedure resembles unsupervised text categorization #REFR, with categories represented by term clusters that are not predefined but rather emerge from the analyzed data:", "predict": "The projection can be based on any sentence clustering scheme, and the following are some of the popular schemes that we consider: #OTHEREFR; #REFR, and #OTHEREFR."}
{"label": "A similar idea is proposed by #REFR for producing high precision data for lexical acquisition.", "predict": "We use a greedy heuristic, which is similar to the one used by #REFRb), to select the dependencies that occur in at least k% of the derivations."}
{"label": "At each step of the distant supervision process, we closely follow the recent literature #OTHEREFR; #REFR.", "predict": "For a detailed description of the algorithms and the implementation, we refer the reader to #REFR."}
{"label": "Discourse parsing tries to identify how the units are connected with each other and thereby uncover the hierarchical structure of the text, from which multiple NLP tasks can benefit, including text summarization #OTHEREFR, sentence compression #REFR or questionanswering #OTHEREFR.", "predict": "As a result, discourse units are interrelated and the text as a whole is well-organized #OTHEREFR; #REFR."}
{"label": "The existence of the ATIS database #REFR is no doubt a factor in the popularity of the travel domain among the research community for exactly this reason.", "predict": "The size of the data needed for a good statistical language model can be quite large #OTHEREFR; #REFR."}
{"label": "The graphbased method views the problem as finding an optimal tree from a fully-connected directed graph #OTHEREFR; #REFR, while the transition-based method tries to find a highest-scoring transition sequence that leads to a legal dependency tree #OTHEREFR.", "predict": "Graph-based methods model the dependency parsing problem as a maximum spanning tree (MST) problem and learn parameters by solving a maximum spanning tree subgraph #REFR."}
{"label": "We use a common graph-based parsing technique #REFR; the approaches described here could be used in transition-based parsing as well.", "predict": "We also focus on graph-based dependency parsers #OTHEREFR; #REFR."}
{"label": "This is a variant of the greedy one-to-one mapping scheme of #REFR.8 With a Tag Dictionary We also ran a second version of each experimental configuration, where we used a tag dictionary to restrict the possible path sequences of the HMM during both learning and inference.", "predict": "For comparison, we also report results using the tag dictionary of #REFR."}
{"label": "First, we investigate the impact of using different flavours of Covington?s algorithm #OTHEREFR for nonprojective dependency parsing on the ten different languages provided for CoNLL-X Shared Task #REFR.", "predict": "First, we compare the performance of the Covington parser #REFR with the performance of two other incremental dependency parsers, namely the MaltParser #OTHEREFR."}
{"label": "#REFR presents a detailed overview that also mentions short-comings.", "predict": "#REFR, however, argue that STSGs are not powerful enough for syntax-based machine translation."}
{"label": "#REFR chose an approach motivated by the assumption that documents containing a large number of patterns already identified as relevant to a particular IE scenario are likely to contain further relevant patterns.", "predict": "#REFR reports an approach to this problem based on the ExDISCO algorithm."}
{"label": "Finally, another soft-constraint approach that can also be viewed as coming from the data-driven side, adding syntax, is taken by #REFR.", "predict": "#REFR propose a?hybrid? framework for SMT that combines a phrase-based model with a grammar-based generator, with a particular focus on Arabic-to-English translation."}
{"label": "The artificial data set of #REFR is widely used in the literature and enables comparison of a new segmentation method with existing ones.", "predict": "We have chosen to compare our algorithm with the one of #REFR because it is the state-of-the-art segmentation algorithm for the classical segmentation criterion."}
{"label": "Another WSD approach incorporating context-dependent phrasal translation lexicons is given in #REFR and has been evaluated on several translation tasks.", "predict": "Another line of research in WSD is to incorporate WSD into SMT #OTHEREFR; #REFR."}
{"label": "Analogous techniques for tree-structured translation models involve either allowing each nonterminal to generate both terminals and other nonterminals #REFR, or, given a constraining parse tree, to ?flatten? it #OTHEREFR.", "predict": "Most of the cases that cannot be covered by shorter phrases can be handled by increasing the size of the phrase table #REFR."}
{"label": "In the Second International Chinese Word Segmentation Bakeoff (the second SIGHAN CWS bakeoff) #REFR, two of the highest scoring systems in the closed track competition were based on a CRF model #OTHEREFR.", "predict": "The model is defined on a linear chain with the labels defined on a fixed-width window #REFR."}
{"label": "The most representative methods for relation classification use supervised paradigm; such methods have been shown to be effective and yield relatively high performance #OTHEREFR; #REFR.", "predict": "Previous methods for relation classification are primarily based on supervised machine learning algorithms, and their performance is mainly affected by the quality of the extracted features #OTHEREFR; #REFR."}
{"label": "We avoid the construction of (Bar-Hillel 1This problem is also relevant to other areas of statistical NLP, for example NL generation #REFR.", "predict": "Our algorithm uses the forest representation of syntax described in #REFR and extends the dynamic programming algorithm of #OTHEREFR to handle the more general class of synchronous grammars."}
{"label": "The MaltParser system for English described in #REFR was used as a baseline, and then optimized for this new task, focusing on feature selection.", "predict": "MaltParser #REFR was used for parsing."}
{"label": "There are two dominant approaches to dependency parsing: graph-based and transition-based, where graphbased parsing is understood to be slower, but often more accurate #REFR.", "predict": "There are two dominant approaches to dependency parsing: graph-based methods #OTHEREFR; #REFR."}
{"label": "Whereas we have concentrated on determinism in this paper, one can also introduce a limited degree of nondeterminism and allow some of the most promising configurations at each input position to compete, applying techniques such as beam search #OTHEREFR, or A ? search #REFR in order to keep the running time low.", "predict": "The formulae in Section 3 and Appendix D can be used to implement a parser using the A* search procedure #REFR, but we do not investigate this further."}
{"label": "We carried out a comprehensive evaluation of the automatically acquired verbal semantic forms against the COMLEX Resource #REFR for the 2992 active verb lemmas that both resources have in common.", "predict": "In previous work, we reported on the extraction of a set of 142 active and 34 passive frames #REFR."}
{"label": "Figure 2: A simple lexicalized parse tree. criminative models described in #OTHEREFR, the generative model in #REFR, the lexicalized TAG extractor in #OTHEREFR.", "predict": "Figure 2: A sample lexicalized parse tree. criminative parsers of #OTHEREFR and #REFR."}
{"label": "More recently, we show that our SCFG-based parser can be inverted to produce a state-of-the-art NL generator, where a formal MRL is translated into an NL #REFR.", "predict": "The idea of using SMT for NL generation has also been explored by others #OTHEREFR; #REFR."}
{"label": "Abstracting from results for concrete test sets, #REFR try to identify statistical and linguistic properties on that the performance of similarity metrics generally depends.", "predict": "However, as pointed out by #REFR, the best similarity metric may depend on the context representation."}
{"label": "We will extend the logical engine used to infer rhetorical relations--DiCE #OTHEREFRb, #REFR--to model inferences about intentional structure and its interaction with informational structure.", "predict": "This approach to discourse structure has been applied to a number of phenomena in discourse processing, including presupposition accommodation #OTHEREFR; #REFR, reference #OTHEREFR."}
{"label": "Some of these techniques have been successfully applied for NLP tasks: word sense disambiguation #REFR, sentiment analysis #OTHEREFR, to name but a few.", "predict": "These methods have been applied to word sense disambiguation #OTHEREFR; #REFR, document classification #OTHEREFR."}
{"label": "To expand our lexicon of these nouns, we started with a seed set garnered from the Penn Treebank #REFR, which uses distinctive tree structures for complement-taking nouns, and a small list of linguistically prominent nouns.", "predict": "To identify more of these nouns, we used the Penn Treebank #REFR to examine all verbs in the database that take a complement but not a gerund."}
{"label": "#REFR use a thesaurus to aid in the construction of a sentiment lexicon for English.", "predict": "#REFR use a thesaurus to generate a highcoverage lexicon for English."}
{"label": "Analyses have shown that this augmented data can lead to better statistical estimation or word coverage #REFR.", "predict": "This simple yet effective approach has been shown to be applicable to a variety of translation tasks #OTHEREFR; #REFR."}
{"label": "In several studies (e.g., #REFR it has been shown that relatively unsupervised and language-independent methods could be used to generate many thousands of sets of words whose semantics is similar in some sense.", "predict": "In previous work #REFR, we have generated sets of words that appear to form single concepts, based on the clustering of words that occur together in lists."}
{"label": "In this study we use PropBanked versions of the Wall Street Journal (WSJ) part of the Penn Treebank #REFR and part of the Brown portion of the Penn Treebank.", "predict": "PropBank 1.0 includes a version of the Penn Treebank #REFR annotated with the PropBank annotation, which we refer to as PropBank WSJ."}
{"label": "More recently, various researchers have used topic models for document geolocation #OTHEREFR; #REFR or other types of geographic document summarization #OTHEREFR.", "predict": "More recent work has employed statistical language models and machine learning techniques, including conditional random fields #OTHEREFR, topic models #REFR, and logistic regression #OTHEREFR."}
{"label": "#REFR implement lexicalized content models that represent global text properties on news articles and narratives using Hidden Markov Models (HMMs).", "predict": "#REFR propose a method for learning a hidden Markov model (HMM) to model the content structure of texts within a specific domain."}
{"label": "The merging procedure seeks to address overfitting at the level of the features themselves and remain true to the spirit of the maximum entropy approach, which seeks to represent what is unknown about the data with uniformity of the distribution, rather than by making adjustments on the model distribution itself, such as the Gaussian prior of #REFR.", "predict": "#REFR describe a scheme for merging features which involves combining the elements of two features which share some commonality."}
{"label": "Recent experiments performed by two groups of researchers at CMU have gathered ata on subjects using speech recognizers in office-like environments #REFR.", "predict": "We recently performed experiments with a speech understanding system, based on the Sphinx recognizer, in the context of a spreadsheet task #REFR."}
{"label": "A source of statistics widely used in prior work is the query log #OTHEREFR; #REFR.", "predict": "As another example, the fact that Sandeep Kohli sent multiple excel attachments increases our confidence in excell? excel (rather than, e.g., excell? excel).1 Such observations are consistent with the notion that query logs are a rich source of information that can be used to learn language models and error models #OTHEREFR; #REFR."}
{"label": "Details about the speech recognition system we refer to in the paper can be found in #REFR/1).", "predict": "The details of this search procedure can be found in #REFR."}
{"label": "As using complementary information has been useful in, e.g., POS error detection #REFR, we explore other simple comparable properties of a dependency grammar.", "predict": "In this section, we present a more general set of rules, which we call dependency rules, which we will use to define a more robust set of comparison methods in Section 4.2.2, based on #REFR."}
{"label": "The linguistic information within this track is encoded in a so-called VIT 2 #REFR which is a formalism following DRT.", "predict": "The shallow translation track uses the VIT, a underspecified Discourse Representation Theory #REFR."}
{"label": "#REFR adopted a supervised learning technique to search for useful syntactic patterns as contextual clues.", "predict": "The work in #REFR used dependency relationships to extract the quadruples in opinion expression."}
{"label": "For more expressive, linguistically-motivated syntactic MT models #REFR, the grammar complexity has grown considerably over hierarchical phrase-based models #OTHEREFR.", "predict": "Another line of work focuses on improving grammar complexity, for example by pruning syntactic rules #REFR or using more compact grammar formalisms #OTHEREFR."}
{"label": "Not surprisingly, some degree of disambiguation is needed to carry out effective anonymization #REFR.", "predict": "Anonymization of clinical text is notoriously difficult #OTHEREFR; #REFR."}
{"label": "A good example of work in this space is shown in #REFR, who describe a method for phrase table reduction, sometimes substantial (>90%), with no impact on the resulting BLEU scores.", "predict": "While the results in #REFR are impressive, the effect of data reduction on training time is not discussed, and their method is not scalable."}
{"label": "Factored models #REFR factor the phrase translation probabilities over additional information annotated to each word, allowing for text to be represented on multiple levels of analysis.", "predict": "Factored models #REFR represent translation by assigning different sets of features to each word in the target language, so that words with different morphological properties can be translated using different translation rules."}
{"label": "Therefore, we were less concerned with improving efficiency, and more with the properties of this algorithm, which we consider a baseline method upon which more sophisticated techniques such as best-first parsing #OTHEREFR or A search #REFR may well be able to improve.", "predict": "We also plan to apply the A* technique of #REFR to this problem, in order to determine whether a more informed search strategy would result in faster convergence."}
{"label": "It has been shown that accurate discourse segmentation within a sentence greatly improves the overall parsing accuracy to near human levels #REFR.", "predict": "We also performed full sentence-level discourse parsing using the SPADE model, using the treebank of #REFR as our training set."}
{"label": "Many systems use binary features i.e. the word-internal features, which indicate the presence or absence of particular property in the word. #OTHEREFR; #REFR.", "predict": "Some of the features are specific to the language and some are common across languages. #REFR used capitalization, prefixes, suffixes, word boundaries, POS tags, and part-of-speech tags as features."}
{"label": "This 5All statistical significance tests in these experiments use the computationally-intensive randomisation test described in #REFR, with p < 0.05. work has shown that tag sequences can be successfully used to restrict the set of parses produced, but generally are not discriminatory enough to distinguish a single best parse.", "predict": "They do this using the chi-squared statistic #REFR, which is calculated over the set of all possible tag sequences for a parse forest."}
{"label": "Segmentation is a useful intermediate step in such applications as subjectivity analysis #REFR, automatic summarization #OTHEREFR and others.", "predict": "This is useful for applications such as topic-based summarization #OTHEREFR, opinion topic detection #REFR, and topic-based question answering #OTHEREFR."}
{"label": "#REFR dissected parsing difficulty metrics (including surprisal and entropy) to separate out the effects of syntactic and lexical difficulties, and showed that these new metrics are strong predictors of reading difficulty.", "predict": "#REFR and Schuler et al #OTHEREFR present various methods for calculating surprisal for probabilistic constituency parsers."}
{"label": "Sentence splitting and tokenization was carried out using the relevant modules from the BRAT package #REFR.", "predict": "We use the BRAT annotation tool #REFR to identify verb senses in the training data."}
{"label": "AL has been successfully applied to a number of NLP tasks such as part-of-speech tagging #OTHEREFR, and named entity recognition (NER) #REFR.", "predict": "AL has been successfully applied to various NLP tasks, including named entity recognition #OTHEREFR, document classification #REFR, and machine translation #OTHEREFR."}
{"label": "#REFR showed a slight improvement in parsing accuracy when enough fragments were added to learn enrichments beyond manual refinements.", "predict": "And #REFR showed that a data-oriented parser that prunes the training set based on fragment probabilities could be augmented with a symbol refinement grammar to improve accuracy."}
{"label": "There is currently support for Word- Net #OTHEREFR, and UBY #REFR, which provides access to WordNet, Wikipedia, Wiktionary, GermaNet, VerbNet, FrameNet, Omega- Wiki, and various alignments between them.", "predict": "DKPro WSD ships with support for WordNet #OTHEREFR, GermaNet #REFR, and OmegaWiki #OTHEREFR."}
{"label": "We follow the approach of #REFR and predict the VDR y of an image over a collection of labelled region annotations x.", "predict": "In this paper we use the Visual Dependency Representation (VDR) to model the relationships between the regions in an image #REFR."}
{"label": "Handcrafted rules #OTHEREFR; #REFR for preordering training data and system input have been explored in numerous publications.", "predict": "The most popular approach is lexicalized reordering, which is described in #REFR."}
{"label": "#REFR found several parsing-based features and part-of-speech based features to be useful.", "predict": "#REFR, and others, have shown that syntactic features are helpful in determining grade level."}
{"label": "Among recent op performing methods are Hidden Markov Models #REFR, maximum entropy approaches #OTHEREFR.", "predict": "Among recent op performing methods are Hidden Markov Models #OTHEREFR, and transformation-based learning #REFR."}
{"label": "The reordering metrics require alignments which were created using the Berkeley word alignment package version 1.1 #REFR, with the posterior probability to being 0.5.", "predict": "Word alignments were obtained using the Berkeley Aligner #REFR."}
{"label": "FEDA is known to not improve upon a single classifier baseline for that dataset #REFR.", "predict": "As expected, we find that the MDR-L2 and MDR-KL multi-domain learning algorithms #REFR and the MTRL algorithm #OTHEREFR both improve upon the single classifier baseline."}
{"label": "Many authors (among them #REFR incorporate RA into their parsing systems, yet none rely on it solely, integrating it instead with disambiguation preferences derived from word/constituent/con", "predict": " (Wilks 1976),The computational study of a syntactically annotated corpus has demonstrated that the failure of RA is a pervasive phenomenon and that it does not always coincide with the failure of MAs (Schubert and #REFR, and that the failure of RA is not always due to the failure of MAs."}
{"label": "Nevertheless, we conclude that among currently available approaches, i.e., our two algorithms and the EM-based approach of #REFR, ?familiarity maximization? is the most promising approach for automatic assignments of heads in treebanks.", "predict": "However, we expect that algorithms based on the lexicalized tree grammars induced from the head-annotated treebank will have an advantage over other methods, since they have the potential to incorporate distributional information in a more direct way than other methods, which often resort to heuristics based on local tree patterns #OTHEREFR; #REFR."}
{"label": "Using higher order LMs to improve the accuracy of SMT is not new. #REFR built 5-gram LMs over web using distributed cluster of machines and queried them via network requests.", "predict": "#REFR proposed to use cluster of machines to build large LMs by partitioning the LM to multiple machines and then merging the results at the end."}
{"label": "This is perhaps unsurprising, as the finer-grained distinctions in corpora seem to be based on lexical properties more than on additional context (see, e.g., #REFR.", "predict": "As #REFRb) have shown, there are many sets which share a common set of categories, and even if they are very different, a frame can be ambiguous in one and unambiguous in the other."}
{"label": "The system translates entences in the ATIS domain #REFR between English and Mandarin Chinese.", "predict": "We used the ATIS corpus #REFR to train the translation model."}
{"label": "We took the model of #REFR as the baseline, and extended it with online large-margin training and an N -gram language model.", "predict": "Our system extended #REFR by incorporating an N-gram language model and a dependency model."}
{"label": "In order to improve QA systems? performance many research focus on different structures such as question processing #REFR, information retrieval #OTHEREFR for ranking, answer extraction, etc.", "predict": "Our QA system has a pipeline structure similar to that of #OTHEREFR, and #REFR."}
{"label": "For language acquisition, a natural question is whether prosody could similarly aid grammar induction from speech #REFR.", "predict": "Punctuation constraints improve accuracy in 17 of 18 languages, and the overall gain of 1.3% is significant in the unsupervised setting #REFR."}
{"label": "While many works #OTHEREFR view the properties of positivity and negativity as categorical (i.e., a term is either positive or it is not), others #REFR view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic.", "predict": "This is typically done by assigning a positive or negative score to each term, or, more precisely, to each sense of the term, on the basis of a corpus of texts #OTHEREFR; #REFR."}
{"label": "Because our algorithm does not consider the context given by the preceding sentences, we have conducted the following experiment to see to what extent the discourse context could improve the performance of the wordsense disambiguation: Using the semantic concordance files #REFR, we have counted the occurrences of content words which previously appear in the same discourse file.", "predict": "#REFR tested this hypothesis using the Brown corpus #OTHEREFR."}
{"label": "One source of constraint which our model still does not explicitly capture is the first-order dependency between alignment positions, as in the HMM model #REFR and IBM models 4+.", "predict": "Note that these features do not take into account word order, so are likely to perform poorly on longer sentences, which is indeed a weakness of IBM Model 4 #REFR."}
{"label": "Analysis In order to distinguish antonyms from synonyms, the polarity inducing LSA (PILSA) model #REFR takes a thesaurus as input.", "predict": "#REFR proposed a novel way of representing antonymy in the LSA framework."}
{"label": "Given a bilingual corpus, we use GIZA++ #REFR as word alignment core algorithm.", "predict": "We start with a standard word-based IBM Model 4 #OTHEREFR, using GIZA++ #REFR for word alignment."}
{"label": "Several researchers explored joint DS and PS information to enhance the quality of syntactic parsing #REFR.", "predict": "There have been some efforts on integrating features from constituent and dependency structures in the literature #OTHEREFR; #REFR."}
{"label": "We compare against the original MIML-RE model using the same dataset and evaluation methodology as #REFR.", "predict": "We compare our approach against two state-of-the-art relation extractors: Riedel?s multi-instance multi-label learning (MIML) #REFR and Bjo?#OTHEREFR?s memory-based classifier."}
{"label": "4 Here I propose what appears to me to be the most direct probabilistic generalization of lexiealized TAG; a different treatment can be found in \\[#REFR\\].", "predict": "In this section, I use the notation of #REFR."}
{"label": "It is a fundamental and often a necessary step before linguistic knowledge acquisitions, such as training a phrase translation table in phrasal machine translation (MT) system #REFR, or extracting hierarchial phrase rules or synchronized grammars in syntax-based translation framework.", "predict": "Word alignments are widely used as knowledge source for phrase table training #REFR and syntax acquisition #OTHEREFR."}
{"label": "#REFR took the approach that large number of entities will be unlinkable, as there is a probability that the relevant KB entry is unavailable.", "predict": "#REFR proposed a method for entity disambiguation by using a NIL learning algorithm."}
{"label": "The field of syntactic parsing has received a great deal of attention and progress since the creation of the Penn Treebank #OTHEREFR; #REFR.", "predict": "In the last few years, there has been a great deal of progress in parser development, as evidenced by the fact that parsers can now achieve state-of-the-art performance on a variety of evaluation tasks #OTHEREFR; #REFR."}
{"label": "Greedy local search #OTHEREFR; #REFR has typically been used for decoding in shift-reduce parsers, while beam-search has recently been applied as an alternative to reduce error-propagation #OTHEREFR.", "predict": "Greedy local search #OTHEREFR; #REFR."}
{"label": "This representation departs from the vector space metaphor #OTHEREFR; #REFR, commonly employed in other frameworks for distributional semantics such as LSA #OTHEREFR.", "predict": "In contrast to related work on distributional semantics that relies on global models #OTHEREFR; #REFR, we are interested in the contextualized representations of language elements."}
{"label": "Since Japanese does not delimit words by white-space, the unit of chunking can be a character #REFR or a morpheme #OTHEREFR.", "predict": "Previous studies #REFR use morphological analysis as an input to a NER model."}
{"label": "#REFR first identified the importance of syntactic query/corpus parsing for information retrieval, but did not consider query segmentation itself.", "predict": "NC bracketing is useful for document indexing, e.g., in order to allow the user to refine the query via a list of candidate NCs #REFR."}
{"label": "One focusses on filtering the extracted hierarchical rules either by removing redundancy #OTHEREFR or by filtering rules based on certain patterns #REFR, while the other stream is concerned about alternative approaches for learning the synchronous grammar #OTHEREFR.", "predict": "One stream of work attempts to modify the rule extraction process to limit the number of rules extracted #OTHEREFR; #REFR."}
{"label": "Rather than using sentence length as a proxy, measures can employ tools for automatic analysis of the syntactic structure of texts (e.g., #REFR).", "predict": "Syntactic parsers are now widely available #OTHEREFR; #REFR."}
{"label": "Sentence compression is typically formulated as the problem of removing secondary information from a sentence while maintaining its grammaticality and semantic structure #OTHEREFR; #REFR.", "predict": "We first apply the basic sentence compression techniques described in #OTHEREFR; #REFR to the input query and document."}
{"label": "Features We have designed rather simple features based on the common feature set #OTHEREFR; #REFR for bunsetsu-based parsers.", "predict": "For feature extraction, we followed the same setting as #REFR."}
{"label": "Each list contained the n-best translations produced by the phrase-based system of #REFR.", "predict": "In addition to the standard features, we also included features that count the number of candidates that contain a given preposition or verb form, following #REFR."}
{"label": "In the following model, summarized here from the full description given in #REFR, we consider words to be ordered pairs consisting of a surface word, W, and a word feature, F , given as < W, F >.", "predict": "In the context of NE, HMMs have been used for a variety of tasks such as #OTHEREFR; #REFR, #OTHEREFR."}
{"label": "However, although it is standard practice in MT evaluation to measure increases in automatic metric scores with significance tests #OTHEREFR; #REFR, this has not been the case in papers proposing new metrics.", "predict": "However, significance tests are generally not used to determine whether the difference in correlation with human judgment is statistically significant #OTHEREFR; #REFR."}
{"label": "For example, it has been shown that grammatical error detection systems with high precision maximize learning effect, and that systems with high precision but lower recall are more useful in language learning than systems with high recall and lower precision #REFR.", "predict": "This was confirmed by #REFR."}
{"label": "The correctness of fields extracted via a conditional random field extractor has been shown to correlate well to an estimate obtained by a constrained forward-backward technique #REFR.", "predict": "#REFR used EM-based confidence estimation to identify low confidence extraction results for information extraction systems."}
{"label": "Previous work has shown that within a given discourse #OTHEREFR, or with respect to a given collocation #REFR, a word appears in only one sense.", "predict": "First, we assume that, for high frequency verbs, only one sense per collocation occurs #REFR."}
{"label": "Instead researchers condition parsing decisions on many other features, such as parent phrase-marker, and, famously, the lexical-head of the phrase #OTHEREFR; #REFR (and others).", "predict": "This has motivated a variety of work to add conditioning information to the parser #OTHEREFR; #REFR."}
{"label": "In particular, each of/#REFR/,/Kuhns 1988/, and/Rau and Jitcobs 1988/ describes ystems that characterize news reports with results that could llOt be obtained by keyword methods alone.", "predict": "In particular, each of/Hayes et al 1988/,/Kuhns 1988/, and/Rau and #REFR describes ystems that characterize news reports with results that could llOt be obtained by keyword methods alone."}
{"label": "Unlike the typical content specification modules #OTHEREFR; #REFR, our system relies on an authoring workstation environment equipped with a knowledge elicitation scenario for joint humancomputer content specification #OTHEREFR, for the details of the knowledge elicitation scenario).", "predict": "The text planning process is not based on a syntactic analysis of the input text, but rather on a semantic analysis of the input conceptual schema #REFR."}
{"label": "Approaches to this problem began by taking all fragments Fall in a treebank #OTHEREFR; #REFR.", "predict": "As a result, early work on learning TSGs has largely focused on heuristics to limit the size of the fragments that are allowed #OTHEREFR; #REFR."}
{"label": "The smoothing methods proposed in the literature #OTHEREFR, and distance-weighted averaging #REFR.", "predict": "Smoothing techniques can be classified as either discounting methods or class-based methods #REFR."}
{"label": "Such annotated resources are scarce, expensive to create and even the largest of them tend to have low coverage #REFR, motivating the need for unsupervised or semi-supervised techniques.", "predict": "Even in this setting, the majority of the work has focused on shallow semantic representations, e.g. #OTHEREFR; #REFR, and semantic role labeling #OTHEREFR."}
{"label": "It is highly effective for learners to receive feedback on their essays from a human tutor #REFR.", "predict": "Traditionally, the most effective way to help learners is manual feedback #REFR."}
{"label": "A review of methods for word sense disambiguation is presented by Ide and colleagues #REFR.", "predict": "Many methods have been proposed, including thesauri #OTHEREFR, #REFR, #OTHEREFR."}
{"label": "Many previous works show promising results with an assumption that syntactic cohesion explains almost all translation movement for some language pairs #OTHEREFR; #REFR.", "predict": "#REFR presents a tree-to-string model to use tree structure to represent the translation."}
{"label": "The pyramid method #REFR, was inspired in part by work in reading comprehension that scores content using human annotation #OTHEREFR.", "predict": "A number of automated methods for content evaluation of summaries were proposed in the context of the Pyramid method #REFR."}
{"label": "Correcting POS annotation errors can be done by applying a POS tagger and altering the input POS tags #REFR.", "predict": "Our previous work #REFR focused on the POS-tagged dependency annotation, where ambiguity class information is available for each position."}
{"label": "The Opinosis dataset #REFR consists of short user reviews in 51 different topics.", "predict": "The dataset used for our experiments is the Opinosis dataset #REFR."}
{"label": "Future research will investigate more sophisticated methods of text-to-text similarity for prompt-based content scoring, such as those used in #REFR.", "predict": "Future research will address the use of more sophisticated methods of calculating lexical overlap, such as those proposed in #REFR."}
{"label": "We pre-process the dataset with the following tools: the Charniak Parser #REFR for parsing sentences, the WordNet similarity package #OTHEREFR for creating the SYNT and the FOR feature spaces.", "predict": "We parse the sentences using the Charniak parser #REFR."}
{"label": "False Opinion Targets: In another case, the phrase ?wonderful time? can be matched by an opinion pattern ?Adj-{mod}-Noun?, which is widely used in previous works #REFR.", "predict": "For example, the phrase?time is money? is a very common phrase, which is often used to express positive opinion in many domains, such as MP3 #REFR, but it is not a valid opinion target."}
{"label": "#REFR investigate questions of dialectal differences and variation in regional interests in Twitter users using a collection of geotagged tweets.", "predict": "Geotagged Twitter feeds have been used to study language use in different regions of the world #REFR."}
{"label": "In addition, we have thrown further doubt on the possible use of the PTB for cross-framework parser evaluation, as recently suggested by #REFR.", "predict": "While the PTB representations are extremely powerful, they are not ideal for CCG parsing, and the CCG parser has been shown to perform very well on alternative parser evaluations, such as those using GR schemes #OTHEREFR; #REFR."}
{"label": "The use of prosodic and coarticulatory context has improved the effectiveness of tone and pitch accent recognition in a range of languages #OTHEREFR, and CRFs #REFR).", "predict": "#REFR, among others, demonstrate that the use of rich contextual features can lead to significant improvements in pitch accent labeling."}
{"label": "#REFR investigated system combination using automatic generation of diverse individual systems.", "predict": "#REFR explores the effect of variation on system combination."}
{"label": "Therefore, the feature model focuses on each kind of head-child pair in the dependency tree, and mainly contains four categories of features #REFRa): basic uni-gram features, basic bi-gram features, in-between POS features, and surrounding POS features.", "predict": "The feature set of MSTParser #REFR is defined by three categories: the headword, the dependency relation, and the path of the arc."}
{"label": "Nearly all previous work on unsupervised grammar induction has focused on learning hierarchical phrase structure #OTHEREFR; #REFR or dependency structure #OTHEREFR.", "predict": "The problem of syntactic chunking is not wellstudied in the unsupervised setting, but there have been several recent attempts to learn hierarchical structure in this way #OTHEREFR; #REFR."}
{"label": "Another common type of projection methods map labels from resource-rich language sentences to resource-scarce ones in a parallel corpus using word alignment information #REFR.", "predict": "The second type of projection methods #REFR are based on word alignments."}
{"label": "Our interpretation is more useful than past interpretations involving marginal constraints #OTHEREFR or maximum-entropy models #REFR as it can recover the exact formulation of interpolated Kneser-Ney, and actually produces superior results. #OTHEREFR has independently noted the correspondence between the hierarchical Pitman-Yor language model and interpolated Kneser-Ney, and conjectured improved performance in the hierarchical Pitman-Yor language model, which we verify here.", "predict": "This is in contrast to previous work where interpolated Kneser-Ney was shown to be equivalent to a special case of a Bayesian model with an exponential prior #REFR."}
{"label": "PARC 700 Dependency Bank following #REFR The results are given in Table 7.", "predict": "We tested the impact of LDD resolution on the two architectures described in #REFR."}
{"label": "Although statistical approaches to automatic term recognition, e.g. #OTHEREFR; #REFR, have achieved relative success over the years, the addition of suitable linguistic information has the potential to enhance results still further, particularly in the case of small corpora or very specialised omains, where statistical information may not be so accurate.", "predict": "The past few years have seen a wide variety of approaches to terminology identification, from those based on pattern matching and statistical techniques #OTHEREFR, #REFR, #OTHEREFR)."}
{"label": "It has received significant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems #OTHEREFR and opinions #REFRa).", "predict": "Many of the techniques used in sentiment analysis make use of sentiment-bearing words, and lexicons of such words have been the focus of considerable attention #OTHEREFR; #REFR."}
{"label": "Results of this evaluation and comparisons with our theoretical figures are further described in #REFR.", "predict": "The evaluation described in #REFR, however, was carried out with experienced translators."}
{"label": "Alignments were learned using two iterations of Model 1 and two iterations of the HMM alignment model #REFR.", "predict": "Word alignment is performed using the HMM-based model #REFR, and phrase extraction is performed using the GIZA++ implementation of IBM Model 4 #OTHEREFR."}
{"label": "#REFR use machine translation for multilingual sentiment analysis.", "predict": "#REFR present a method based on machine translation."}
{"label": "Here we report first quantitative results on the ATIS3 corpus #REFR.", "predict": "We have applied the algorithm to the ATIS corpus of phrase-structure annotated sentences #REFR."}
{"label": "For example, citation-based summarization systems #REFR and survey generation systems #OTHEREFR can benefit from citation purpose and polarity analysis to improve paper and content selection.", "predict": "Such systems could help identify the most relevant papers for a given paper, or help summarize a given topic #REFR."}
{"label": "We use MXPOST tagger #OTHEREFR for POS tagging, Charniak parser #REFR for extracting syntactic relations, SVMlight1 for SVM classifier and David Blei?s version of LDA2 for LDA training and inference.", "predict": "The data for the English lexical sample task is from Senseval-3 and the data for the English all-words task is from the WSJ corpus of the Penn Treebank #OTHEREFR; #REFR."}
{"label": "Thanks to this sort of activation flow FIG tends to select and emit an appropriate word in an appropriate form #REFR.", "predict": "Syntactic category nodes handle both lexical and nonlexical categories, as discussed in #REFR."}
{"label": "The deterministic shift/reduce classifier-based dependency parsing approach #REFR has been shown to offer state-of-the-art accuracy #OTHEREFR with high efficiency due to a greedy search strategy.", "predict": "In order to achieve both of these goals, we follow the approach of Nivre and Scholz #OTHEREFR, which has been shown to be both accurate and efficient #REFR."}
{"label": "This method is more similar to the one used in #REFR, with the difference that they use only 1-best input from a base MT system.", "predict": "To obtain a system which is able to predict word forms, we integrate the inflection prediction component in three ways: (1) by applying the full model directly to the n-best list from the base MT system, (2) by applying the model to the n-best list, and (3) by applying the model to the n-best list and then capitalizing the output.1 We also use a capitalization model #REFR trained on the same data as the inflection prediction component."}
{"label": "#REFR used a Roget-like thesaurus, co-occurrence statistics, and a seed set of antonyms to identify the degree of antonymy between two words, and generate a list of antonymous words.", "predict": "We use a thesaurus built by #REFR."}
{"label": "The English corpus contains 47613 sentences, that were POS tagged using Stepp Tagger #OTHEREFR, and use the Lemmatizer #REFR to extract and stem content words (nouns, verbs, adjectives, adverbs).", "predict": "The English corpus contains 14069 sentences that were POS tagged using MXPOST #REFR."}
{"label": "#REFR introduced a corpus-based approach for generating a K ?K matrix for each verb from an average of Kronecker products of the subject and object vectors from the positively labelled subset of the training data.", "predict": "The method is described in detail in #REFR."}
{"label": "Gi#REFR reports a relation discovery algorithm based on Hearst.", "predict": "#REFR discusses the difficulty of part-whole relation extraction, noting that selectional preferences alone are insufficient to identify part-whole relations."}
{"label": "Our error analysis above also highlights our task?s difference with previous work that identify corresponding phrases between two sentences, including phrase extraction #REFR and paraphrase extraction #OTHEREFR.", "predict": "Phrase extraction is the task of identifying phrases that have similar meanings #REFR."}
{"label": "To address this problem, there have been several recent attempts to incorporate into distributional semantic models a component that generates vectors for unseen linguistic structures by compositional operations in the vector space #REFR.", "predict": "A number of models have been proposed to address this problem, including models that take advantage of linguistic knowledge to improve the performance of the distributional representations #OTHEREFR; #REFR, or that take into account the compositional nature of natural language #OTHEREFR."}
{"label": "Several approaches have modified the Lesk algorithm to reduce is exponential complexity, like the one based on Simulated Annealing #REFR.", "predict": "#REFR extended the Lesk algorithm to perform WSD on complete sentences, using a technique similar to simulated annealing."}
{"label": "In recent years a variety of statistical models for realization ranking that take syntax into account have been proposed, including generative models #OTHEREFR; #REFR, maximum entropy models #OTHEREFR.", "predict": "Many statistical models have been proposed for surface realization in CCG #OTHEREFR; #REFR."}
{"label": "We have been building the Sandglass MT system for the Japanese-Chinese, Chinese- Japanese language pairs #OTHEREFR; #REFR.", "predict": "In this paper, we describe the principle of our machine translation model, which is based on our previous studies #OTHEREFR; #REFR."}
{"label": "There are two kinds of methods for morphological disambiguation: onone hand, statistical methods need little effort and obtain very good results #OTHEREFR; #REFR, at least when applied to English, but when we try to apply them to Basque we encounter additional problems; on the other hand, some rule-based systems #OTHEREFR are at least as good as statistical systems and are better adapted to free-order languages and agglutinative languages.", "predict": "As the training corpus is very small, we have decided to use different tagsets for the different levels of ambiguity, which have been proposed by #REFR."}
{"label": "Methodologies such as lexicalisation #OTHEREFR; #REFR and tree transformations #OTHEREFR, weaken the independence assumptions and have been applied successfully to parsing and shown significant improvements over simple PCFGs.", "predict": "Recent research has shown that lexical information #OTHEREFR and treebank head information #REFR can be used to weaken such independence assumptions."}
{"label": "#REFR suggested a division of countability into five major types, based on Allan #OTHEREFR?s noun countability preferences (NCPs).", "predict": "The system described in #REFR is similar to the one used in the present paper."}
{"label": "In this section we introduce basic definitions related to synchronous context-free grammars and their probabilistic extension; our notation follows #REFR.", "predict": "Following #REFR, we will assume that SCFGs are defined as pairs of strings (S, T ) over N and N?, respectively."}
{"label": "In principle, the comparison can be done via coselection of extracted sentences #OTHEREFR; #REFR, by string-based surface measures #OTHEREFR.", "predict": "The DUC evaluations #OTHEREFR, #REFR, #OTHEREFR."}
{"label": "An investigation propose that boundary strength according to the measure, which the boundary strength is applied to syntactic structures and the phrase structure is viewed as an immediate constituency tree exclusively, corresponds much more closely to empirical prosodic boundary strength than does syntactic boundary strength according to a standard measure #REFR.", "predict": "In Spanish, prosodic phrase boundaries have a high accuracy (87%) compared to syntactic boundaries #REFR."}
{"label": "Several methods have been proposed with regard to aligning sentences #OTHEREFR; #REFR.", "predict": "Several techniques for aligning bilingual sentences have been proposed #OTHEREFR; #REFR."}
{"label": "#REFR\\] propose a large scale method, but results are reported for only one sentence, and no success rate is given.", "predict": "The methods of Hearst \\[1991\\] and #REFR\\] have been applied to a number of words with only a few senses."}
{"label": "There are also automatic measures which do not require model summaries, but compare against the source text instead #OTHEREFR; #REFR.", "predict": "Several studies have shown that current extractive systems score poorly compared to human-written abstracts #REFR."}
{"label": "At first, additional linguistic resources, such as specialized dictionaries #REFR or transliterated words #OTHEREFR, were combined with the seed dictionary to translate context vectors.", "predict": "Starting from the standard approach, several improvements were proposed: the use of additional information like the position of the candidate word in a sentence #OTHEREFR or the frequency of the candidate word in the target corpus #REFR."}
{"label": "We choose to use an earlier neural network based probabilistic model of parsing #REFR, whose hidden units can be viewed as approximations to latent variables.", "predict": "In this paper, we use the neural network model of #REFR."}
{"label": "In #REFR we proposed a general protocol for handling annotation discrepancies when comparing parses across different dependency theories.", "predict": "#REFR have recently presented a protocol for evaluating constituency and dependency treebanks that overcomes the shortcomings of the previous approaches."}
{"label": "For instance, measures that compute the association strength between the elements of an expression have been employed to determine its degree of compositionality #OTHEREFR (see also #REFR for an overview and a comparison of different measures).", "predict": "For instance, the authors of #REFR look at the distributional similarity of the component words and assume that low similarity indicates high compositionality."}
{"label": "In #REFR, it is proposed a matrix-vector recursive neural network model for semantic compositionality, which has the ability to learn compositional vector representations for phrases and sentences of arbitrary length.", "predict": "In #REFR the authors propose a matrix-vector RNN architecture to learn compositional vector representations for phrases and sentences."}
{"label": "This problem is a counterpart to the image description problem #OTHEREFR; #REFR, which has so far remained largely unexplored by the community.", "predict": "For example, prior work on text-to-image generation #OTHEREFR; #REFR does not address the grounding of language to spatial constraints."}
{"label": "Unlabeled data has been shown to improve the accuracy of conjunctions within complex noun phrases #REFR.", "predict": "Adding web-scale features #OTHEREFR; #REFR improves parsing performance."}
{"label": "The method has also been popular in the related task of noun clustering #REFR.", "predict": "We extend this method so that it is optimal for the task, and compare the results with those obtained by the method introduced in #REFR, which has been shown to outperform AGG on flat classifications."}
{"label": "Care was taken to ensure not just that the utterances themselves, but also the speakers of the utterances were disjoint between test and training data; as pointed out in #REFRa), failure to observe these precautions can result in substantial spurious improvements in test data results.", "predict": "These 15,000 utterances were also used in the experiments reported in #REFR."}
{"label": "Previous work on transfer-based MT systems #REFR and alignment-based transfer knowledge acquisition #OTHEREFR have proven that transfer knowledge can be best represented by declarative structure mapping (transforming) rules each of which typically consists of a pair of source and target partial structures as in the middle of Figure 2.", "predict": "To facilitate the application of a paraphrase generator, we should use a tree-to-tree representation style #REFR."}
{"label": "To speed up Viterbi parsing, sophisticated search strategies have been developed which find the most probable analysis without examining the whole set of possible analyses #OTHEREFR; #REFRa).", "predict": "Probabilistic methods like dynamic programming and the CKY algorithm #OTHEREFR; #REFR are applied to find the most probable parse."}
{"label": "Historically MT researchers have focused their attention on the mismatch of linear realization of syntactic arguments #OTHEREFR and word polysemy #REFR.", "predict": "We focus on discourse devices, which are discourse connectives and discourse particles that are used to link information in a sentence together and organize it into a coherent discourse segment #OTHEREFR; #REFR."}
{"label": "Researchers have explored error detection for manually tagged corpora in the context of pos-tagging #REFR, dependency parsing #OTHEREFR.", "predict": "#REFR detect errors in a single round of annotation."}
{"label": "Although the overall parsing style of our system integrates template-based and language-based strategies \\[#REFR\\], the skimming algorithm is actually more bottom-up or language-based.", "predict": "The skimming program is also related to other approaches that use bottom-up linguistic processing in combination with top-down constraints \\[e.g., Dorr, 1986; #REFR\\]."}
{"label": "Several unsupervised POS induction systems make use of morphological features #OTHEREFR; #REFR and this approach has been empirically proved to be helpful #OTHEREFR.", "predict": "Incorporating the information about POS tags into the morphology learning task has been shown to improve results #REFR."}
{"label": "Our data sources are the German NeGra #REFR and TIGER #OTHEREFR treebanks.", "predict": "The annotation scheme for the NeGra treebank was created in 2005 #REFR."}
{"label": "We show that by augmenting the delexicalized direct transfer system of #REFR with cross-lingual cluster features, we are able to reduce its error by up to 13% relative.", "predict": "We then use these clusters to significantly improve the accuracy of direct-transfer dependency parsers #REFR."}
{"label": "Subsequent work explored ways of exploiting linguistically annotated data for trainable generation models #REFR; Marciniak and Strube, 2005; Belz, 2005, a.o.).", "predict": "This work was followed by the use of maximum entropy models to predict word order #REFR and the incorporation of syntactic information in the models #OTHEREFR."}
{"label": "The speed and cost benefits for annotation are certainly impressive #OTHEREFR; #REFR but we hope to show that some of the greatest gains are in the very nature of the phenomena that we can now study.", "predict": "This is not a new idea, as it has been used to generate new data for machine learning #OTHEREFR, and machine translation #REFR, among many others."}
{"label": "Related sentences are represented by a word graph so that summaries constitute paths in the graph #REFR.", "predict": "Related sentences are represented by a word graph so that summaries constitute paths in the graph #REFR."}
{"label": "Most of the research as focused on bilingual terminology identification, either as parallel multiwords forms #OTHEREFR), technical terminology (e.g. the Termight system #REFR or broad-coverage translation lexicons #OTHEREFR).", "predict": "For instance, bilingual alignment techniques are now a standard tool in the translators? toolkit #REFR."}
{"label": "The domaingeneral DM was mostly abstracted from the TALK system #REFR.", "predict": "For more details on the ADT, see #REFR."}
{"label": "This is partly due to its relevance for applications ranging from information extraction #OTHEREFR, and the modeling of textual entailment relations #REFR.", "predict": "Automatic semantic role labeling has many applications, including information extraction #OTHEREFR; #REFR."}
{"label": "Bilingual word alignments are trained and combined from two sources: GIZA #REFR and maximum entropy word aligner #OTHEREFR.", "predict": "Word alignments are obtained with GIZA++ #REFR, and the sentence pairs are parsed with a modified version of the Berkeley parser #OTHEREFR."}
{"label": "Thanks to specific reordering modeling components, phrase-based SMT #OTHEREFR; #REFR are generally good at handling local reordering phenomena that are not captured inside phrases.", "predict": "Phrase-based approaches #REFR can learn local reorderings of phrases from parallel corpora and are thus well suited to handle short-range reordering phenomena."}
{"label": "These rules can be handcrafted grammar rules, such as those of #OTHEREFR or, alternatively, extracted fully automatically from treebanks #REFR.", "predict": "In some cases, the grammar rules are hand-crafted from an annotated corpus #OTHEREFR; #REFR, while in other cases they are automatically induced from a corpus #OTHEREFR."}
{"label": "Over the years, several approaches for mining translations from non-parallel corpora have emerged #OTHEREFR; #REFR, all sharing the same Firthian assumption, often called the distributionial hypothesis #OTHEREFR, which states that words with a similar meaning are likely to appear in similar contexts across languages.", "predict": "A plethora of methods have been proposed for translation of words from one language to another, based on comparable corpora, such as the ones presented by #REFR, Daum?e III and Guevara #OTHEREFR."}
{"label": "Many computational models of compositionality focus on learning vector spaces #OTHEREFR; #REFR.", "predict": "Previous approaches to modeling compositionality in vector spaces include models that use matrix multiplications #OTHEREFR; #REFR and recurrent neural networks #OTHEREFR."}
{"label": "This is the approach taken by #REFR, where they estimate what in our terms are projections of the raw treebank grammar from the treebank itself.", "predict": "The resulting grammar can then be used to prune the search space of CKY parsing #REFR."}
{"label": "Transliteration methods typically fall into two categories: generative approaches #OTHEREFR; #REFRa), that try to identify the correct transliteration for a word in the source language given several candidates in the target language.", "predict": "There have been a number of previous attempts at discovering NEs in bilingual corpora #OTHEREFR; #REFR."}
{"label": "These results are astonishing considering that #REFR ignored candidates that appeared less than 10 times (because they were unreliable). nouns because their morphological behaviors were the same as those of nouns.", "predict": "The high precision was mainly due to the fact that we only acquired morphemes of closed class morphemes, i.e., verbs, adjectives, adverbs, nouns and particles, in contrast to previous work #REFR."}
{"label": "Amazon Mechanical Turk is a crowdsourcing platform that has been extensively used for obtaining low-cost human annotations for various linguistic tasks over the last few years #REFR.", "predict": "Mechanical Turk has been used to conduct many NLP tasks, including text classification #OTHEREFR, machine translation #REFR, and sentiment analysis #OTHEREFR."}
{"label": "Recently, #REFR have reported experiments on learning information structure in the Prague TreeBank.", "predict": "The only study that is close in spirit is the one by #REFR, who use the Prague Dependency Treebank #OTHEREFR to automatically identify topic and focus."}
{"label": "#REFR employ a semi-automatic method to improve a large-scale morphosyntactic lexicon of French #OTHEREFR).", "predict": "A more recent study #REFR applies LA to a French lexicon."}
{"label": "There have been a number of recent studies on probabilistic treebank parsing of German #OTHEREFR, using the Negra treebank #REFR as their underlying data source.", "predict": "There has been a substantial body of research on the parsing of German using probabilistic treebank models, cf. #OTHEREFR; #REFR."}
{"label": "Finally, we have also considered ULC, which is a very simple approach to metric combination based on the unnormalized arithmetic mean of metric scores, as described by Gime?nez and Ma`#REFRa).", "predict": "ULC is a recently proposed non-parametric approach to combining different metrics #REFR."}
{"label": "This weight vector is learned using a simple Perceptron like algorithm similar to the one used in #REFR.", "predict": "The weight vector is computed by maximizing the probability of the candidate arc, given the weight vector and the projected parse #REFR."}
{"label": "They are characterized by the following properties #REFRb):", "predict": "The use of decomposable models for WSD has been extensively studied #OTHEREFR; #REFR."}
{"label": "Work on preposition errors has used a similar classification approach and mainly differs in terms of the features employed #OTHEREFR; #REFR.", "predict": "There has also been work on correcting preposition errors #REFR."}
{"label": "Parallel sentences were first word-aligned using a MaxEnt aligner #REFR.", "predict": "The English side of the two corpora were word aligned using a maximum entropy alignment model #REFR, which was trained on a bilingual corpus of 1.5M sentence pairs."}
{"label": "Identification of semantically similar situations can be improved by the use of segmentmatching algorithms as employed in Example- Based MT and translation memories #REFR.", "predict": "In the future we also plan to develop a methodology for extending the semantic similarity matching algorithm proposed in #REFR to bilingual texts."}
{"label": "Others have exploited the automatic transfer of some already existing annotated resource in a different medium or language (such as the translingual projection of part-of-speech tags, syntactic bracketing and inflectional morphology in #REFR, requiring no direct supervision in the foreign language).", "predict": "Others have defined minimal in terms of the amount of hand-labeled training data required for a given level of accuracy #OTHEREFR; #REFR."}
{"label": "Recent work has shown how paraphrases can improve question answering through query expansion #OTHEREFR, automatic evaluation of translation and summarization by modeling alternative lexicalization #REFR, and machine translation both by dealing with out of vocabulary words and phrases #OTHEREFR.", "predict": "Examples include machine translation #OTHEREFR; #REFR."}
{"label": "Currently, the performance of even the most simple direct transfer systems far exceeds that of unsupervised systems #OTHEREFR; #REFR. ", "predict": "For a recent survey of transfer methods see #REFR. "}
{"label": "For our Chinese to English translation experiments, we generated word alignments using the Berkeley Aligner #REFR with default settings.", "predict": "The word alignments were generated using the Berkeley Aligner #REFR."}
{"label": "ORIG with fixed hyperparameters performs best, with the highest VM score (a clustering measure, #REFR) and a level of segmentation close to the correct one.", "predict": "DP-UNI, when fixed, finds a relatively small number of types and achieves a low entropy #REFR."}
{"label": "Conditional random fields #OTHEREFR are quite effective at sequence labeling tasks like shallow parsing #REFR and namedentity extraction #OTHEREFR.", "predict": "Conditional random fields #OTHEREFR are quite effective at sequence labeling tasks like shallow parsing #REFR and namedentity extraction #OTHEREFR."}
{"label": "State-of-art approaches to frame-based SRL are based on Support Vector Machines, trained over linear models of syntactic features, e.g. #REFRb), or tree-kernels, e.g. #OTHEREFR.", "predict": "In the last years, many approaches have been proposed to solve the semantic role labeling problem #OTHEREFR; #REFR."}
{"label": "This would also include more semantic information, e.g., in the form of Brown clusters or using semantic similarity between the words composing the structure calculated with latent semantic analysis #REFRb).", "predict": "We will explore the use of other tree-based kernels #REFR and different types of tree structures #OTHEREFR."}
{"label": "Following #REFR, we use the default parameters (? = 0.1 and ?0 = 1.0) for HDP.1 For each target word, we apply HDP to induce the senses, and a distribution of senses is produced for each ?document? in the model.", "predict": "We use the HDP model of #REFR to induce the senses of the verb strike."}
{"label": "Some of these needs can be addressed by emerging technologies for temporal analysis #OTHEREFR; #REFR.", "predict": "Most prior work in temporal analysis has focused on the identification of temporal relations between events #OTHEREFR; #REFR."}
{"label": "Our work joins others in using continuous representations to express the meaning of words and phrases #REFR and how these may be combined in a language modeling context #OTHEREFR.", "predict": "Recurrent neural networks have been used for a variety of tasks in NLP, including sentiment analysis #REFR, syntactic parsing #OTHEREFR."}
{"label": "5The meaning of the word \"synchronized\" here is exactly the same as in STAG #REFR.", "predict": "5The notion of \"synchronization\" is used in synchronous grammar #REFR, which is a kind of bidirectional grammar #OTHEREFR, to define the relationship between two CFGs."}
{"label": "A Data-Oriented Parsing model #OTHEREFR; #REFR, 1993a) is characterized by a corpus of analyzed language utterances, together with a set of operations that combine sub-analyses from the corpus into new analyses.", "predict": "The statistical dimension of DOP #REFR can be characterized by the following parameters: the number of trees in the corpus, the number of features, and the number of trees that are used for training."}
{"label": "Transition-based dependency parsing can be modeled under this framework, where the state consists of a stack and a queue, and the set of actions can be either the arc-eager #REFR or the arc-standard #OTHEREFR transition systems.", "predict": "This framework has been successfully applied to dependency parsing #OTHEREFR; #REFR."}
{"label": "Phrase-based SMT models, such as the alignment template model #REFR, improve on word-based models because phrases provide local context which leads to better lexical choice and more reliable local reordering.", "predict": "Later, the phrase-based approach #REFR was proposed to further improve performance by extracting phrase pairs from word alignments."}
{"label": "Similar work has also been performed in the area of query expansion using training data consisting of FAQ pages #OTHEREFR or queries and clicked snippets from query logs #REFR.", "predict": "#REFR used pairs of user queries and snippets of clicked results."}
{"label": "Many approaches have been devised, including the identification of domain-specific predominant senses #OTHEREFR; #REFR, the development of domain resources #OTHEREFR.", "predict": "In fact, since the introduction of a domain corpus for WSD #OTHEREFR, a variety of approaches have been proposed which make use of domain information for domain WSD #REFR."}
{"label": "#REFR described a WSD method and an implementation based on Roget' s Thesaurus and the training material of the 10-rnillion-word Grolier' s Encyclopedia.", "predict": "#REFR proposed a method for selecting the most likely sense from a MRD using a Bayesian model of Roget is Thesaurus categories."}
{"label": "Deep and accurate text analysis based on discriminative models is not yet efficient enough as a component of real-time applications, and it is inadequate to process Web-scale corpora for knowledge acquisition #OTHEREFR or semi-supervised learning #REFR.", "predict": "Recent studies have shown that state-of-the-art accuracy is obtained for various natural language processing #OTHEREFR; #REFR."}
{"label": "We have extended non-projective unlabeled dependency parsing #REFR to a very simple non-projective labeled dependency and showed that the parser performs reasonably well with small number of features and just one iteration of training.", "predict": "We have applied a voted perceptron learning algorithm #REFR to the problem of non-projective labeled dependency parsing."}
{"label": "There has been much recent work in attempting to convert native parser output into alternative representations for evaluation purposes, e.g. #OTHEREFR; #REFR.", "predict": "#REFR converted the output of the HPSG parser of Ratnaparkhi #OTHEREFR into the shallow CFG representation of the PTB."}
{"label": "Recently, #REFR has reported a word accuracy of 92.6% for Dutch, using a `lazy' training strategy on data aligned with the correct phoneme string, and a hand-crafted system that relied on a large set of rule templates and a many-to-one mapping of characters to graphemes preceding the actual g2p conversion.", "predict": "Our system outperforms the best English system, which achieves 70.4% #REFR."}
{"label": "Previous research has shown that RST trees can play a crucial role in building natural language generation systems #OTHEREFR and text summarization systems #REFR; can be used to increase the naturalness of machine translation outputs #OTHEREFR.", "predict": "We have seen in previous work #OTHEREFR; #REFR that RST trees can be used to model the discourse structure of texts in a variety of domains."}
{"label": "These same features also proved crucial to subsequent approaches, e.g. #REFR.", "predict": "These include features from both syntactic and semantic analysis #REFR."}
{"label": "For this reason, we compute an unweighted entity-constrained mention F-measure #REFR and report all contrastive experiments with this metric.", "predict": "The Entity- Alignment F-measure (CEAF) #REFR is an alternative metric that is better suited for pronoun resolution."}
{"label": "After the error miner identifies afwater as a problematic word, we employ our machine learning based LA method presented in #REFR to learn new entries for this word.", "predict": "We use the automatic lexical acquisition technique proposed in #REFR for the task of acquiring lexical entries for afwater."}
{"label": "To further assure the quality of the annotation, a series of automatic tests was performed and used as the basis of a further manual round of revision.4 Annotation guidelines were initially created based on those created by our previous domain-specific effort #REFRa) and revised throughout the annotation effort to document specific decisions made during annotation.", "predict": "Following the initial annotation, the primary annotator performed a self-verification round to resolve ambiguities, and the corpus was then independently annotated by two annotators to assess annotation consistency #REFR."}
{"label": "These User Simulations are now commonly used in statistical learning approaches to dialogue management #OTHEREFR; #REFR, but they have not been used for context-sensitive ASR before.", "predict": "This idea is inspired by previous work in statistical User Simulation for dialogue systems #REFR."}
{"label": "Other work has shown that co-occurrence of words #OTHEREFR and discourse relations #REFR also predict coherence.", "predict": "Methods which focus on the content of discourse capture intentional structure #REFR."}
{"label": "It is a well-documented fact #REFR that subcategorisation frames (and their frequencies) vary across domains.", "predict": "Firstly, COMLEX is a much larger lexicon than our induced lexicon (see Section 4.3.2), and consequently, it is more likely to contain more specific frames, especially in the case of directional prepositions which tend to be very specific in their usage #REFR."}
{"label": "In this paper we focus on recurrent neural network architectures, which have recently advanced the state of the art in language modeling #OTHEREFR; #REFR, outperforming multi-layer feed-forward based networks in both perplexity and word error rate in speech recognition #OTHEREFR.", "predict": "This includes recurrent neural network-based language models #OTHEREFR; #REFR, and translation models #OTHEREFR."}
{"label": "As our approach for incorporating unlabeled data, we basically follow the idea proposed in #REFR.", "predict": "CRFs are a representative and successful approach for SSL #REFR."}
{"label": "We extended the unsupervised corpus-extracted phrase approximation method of Guevara #OTHEREFR and #REFR to estimate all known state-of-the-art cDSMs, using closedform solutions or simple iterative procedures in all cases.", "predict": "We proposed a framework for evaluating compositional distributional semantic models (cDSMs) that extend distributional models of words to models of phrases and sentences #REFR."}
{"label": "The paradigm of translation for monolinguals introduced by Kay in 1973 #OTHEREFR; #REFR).", "predict": "For instance, #REFR introduced a keyboard interface to machine translation, whereby a technical author could interactively compose a target-language document."}
{"label": "The projected trees can be used to answer linguistic questions such as word order #REFR or bootstrap parsers #OTHEREFR.", "predict": "#REFR have used this method to build individual CFGs for approximately 100 languages."}
{"label": "We evaluated our system using the standard evaluation script provided by the organizers #REFR.", "predict": "We used the CoNLL-2007 evaluation scripts #REFR to evaluate the performance of our system."}
{"label": "Second, we prune the phrase-table using a statistical significance test to measure #REFR.", "predict": "A more interesting finding is that using the phrase table with a 50-phrase candidate per source phrase, instead of the 20-phrase candidate per source phrase, decreases CLWSD performance by 1.6 F1 points (p = 0.01) and decreases PBSMT BLEU score by 0.04 points (p = 0.0002), a decrease that is in line with results obtained with the Moses phrase table pruning heuristic #REFR."}
{"label": "To this end, patternbased approaches have long been used to induce type systems #REFR.", "predict": "The closest work to ours is #REFR, which uses patterns to find lexical relations (hyponyms) and applies them to thesauri."}
{"label": "They include such topics as: work with various corpus manipulation and annotation tools, use of various POS taggers and their comparison #REFR, development of morphophonological rules in PC-Kimmo #OTHEREFR.", "predict": "In addition to these assignments, students are encouraged to read papers in the area of NLP and related fields, and to write up their own research papers #REFR."}
{"label": "First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity #OTHEREFR; #REFR.", "predict": "First, while sentiment analysis is a popular application of subjectivity analysis, the distinction between subjective and objective content is often more important than polarity classification #OTHEREFR; #REFR."}
{"label": "Compared to graph-based dependency parsing, it typically offers linear time complexity and the comparative freedom to define non-local features, as exemplified by the comparison between MaltParser and MSTParser #OTHEREFR; #REFR.", "predict": "This approach is appealing because it is simple, efficient, and can easily incorporate a large variety of features #REFR."}
{"label": "Unbalanced corpora are common in a number of different tasks, such as emotion detection #OTHEREFR; #REFR, text classification #OTHEREFR, and so on1.", "predict": "Unbalanced corpora occur frequently in natural language processing #OTHEREFR; #REFR."}
{"label": "Metrics in the Rouge family allow for skip n-grams #OTHEREFRa); #REFR take paraphrasing into account; metrics such as METEOR #OTHEREFR in that word class information is used.", "predict": "One of the most popular variations is to use the n-gram precision of the reference sentence against a paraphrase of the reference sentence #REFR."}
{"label": "Therefore, recent efforts #REFR have concentrated on feature design ? wherein more intelligent features may be added.", "predict": "The same framework is also used in many studies #OTHEREFR; #REFR."}
{"label": "#REFR report better results than ours on Portuguese, Slovene, Spanish and Swedish, but worse on Danish.", "predict": "For the languages for which this model was trained, it is clearly the best performing model (11/12).10 10#REFR report that their model obtains the best results on 10/12 languages."}
{"label": "We used three aligners in this work: GIZA++ #OTHEREFR, jointly trained HMM #REFR, and ITG #OTHEREFR.", "predict": "We used three word aligners in this study: GIZA++ #OTHEREFR, HMM #REFR and ITG #OTHEREFR."}
{"label": "#REFR propose a solution to this problem: for each token, they define additional features based on known information, taken from other occurrences of the same token in the document.", "predict": "#REFR proposed a Maximum Entropy #OTHEREFR."}
{"label": "Among the current similar works, Table 4 shows that our system outperforms Chen#OTHEREFR in VV compounds, and approximates the #REFR in NN compounds.", "predict": "However, we believe that the present model, with the ontology-based semantic class prediction strategy and the morphological knowledge base built upon a character ontology, is an important step toward the task of Chinese compound word semantic prediction #REFR."}
{"label": "A similar modification was used by #REFR for the study of dependency parsing models.", "predict": "This is the same approach as in #REFR."}
{"label": "In both cases, transfer is driven by the transfer module developed and implemented by #REFRa).", "predict": "The two approaches are interfaced with an existing transfer component #REFR, by translating f-structures into a term language, and by interfacing fstructure representations with an existing semantic based transfer approach, respectively."}
{"label": "Such text data tend to be long and generate enough context for the target task #OTHEREFR; #REFR.", "predict": "The extracted attributes are then used for sentiment analysis #OTHEREFR, and comparison and recommendation #REFR."}
{"label": "In a related recent approach, #REFR presented preliminary results from automatically generating related work sections for a target paper by taking a hierarchical topic tree as an input; however, the requirement of a pre-conceived topic tree limits the scalability of this system.", "predict": "A related work summarization system #REFR attempted to extract sentences that best describe the relationships between a paper and its related work."}
{"label": "Although it has been shown that increasing the amount of training data for SMT improves results #REFR, not all data is beneficial, and clean data is best of all.", "predict": "Some examples of data cleaning are: converting all characters to lower case, normalizing abbreviations and contractions, normalizing punctuation, removing stop words, and cleaning up punctuation and whitespace, as described in #REFR."}
{"label": "We first extracted named entities using a Twitter-tuned NER system #REFR from millions of tweets, which we collected over a one-year period spanning from January 2012 to January 2013; we used the public streaming Twitter API to download tweets.", "predict": "We selected topics that are frequently discussed on Twitter and for which we have access to opinionated data, such as movies, celebrities, and TV shows #OTHEREFR; #REFR."}
{"label": "Past studies of combining alternative alignments focused on minimizing alignment errors, usually by merging alternative alignments for a sentence pair into a single alignment with the fewest number of incorrect alignment links #REFR.", "predict": "First, previous work mainly focuses on improving word alignment quality #OTHEREFR; #REFR."}
{"label": "#REFR presented a statistical system that automatically produces an analysis of the rhetorical structure that holds between sets of sentences or clauses at the paragraph level.", "predict": "Discourse segmentation, the process of identifying discourse units such as sentences, paragraphs and sections, has been studied in #REFR, and discourse parsing, the process of assigning syntactic and semantic relations to discourse units, has been studied in #OTHEREFR."}
{"label": "We employ the features of noun terms, and sentiment terms in the sentiment lexicon provided by MPQA project #REFR.", "predict": "The polarity of the opinions in the reviews is extracted by applying a sentiment analyzer #REFR."}
{"label": "A translation model consists of two distinct elements: an unweighted ruleset, and a parameterization #REFR.", "predict": "In this section we review the basic definitions of phrase-based translation #OTHEREFR, and we use these definitions to define the search space of the Hiero model #REFR."}
{"label": "We are inspired by multiple sequence alignment methods in computational biology #OTHEREFR and by #REFR, who described a hidden Markov model (HMM) for document content where each state corresponds to a distinct topic and generates sentences relevant to that topic according to a language model.", "predict": "In this paper, we propose a probabilistic model that can be used to align sections of privacy policies, building on our previous work on document modeling #REFR."}
{"label": "Unlike other languages #REFR, Chinese UNK translation cannot use information from stem and inflection analysis.", "predict": "A few researchers proposed methods for translating unknown words for Chinese-to-English SMT #OTHEREFR; #REFR."}
{"label": "For this paper, we consider tree-shaped hierarchies so that tree kernels, e.g. #OTHEREFR; #REFRa), can be applied.", "predict": "In particular, we consider the tree kernel proposed by #REFR."}
{"label": "We follow the same approach as in #REFR to build our SWSD system.", "predict": "We train SWSD classifiers using the same dataset as in #REFR."}
{"label": "The dataset is the same as in leading works #REFR.", "predict": "We followed the same setting as in #REFR, and used 70% of the training data for training and the remaining 30% for tuning."}
{"label": "Part of the work using this tool was described by #REFR.", "predict": "Achilles is a CRF-based word segmentation tool and it is available from the website of #REFR."}
{"label": "However, the performance of context vectors drastically decreases for lower frequency terms #REFR.", "predict": "Recent work in term alignment includes supervised approaches #OTHEREFR, unsupervised approaches #REFR, semi-supervised approaches #OTHEREFR."}
{"label": "#REFR explored strategies for selecting better random ?restart points? in optimization.", "predict": "#REFR explored random restarts for MERT, and showed that these were more reliable than averaging results from multiple runs."}
{"label": "The Grammar Matrix customization system #REFR presents the linguist-user with a typological questionnaire which elicits information about the language to be described.", "predict": "Grammar Matrix #REFR is a system for building grammar libraries in a language-independent way."}
{"label": "The model is called Transfer- Driven Machine Translation (TDMT) #REFR (see subsection 2.1 for details).", "predict": "This model, TDMT (Transfer-Driven Machine Translation) #REFR, translates a sentence utilizing examples effectively and performs accurate structural disambiguation and target word selection."}
{"label": "These modifications, however, give a system which suffers 2See, for example, the formalisms developed in #OTHEREFR, #REFR. the problem of woulderivational equivalence', also called ispurious ambiguity', i.e. allowing multiple proofs which assign the same reading for some combination, a fact which threatens processing efficiency.", "predict": "This approach has the problem of ispurious ambiguity', in the sense that a single deduction may be appropriate to more than one syntactic context (see #REFR."}
{"label": "On the other hand, #REFR proposed a resolving algorithm for Japanese exophoric ellipses of written texts, utilizing semantic and pragmatic onstraints.", "predict": "#REFR used only the semantic constraints and a few pragmatic ones, and they used a set of 175 successive sentences to investigate the effectiveness of the proposed method."}
{"label": "Cutting introduced grouping of words into equiva.lence classes based on the set of possible tags to reduce the number of the parameters #REFR .", "predict": "Equivalence classes have been used by #REFR, Schmid #OTHEREFR."}
{"label": "#REFR proposed several approaches for cross lingual subjectivity analysis by directly applying the translations of opinion corpus in source language to train the opinion classifier on target language.", "predict": "For example, #REFR translated the annotated corpora from source language to target language by machine translation systems and used them as the training data for target language."}
{"label": "#REFR evaluate various similarity measures based on 1000 frequent and 1000 infrequent target terms.", "predict": "#REFR also used WordNet as a gold standard thesaurus."}
{"label": "This was the setting obtaining the best results in a word similarity dataset as reported by #REFRb).", "predict": "For more details, see #REFR."}
{"label": "In the last 4-5 years, researchers have begun to introduce compositional operations on distributional semantic representations, for instance to combine verbs with their arguments or adjectives with nouns #OTHEREFR; #REFR1.", "predict": "One strategy for modeling composition in distributional semantic models has been to assume a vector space model for meaning #OTHEREFR; #REFR, and to propose a set of operations to combine these vectors, including matrix multiplication, addition, and intersection."}
{"label": "MERT is the standard technique for obtaining a machine translation model fit to a specific evaluation metric #REFR.", "predict": "Typically, MT models are trained to optimize a standard log-linear parameterized model #REFR with respect to a minimum error rate training #OTHEREFR."}
{"label": "Pseudo-word evaluations are currently used to evaluate a variety of language modeling tasks #OTHEREFR; #REFR.", "predict": "Pseudo-words have been used for selectional preferences in a variety of ways #OTHEREFR; #REFR."}
{"label": "Statistical machine learning methods such as hidden Markov models #OTHEREFR; #REFR have become popular approaches to address the text extraction problem.", "predict": "Machine learning approaches have been shown to be effective in IE #OTHEREFR; #REFR."}
{"label": "The advantage of using POS tags rather than words is that their probabilities can be estimated much more accurately and, consequently, more accurate prediction of wordreading time is possible #OTHEREFR; #REFR.", "predict": "These models were used to estimate the probability of each sentence?s next word given the sentence?s preceding words, following the methods described in #REFR."}
{"label": "The second line of research uses comparable or bilingual corpora as the ?pivot? that binds paraphrases together #OTHEREFR; #REFR.", "predict": "Another approach to paraphrase generation is to harvest paraphrases from parallel corpora #OTHEREFR; #REFR."}
{"label": "These rules can be designed manually #OTHEREFR; #REFR.", "predict": "Examples of this approach are the reordering rules used by the XLE toolkit #OTHEREFR, the manually curated rules used by the MMT system #REFR, and the automatically learned rules used by the MRT system #OTHEREFR."}
{"label": "#REFR adapt the technique of supertagging #OTHEREFR to CCG, using a standard maximum entropy tagger to assign small sets of supertags to each word.", "predict": "The CCG parser uses a supertagger to assign supertags to the words in a sentence, and a parser to derive a CCG analysis for the sentence #REFR."}
{"label": "It also exploits the classification given by the COMLEX lexicon #REFR in order to calculate the deep-subject of infinitive verbs.", "predict": "Some deep syntactic rules have been developed to account for some of the ambiguities observed in the syntactic representations.2 These rules are inspired by the Levin rule set and have been manually tuned to improve the precision of the normalizer (see #REFR for a similar approach)."}
{"label": "Recently, studies have explored dialog act tagging in written interactions such as emails #OTHEREFR; #REFRb), instant messaging #OTHEREFR.", "predict": "Recent work has also focused on modeling written dialogues #OTHEREFR; #REFR."}
{"label": "A number of relation extraction kernels have been proposed, including dependency tree kernels #OTHEREFR; #REFR.", "predict": "Several kernel functions were proposed for relation extraction #OTHEREFR; #REFR."}
{"label": "For one, it allows a tight correspondence between syntax and semantics by letting constituent structure express argument structure #REFR.", "predict": "For instance, the Negra project #REFR, an annotation scheme for German, introduces discontinuity in the constituency annotations in order to provide an adequate formalism for syntactic analysis."}
{"label": "Recently, there have been two promising research directions for improving SMT and its evaluation: #OTHEREFR, and (b) by going beyond the sentence-level, e.g., translating at the document level #REFR.", "predict": "A number of recent approaches try to go beyond the sentence-level, either by using discourse information #OTHEREFR; #REFR, or by modeling longer range dependencies through lexicalized reordering #OTHEREFR."}
{"label": "The k?means algorithm is used for clustering the contexts, where the number of clusters is automatically discovered using the Adapted Gap Statistic #REFR.", "predict": "The number of clusters for each target word was discovered using the Gap Statistic #OTHEREFR; #REFRb)."}
{"label": "One type of approach uses information extraction techniques such as pattern matching that use strong predictions on the content and attempt to fill templates derived from a model of the domain (e.g. #REFR), thus not giving too much importance to syntactic structure.", "predict": "For example, in #REFR, a pattern-based approach is followed to analyze the content of documents and to recognize well-formed phrases that can be extracted as argument values."}
{"label": "The mapping from a word alignment to the set of licensed phrase pairs pi(a) is based on the standard rule extraction procedures used in most modern statistical systems #REFR, but extended to handle possible links #OTHEREFR.", "predict": "Following #REFR, we define the projection function pi(a) for each phrase pair a in the training data."}
{"label": "Word alignment and tokenization can also be optimized by maximizing the likelihood of bilingual corpus #REFR.", "predict": "Similarly, some work try to determine the optimal number of words for a given word alignment #OTHEREFR; #REFR."}
{"label": "It is also interesting to note that the best result on the validation set for estimation 4We measured significance of all the experiments in this paper with the randomized significance test #REFR. of the loss with data-defined kernels (12) and (13) was achieved when the parameter A is close to the inverse of the first component of the learned decision vector, which confirms the motivation for these kernels.", "predict": "Statistical significance testing using the permutation test #REFR was performed on the test data for all the reranking models."}
{"label": "The binarization method used by #REFR can cover many non-constituent rules also, but not all of them.", "predict": "#REFR pointed out that this technique does not work well when the phrase of interest is not a constituent."}
{"label": "In contrast, approaches to WSD attempt o take advantage of many different sources of information #OTHEREFR); it seems possible to obtain benefit from sources ranging from local collocational clues #REFR to membership in semantically or topically related word classes #OTHEREFR; and disambignation seems highly lexically sensitive, in effect requiring specialized isamhignators for each polysemous word.", "predict": "The most recent studies #OTHEREFR; #REFR use the Brown corpus."}
{"label": "One option would be to leverage unannotated text #OTHEREFR; #REFR.", "predict": "For example, we can use unlabeled target-language text, and bootstrap a parser using entropy regularization #REFR."}
{"label": "Initially all sentences are pre-processed by the CoreNLP #OTHEREFR; #REFR suite of tools, a process that includes named entity recognition, normalization, part of speech tagging, lemmatization and stemming.", "predict": "The input sentences were tokenized and POS-tagged using the Stanford Tagger #REFR."}
{"label": "Our data source is the German NeGra treebank #REFR.", "predict": "The NeGra treebank #REFR is a German treebank annotated with dependency structure and morphological information."}
{"label": "Automatic detection of such argument alternations is important to acquisition of verb lexical semantics #REFR, and moreover, may play a role in automatic processing of language for applied tasks, such as question-answering #OTHEREFR.", "predict": "We have previously shown that this sort of semantic alternation can be automatically detected using a combination of lexical and semantic resources #REFR."}
{"label": "Only for the Machine Translation task, #REFR report several results using different Arabic segmentation schemes.", "predict": "They used a tokenization scheme based on the Stanford NLP tools #REFR."}
{"label": "Next, other research efforts utilized the three categories into which various types of subordinate clauses are hierarchically classified based on the ?scope-embedding preference? of Japanese subordinate clauses #OTHEREFR; #REFR.", "predict": "Other studies have focused attention on subordinate clauses #OTHEREFR; #REFR."}
{"label": "This is because in citations, the discussion of the paper cited is usually mixed with the content of the paper citing it, and sometimes also with discussion about other papers cited #REFR.", "predict": "This is different from previous work on citation extraction #OTHEREFR; #REFR."}
{"label": "The work of #OTHEREFR; #REFR focuses on manually constructing several lexica and rules for both polar words and related content-word negators, such as ?prevent cancer?, where prevent reverses the negative polarity of cancer.", "predict": "Their approach learns a compositional model for sentiment analysis #REFR."}
{"label": "An appealing alternative to a similar approximation to the above would use loopy belief propagation to efficiently approximate the marginals #REFR.", "predict": "We can approximate such marginals using loopy belief propagation #OTHEREFR; #REFR."}
{"label": "Finally, a few efforts #OTHEREFR; #REFR have tried to translate sentences into formulas of first-order logic, in order to test logical entailment with a theorem prover.", "predict": "The logical inference approach of #REFR uses a combination of shallow word overlap and logical inference to recognize textual entailment."}
{"label": "Therefore, we prepare single bilingual signs for expressing their truth conditions if at least one of the languages has lexical items \\[#REFR\\].", "predict": "We then assume that there are classes of linguistic objects whose properties can be captured by a single predicate in logical forms (see \\[#REFR\\])."}
{"label": "#REFR use shift-reduce parsing to impose ITG #OTHEREFR constraints on phrase permutation.", "predict": "#REFR present a shift-reduce algorithm for inversiontransduction grammar constraints in decoding."}
{"label": "Similar tagsets are used by other studies on grammar induction and projection #REFR.", "predict": "These universal tags have been shown to be useful for unsupervised dependency parsing #REFR."}
{"label": "A variety of features have been explored for ERD in previous research #OTHEREFR; #REFR.", "predict": "The work of #REFR shows that simple features can be as good as complex ones."}
{"label": "However, it is fair to compare our work against other approaches which have attempted to disambiguate all content words in a text against some standard lexical resource, such as #REFR, #OTHEREFR.", "predict": "#REFR and Veronis & Ide #OTHEREFR used the same dictionary (LDOCE) and evaluated on the same corpus (Wall Street Journal), but with different methods."}
{"label": "This feature set is very close to that used in #REFR, but not identical.", "predict": "The feature templates used by #REFR are similar."}
{"label": "The inside weight w i and the outside weight w o in the active items deserve more attention since this is the only difference compared to #REFR.", "predict": "#REFRb) defines a data structure called item which maintains a list of constituents for a given category."}
{"label": "Various recent attempts have been made to include non-local features into graph-based dependency parsing #REFR.", "predict": "Early transition-based parsers such as MaltParser #OTHEREFR; #REFR."}
{"label": "This feature set is reminiscent of the featurized representation of #REFR.", "predict": "We chose these classes based on previous work #REFR, which found that they were the most informative for reconstructing Proto-Oceanic word forms."}
{"label": "For example, a popular approach to reduce annotation effort is bootstrapping from seed examples #OTHEREFR; #REFR.", "predict": "For example, bootstrapping #OTHEREFR; #REFR and unsupervised learning #OTHEREFR."}
{"label": "These efforts have been met with some success in evaluations such as phrase similarity tasks #OTHEREFR; #REFR, sentiment prediction #OTHEREFR.", "predict": "Examples of such models include the work of Clark and Curran #OTHEREFR, #REFR, Pado? and Lapata #OTHEREFR."}
{"label": "Our use of an LSVM to assign credit during joint training differs substantially from previous LSVM applications, which have induced latent linguistic structures #OTHEREFR or sentence labels #REFR.", "predict": "The latent variable formulation is related to joint inference in structured prediction #OTHEREFR; #REFR, but our approach is the first to apply it to arc filtering."}
{"label": "The two most popular algorithms are McDonald?s MST- Parser #REFR and Nivre?s Malt- Parser #OTHEREFR.", "predict": "The MST Parser uses the MST- Parser #REFR, while the Stanford Parser uses Malt- Parser #OTHEREFR."}
{"label": "#REFR developed a method in which they first identify (by means of affixes rules) a set of positive/negative words which act as seeds, then used a Roget-like thesaurus to mark the synonymous words for each polarity type and to generalize from the seeds.", "predict": "#REFR extended the previous work by introducing an algorithm that also considers multi-word expressions."}
{"label": "We follow the candidate-ranking model proposed by #REFR.", "predict": "In this work, we use the candidate-ranking model of #REFR."}
{"label": "Recent randomized language models #REFR make use of Bloom filter like structures to map n-grams to their associated probabilities or counts.", "predict": "Several recent papers have presented new data structures for storing very large n-gram language models #OTHEREFR; #REFR."}
{"label": "#REFR introduced the concept of lexical weighting to check how well words of the phrase translate to each other.", "predict": "Following the lexicalized translation model #REFR, the lexical translation probability p(e|f) is estimated by the number of times that a target word e is aligned to a source word f divided by the total number of times that f is aligned to any word."}
{"label": "Much work has been done on automatic Arabic diacritization #OTHEREFR; #REFR.", "predict": "Therefore, the Arabic lexical resource #REFRb) provides the necessary information to determine Hamzat-Wasl through morphologically tagging the definite article."}
{"label": "This kind of supervision is similar to the seeding in bootstrapping literature #OTHEREFR or prototype-based learning #REFR.", "predict": "Our model uses these seed words to improve both topic-word distributions (by biasing topics to produce appropriate seed words) and to improve document-topic distributions (by biasing documents to select topics related to the seed words they contain).2 This is in contrast to other approaches to adding supervision to topic models, such as the semi-supervised approaches of #OTHEREFR; #REFR, which do not provide seed words."}
{"label": "In our system, the well-known forward maximum matching algorithm #REFR is implemented.", "predict": "This approach was used by #REFR and #OTHEREFR."}
{"label": "The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text #OTHEREFR; #REFR.", "predict": "The word-level sentiment annotation focuses on sentiment annotation on words with concern that atomic units of expression is individual words #REFR."}
{"label": "This alignment matrix contains scores for all word correspondences in the sentence pair and can be created using GIZA++ #OTHEREFR or the Berkeley aligner #REFR.", "predict": "The phrase alignments are generated by a word alignment model #REFR."}
{"label": "It has already been proposed for phrase-based #OTHEREFR, hierarchical #REFR, and syntax-based #OTHEREFR systems.", "predict": "On the other hand, our approach is very similar to phrase-based SMT systems that employ on-the-fly rule extraction #OTHEREFR; #REFR."}
{"label": "Class-based approaches #OTHEREFR and #REFR are more promising: the implied clustering also tackles the data sparseness difficulties, but mainly they produce selectional constraints hat have a direct semantic interpretation.", "predict": "The use of the Wordnet taxonomy as reference information is in contrast with the use of a statistical method, like Maximum Entropy Models #OTHEREFR or Support Vector Machines #REFR, which need to train the models on a set of tagged examples."}
{"label": "In contrast, #REFR show that parser agreement is a strong indicator of parse quality, and in parser domain adaptation, Sagae and Tsujii #OTHEREFR use agreement between parsers to choose which automatically parsed target domain items to add to the training set.", "predict": "Similar ideas have been discussed by #REFR."}
{"label": "For comparison, we also include results for a setting that only uses word forms (Forms), which was the baseline for previous work on French dependency parsing #REFRb).", "predict": "Scores are calculated using the MaltParser toolkit #REFR."}
{"label": "In recent years discriminative probabilistic models have been successfully applied to a number of information extraction tasks in natural language processing #OTHEREFR, noun phrase chunking #REFR and information extraction from research papers #OTHEREFR.", "predict": "Recent work on named entity recognition #OTHEREFR; #REFR."}
{"label": "These records are also known as field books and reference sets in literature #REFR.", "predict": "#REFR and Agichtein and Riloff #OTHEREFR present approaches that learn to extract information from database records."}
{"label": "That parsing model has since been extended to make unsupervised learning more feasible #OTHEREFR; #REFRb).", "predict": "Later, methods such as expectation maximization #OTHEREFR; #REFR."}
{"label": "This is also the task addressed by other WSD research such as #OTHEREFR; #REFR.", "predict": "There have been several attempts at automatic word sense disambiguation #OTHEREFR; #REFR."}
{"label": "Statistical data about these various cooccurrence r lations is employed for a variety of applications, uch as speech recognition #OTHEREFR; #REFR.", "predict": "Such cooccurrence data are used in various applications, including word sense disambiguation #OTHEREFR, it-antecedent resolution #REFR, parsing #OTHEREFR."}
{"label": "He has achieved state-of-the art results by applying M.E. to parsing #OTHEREFR, and sentence-boundary detection #REFR.", "predict": "There he has applied M.E. to the tasks of part-of-speech tagging #OTHEREFR, sentence boundary detection #REFR, and word sense disambiguation #OTHEREFR."}
{"label": "Among the machine learning algorithms studied, rule based systems have proven effective on many natural language processing tasks, including part-of-speech tagging #OTHEREFR, message understanding #REFR, discourse tagging #OTHEREFR.", "predict": "This is especially true of rule based systems, which have proven to be quite effective at extracting linguistic knowledge #OTHEREFR; #REFR."}
{"label": "Rather than relying on volunteers or gamification, NLP research into crowdsourcing translation has focused on hiring workers on the Amazon Mechanical Turk (MTurk) platform #REFR.", "predict": "Mechanical Turk has been used to translate large volumes of data #OTHEREFR; #REFR."}
{"label": "Other researchers #OTHEREFR; #REFR have reported performance gains in translation by allowing deviations from monotone word and phrase order.", "predict": "A similar approach is taken by #REFR, in which reordering is governed by a set of constraints (ITG) that are not explicitly modeled."}
{"label": "In addition, timeline summarization techniques #OTHEREFR and some event-event ordering models #REFR also rely on the timestamps.", "predict": "In addition, some temporal summarization algorithms, such as #REFR, can use timestamps for summarizing documents."}
{"label": "For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance #REFR.", "predict": "Memorization features #OTHEREFR; #REFR are the most prevalent of these."}
{"label": "Experiments have been made on the automatic acquisition of subcategorization frames since mid 1990s #OTHEREFR; #REFR.", "predict": "This work is part of the ongoing research on automatic acquisition of subcategorization frames (SCFs) for verbs from corpora #REFR."}
{"label": "Fortunately, there is a growing body of work on genre-based text classification, including #OTHEREFR; #REFR.", "predict": "This is the focus of recent work by many researchers #OTHEREFR; #REFR."}
{"label": "This assumption, or its minor relaxations, is relatively standard in work on unsupervised semantic parsing tasks #REFR.", "predict": "An interesting direction for future work would be to relax this assumption and allow for multiple frames per verb, as in #REFR."}
{"label": "Other research has introduced the notion of identifying concepts in the input text #REFR, using a set cover algorithm to attempt to include as many concepts as possible.", "predict": "#REFR propose an algorithm for identifying redundant text that first maps sentences to a two-dimensional space of words and atomic concepts, then uses a set cover approximation algorithm to remove redundant text."}
{"label": "Early work on automatically inducing semantic relations between words, starting with #REFR, uses textual patterns.", "predict": "One of the earliest approaches #REFR used simple syntactic patterns to indicate the presence of semantic relations."}
{"label": "Experiments in both #OTHEREFR and #REFR find no conclusive winner among early fusion, additive late fusion, and multiplicative late fusion.", "predict": "#REFR use late fusion for speech transcription and language modeling."}
{"label": "First, as in #REFR, we stipulate that some attributes of entities are more important than others, and that some words more naturally describe those attributes.", "predict": "First, we use a more general representation of the semantics of events and states, and incorporate into this representation the kinds of knowledge about events and states that are normally represented in a discourse model (e.g., #REFR)."}
{"label": "Active learning has been shown, for a number of different NLP tasks, to reduce the number of manually annotated instances needed for obtaining a consistent classifier performance #OTHEREFR; #REFR.", "predict": "Since its inception #OTHEREFR; #REFR."}
{"label": "Therefore, SVMs have shown good performance for text categorization #OTHEREFR, chunking #REFR, and dependency structure analysis #OTHEREFR.", "predict": "We have applied SVMs to various NLP tasks #REFR."}
{"label": "First, we briefly introduce our method for constructing NCFs from raw corpora proposed in #REFR.", "predict": "To construct NCFs, we first conduct a semantic analysis of each noun using the dictionary of the MeCab morphological analyzer #REFR."}
{"label": "Traditionally, broad coverage has always been considered to be a desirable property of a grammar: the more linguistic phenomena are treated properly by the grammar, the better results can be expected when applying it to unrestricted text #OTHEREFR; #REFR).", "predict": "The general assumption in statistical parsing research was that the coverage of a grammar, i.e. the number of syntactic constructions it deals with, is positively correlated with parsing quality #OTHEREFR; #REFR."}
{"label": "Common combination methods include the union or intersection of directional alignments, as well as heuristic interpolations between the union and intersection like grow-diag-final #REFR.", "predict": "But heuristics for aligner combination #REFR have not been shown to improve translation quality."}
{"label": "Following #REFR, we use an n-best list of 10000 sentences but we do not initially tune the negation feature using MERT or interpolate it with other features.", "predict": "Our re-ranker is different from the one described in #REFR."}
{"label": "WASP #REFR is a model motivated by statistical synchronous parsing-based machine translation #OTHEREFR.", "predict": "The KRISP system #OTHEREFR; #REFR."}
{"label": "The resource presented in #REFR uses a similar binomial annotation for single words; another interesting resource is WordNetAffect #OTHEREFR but it labels words senses and it cannot be used for the prior polarity validation task.", "predict": "Finally, the lexicon by #REFR provides the prior polarity of a given word."}
{"label": "Previous approaches #OTHEREFR; #REFR have performed this task by modifying the type vector for T to the context s and then comparing the resulting vector T ? to the type vector of a paraphrase candidate P .", "predict": "This is a difficult task, as the correct paraphrase may be a rare occurrence in the context, as noted by #REFR."}
{"label": "The method #OTHEREFR aims to detect omission-type and replacement-type errors and transformation-based leaning is employed in #REFR to learn rules to detect errors for speech recognition outputs.", "predict": "Supervised methods #OTHEREFR; #REFR) learn from a corpus of corrected sentences."}
{"label": "In recent years, conditional random fields #OTHEREFR and information extraction from research papers #REFR.", "predict": "Recent work on Conditional Random Fields #OTHEREFR; #REFR."}
{"label": "This is a significant improvement with respect to previous results achieved by the pure distributional model reported in #REFR.", "predict": "This result outperforms the previous work on the same dataset #REFR."}
{"label": "As a consequence, finding the highest scoring parse tree is a provably hard combinatorial inference problem #REFR.", "predict": "These features include the classic sibling and grandchild features #OTHEREFR; #REFR."}