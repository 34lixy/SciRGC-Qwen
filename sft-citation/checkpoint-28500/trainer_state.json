{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.957735516176738,
  "eval_steps": 500,
  "global_step": 28500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.6814595460891724,
      "learning_rate": 9.999997105542622e-05,
      "loss": 2.7868,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.603102445602417,
      "learning_rate": 9.999988304930821e-05,
      "loss": 2.2817,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.0500634908676147,
      "learning_rate": 9.999973597879671e-05,
      "loss": 2.0656,
      "step": 30
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.5359777212142944,
      "learning_rate": 9.999952984406545e-05,
      "loss": 2.08,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.8382331132888794,
      "learning_rate": 9.999926464535793e-05,
      "loss": 2.2224,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.677966833114624,
      "learning_rate": 9.999894038298745e-05,
      "loss": 2.1124,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.6304247379302979,
      "learning_rate": 9.999855705733705e-05,
      "loss": 2.1529,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4579623937606812,
      "learning_rate": 9.999811466885953e-05,
      "loss": 2.0851,
      "step": 80
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4242154359817505,
      "learning_rate": 9.99976132180775e-05,
      "loss": 2.0387,
      "step": 90
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.6168409585952759,
      "learning_rate": 9.99970527055833e-05,
      "loss": 2.2086,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.034121513366699,
      "learning_rate": 9.999643313203907e-05,
      "loss": 2.0597,
      "step": 110
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.545487403869629,
      "learning_rate": 9.999575449817673e-05,
      "loss": 2.1367,
      "step": 120
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3781763315200806,
      "learning_rate": 9.999501680479789e-05,
      "loss": 2.093,
      "step": 130
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.6459379196166992,
      "learning_rate": 9.999422005277402e-05,
      "loss": 1.9829,
      "step": 140
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.673170804977417,
      "learning_rate": 9.99933642430463e-05,
      "loss": 2.0411,
      "step": 150
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.0364677906036377,
      "learning_rate": 9.99924493766257e-05,
      "loss": 1.9666,
      "step": 160
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.3610566854476929,
      "learning_rate": 9.999147545459296e-05,
      "loss": 2.1205,
      "step": 170
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.287041187286377,
      "learning_rate": 9.999044247809851e-05,
      "loss": 1.9545,
      "step": 180
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.6564046144485474,
      "learning_rate": 9.998935044836264e-05,
      "loss": 1.9142,
      "step": 190
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.4527407884597778,
      "learning_rate": 9.998819936667536e-05,
      "loss": 1.9923,
      "step": 200
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2297298908233643,
      "learning_rate": 9.998698923439638e-05,
      "loss": 1.95,
      "step": 210
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.5269263982772827,
      "learning_rate": 9.998572005295528e-05,
      "loss": 2.1652,
      "step": 220
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.9094253778457642,
      "learning_rate": 9.998439182385132e-05,
      "loss": 2.0617,
      "step": 230
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.1412829160690308,
      "learning_rate": 9.998300454865348e-05,
      "loss": 2.0836,
      "step": 240
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.411056399345398,
      "learning_rate": 9.998155822900057e-05,
      "loss": 1.9601,
      "step": 250
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.2271090745925903,
      "learning_rate": 9.998005286660113e-05,
      "loss": 2.0143,
      "step": 260
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.5207228660583496,
      "learning_rate": 9.997848846323339e-05,
      "loss": 2.0223,
      "step": 270
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3162139654159546,
      "learning_rate": 9.997686502074537e-05,
      "loss": 1.9737,
      "step": 280
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4996140003204346,
      "learning_rate": 9.997518254105487e-05,
      "loss": 2.0182,
      "step": 290
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.210682988166809,
      "learning_rate": 9.997344102614936e-05,
      "loss": 1.9146,
      "step": 300
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.410660982131958,
      "learning_rate": 9.997164047808608e-05,
      "loss": 1.8915,
      "step": 310
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.305262565612793,
      "learning_rate": 9.996978089899196e-05,
      "loss": 1.9784,
      "step": 320
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.6823033094406128,
      "learning_rate": 9.996786229106376e-05,
      "loss": 2.0213,
      "step": 330
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.3488845825195312,
      "learning_rate": 9.99658846565679e-05,
      "loss": 1.9996,
      "step": 340
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.4179999828338623,
      "learning_rate": 9.996384799784053e-05,
      "loss": 1.9657,
      "step": 350
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.392103672027588,
      "learning_rate": 9.996175231728753e-05,
      "loss": 1.9959,
      "step": 360
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.6429163217544556,
      "learning_rate": 9.995959761738453e-05,
      "loss": 2.0702,
      "step": 370
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.279282808303833,
      "learning_rate": 9.995738390067684e-05,
      "loss": 2.0598,
      "step": 380
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.5140191316604614,
      "learning_rate": 9.995511116977949e-05,
      "loss": 1.9876,
      "step": 390
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.3344664573669434,
      "learning_rate": 9.995277942737728e-05,
      "loss": 1.9579,
      "step": 400
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.7063446044921875,
      "learning_rate": 9.995038867622463e-05,
      "loss": 1.9622,
      "step": 410
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.318520426750183,
      "learning_rate": 9.994793891914573e-05,
      "loss": 1.9689,
      "step": 420
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.2914881706237793,
      "learning_rate": 9.994543015903446e-05,
      "loss": 1.9261,
      "step": 430
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.9698363542556763,
      "learning_rate": 9.99428623988544e-05,
      "loss": 2.0156,
      "step": 440
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.2983123064041138,
      "learning_rate": 9.994023564163879e-05,
      "loss": 1.9459,
      "step": 450
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.6277844905853271,
      "learning_rate": 9.993754989049063e-05,
      "loss": 1.9866,
      "step": 460
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.3046586513519287,
      "learning_rate": 9.993480514858255e-05,
      "loss": 1.9784,
      "step": 470
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.6917170286178589,
      "learning_rate": 9.993200141915691e-05,
      "loss": 1.9721,
      "step": 480
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1478283405303955,
      "learning_rate": 9.992913870552569e-05,
      "loss": 2.0133,
      "step": 490
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1325079202651978,
      "learning_rate": 9.992621701107063e-05,
      "loss": 1.839,
      "step": 500
    },
    {
      "epoch": 0.05,
      "eval_loss": 1.9732155799865723,
      "eval_runtime": 367.5199,
      "eval_samples_per_second": 23.308,
      "eval_steps_per_second": 23.308,
      "step": 500
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.5798487663269043,
      "learning_rate": 9.992323633924307e-05,
      "loss": 1.9911,
      "step": 510
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.287979006767273,
      "learning_rate": 9.992019669356407e-05,
      "loss": 1.9952,
      "step": 520
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.3271788358688354,
      "learning_rate": 9.991709807762432e-05,
      "loss": 2.0164,
      "step": 530
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.294248342514038,
      "learning_rate": 9.99139404950842e-05,
      "loss": 1.9265,
      "step": 540
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.2379933595657349,
      "learning_rate": 9.991072394967371e-05,
      "loss": 1.9854,
      "step": 550
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.5958977937698364,
      "learning_rate": 9.990744844519255e-05,
      "loss": 2.0341,
      "step": 560
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4056066274642944,
      "learning_rate": 9.990411398551003e-05,
      "loss": 1.9517,
      "step": 570
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4922430515289307,
      "learning_rate": 9.990072057456513e-05,
      "loss": 1.9173,
      "step": 580
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1149119138717651,
      "learning_rate": 9.989726821636643e-05,
      "loss": 1.944,
      "step": 590
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4706257581710815,
      "learning_rate": 9.989375691499219e-05,
      "loss": 1.9952,
      "step": 600
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4858484268188477,
      "learning_rate": 9.989018667459026e-05,
      "loss": 1.8122,
      "step": 610
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4086642265319824,
      "learning_rate": 9.988655749937815e-05,
      "loss": 2.0985,
      "step": 620
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.4986463785171509,
      "learning_rate": 9.988286939364295e-05,
      "loss": 1.8972,
      "step": 630
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.5065643787384033,
      "learning_rate": 9.987912236174142e-05,
      "loss": 1.9396,
      "step": 640
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.2090814113616943,
      "learning_rate": 9.987531640809984e-05,
      "loss": 2.081,
      "step": 650
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.4599831104278564,
      "learning_rate": 9.98714515372142e-05,
      "loss": 2.0714,
      "step": 660
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.476672649383545,
      "learning_rate": 9.986752775365e-05,
      "loss": 1.9987,
      "step": 670
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3152525424957275,
      "learning_rate": 9.986354506204239e-05,
      "loss": 2.0203,
      "step": 680
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3909993171691895,
      "learning_rate": 9.985950346709608e-05,
      "loss": 1.9938,
      "step": 690
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.17268967628479,
      "learning_rate": 9.985540297358534e-05,
      "loss": 1.9375,
      "step": 700
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3141130208969116,
      "learning_rate": 9.98512435863541e-05,
      "loss": 1.819,
      "step": 710
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.6078661680221558,
      "learning_rate": 9.984702531031575e-05,
      "loss": 1.9303,
      "step": 720
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.0750982761383057,
      "learning_rate": 9.984274815045334e-05,
      "loss": 1.8821,
      "step": 730
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.2481327056884766,
      "learning_rate": 9.983841211181943e-05,
      "loss": 1.8463,
      "step": 740
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.4692294597625732,
      "learning_rate": 9.983401719953614e-05,
      "loss": 1.8621,
      "step": 750
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.4363998174667358,
      "learning_rate": 9.982956341879512e-05,
      "loss": 1.8956,
      "step": 760
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7250843048095703,
      "learning_rate": 9.982505077485761e-05,
      "loss": 2.0889,
      "step": 770
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.241531491279602,
      "learning_rate": 9.982047927305434e-05,
      "loss": 1.8503,
      "step": 780
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.3754851818084717,
      "learning_rate": 9.981584891878556e-05,
      "loss": 1.9609,
      "step": 790
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7444872856140137,
      "learning_rate": 9.981115971752109e-05,
      "loss": 1.8687,
      "step": 800
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.5480446815490723,
      "learning_rate": 9.980641167480025e-05,
      "loss": 1.9404,
      "step": 810
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.3318254947662354,
      "learning_rate": 9.980160479623184e-05,
      "loss": 1.8693,
      "step": 820
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.3126100301742554,
      "learning_rate": 9.979673908749417e-05,
      "loss": 1.9646,
      "step": 830
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0604039430618286,
      "learning_rate": 9.979181455433508e-05,
      "loss": 1.9659,
      "step": 840
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.181060552597046,
      "learning_rate": 9.978683120257186e-05,
      "loss": 1.8587,
      "step": 850
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.6409095525741577,
      "learning_rate": 9.97817890380913e-05,
      "loss": 1.9207,
      "step": 860
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.672109842300415,
      "learning_rate": 9.977668806684967e-05,
      "loss": 1.9153,
      "step": 870
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.1408624649047852,
      "learning_rate": 9.977152829487271e-05,
      "loss": 1.9581,
      "step": 880
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.3651574850082397,
      "learning_rate": 9.976630972825556e-05,
      "loss": 1.9261,
      "step": 890
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.1959048509597778,
      "learning_rate": 9.976103237316292e-05,
      "loss": 1.9404,
      "step": 900
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.346821665763855,
      "learning_rate": 9.975569623582885e-05,
      "loss": 1.8211,
      "step": 910
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.4869592189788818,
      "learning_rate": 9.975030132255687e-05,
      "loss": 1.7808,
      "step": 920
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.685276746749878,
      "learning_rate": 9.974484763971998e-05,
      "loss": 2.0215,
      "step": 930
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.3963316679000854,
      "learning_rate": 9.973933519376053e-05,
      "loss": 2.0146,
      "step": 940
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.4395750761032104,
      "learning_rate": 9.973376399119033e-05,
      "loss": 1.844,
      "step": 950
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2692431211471558,
      "learning_rate": 9.97281340385906e-05,
      "loss": 1.9991,
      "step": 960
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.1997466087341309,
      "learning_rate": 9.972244534261194e-05,
      "loss": 1.9449,
      "step": 970
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.1481742858886719,
      "learning_rate": 9.971669790997434e-05,
      "loss": 1.9286,
      "step": 980
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.4515246152877808,
      "learning_rate": 9.971089174746722e-05,
      "loss": 1.9185,
      "step": 990
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2167961597442627,
      "learning_rate": 9.970502686194932e-05,
      "loss": 1.8557,
      "step": 1000
    },
    {
      "epoch": 0.1,
      "eval_loss": 1.9410074949264526,
      "eval_runtime": 367.5819,
      "eval_samples_per_second": 23.304,
      "eval_steps_per_second": 23.304,
      "step": 1000
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5084930658340454,
      "learning_rate": 9.96991032603488e-05,
      "loss": 1.8981,
      "step": 1010
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1160629987716675,
      "learning_rate": 9.969312094966311e-05,
      "loss": 1.8218,
      "step": 1020
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.162402629852295,
      "learning_rate": 9.968707993695913e-05,
      "loss": 2.0093,
      "step": 1030
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.571872591972351,
      "learning_rate": 9.968098022937306e-05,
      "loss": 1.9617,
      "step": 1040
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.5736411809921265,
      "learning_rate": 9.967482183411042e-05,
      "loss": 1.9807,
      "step": 1050
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1255543231964111,
      "learning_rate": 9.966860475844605e-05,
      "loss": 1.9294,
      "step": 1060
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.2956150770187378,
      "learning_rate": 9.966232900972414e-05,
      "loss": 1.9229,
      "step": 1070
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.8385367393493652,
      "learning_rate": 9.965599459535815e-05,
      "loss": 1.9663,
      "step": 1080
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.350641131401062,
      "learning_rate": 9.964960152283089e-05,
      "loss": 1.967,
      "step": 1090
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.4043447971343994,
      "learning_rate": 9.964314979969443e-05,
      "loss": 1.9022,
      "step": 1100
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.838562250137329,
      "learning_rate": 9.96366394335701e-05,
      "loss": 1.9357,
      "step": 1110
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.124435544013977,
      "learning_rate": 9.96300704321486e-05,
      "loss": 1.9648,
      "step": 1120
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8804187774658203,
      "learning_rate": 9.962344280318978e-05,
      "loss": 2.0338,
      "step": 1130
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.4011647701263428,
      "learning_rate": 9.96167565545228e-05,
      "loss": 2.0127,
      "step": 1140
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.5331485271453857,
      "learning_rate": 9.961001169404607e-05,
      "loss": 1.879,
      "step": 1150
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.6809310913085938,
      "learning_rate": 9.960320822972723e-05,
      "loss": 1.9586,
      "step": 1160
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.255653738975525,
      "learning_rate": 9.959634616960315e-05,
      "loss": 1.9324,
      "step": 1170
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.2338812351226807,
      "learning_rate": 9.958942552177992e-05,
      "loss": 1.9385,
      "step": 1180
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.663322925567627,
      "learning_rate": 9.958244629443283e-05,
      "loss": 1.8848,
      "step": 1190
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.2694998979568481,
      "learning_rate": 9.957540849580638e-05,
      "loss": 1.9226,
      "step": 1200
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.2556158304214478,
      "learning_rate": 9.956831213421426e-05,
      "loss": 1.8796,
      "step": 1210
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.2608530521392822,
      "learning_rate": 9.956115721803932e-05,
      "loss": 2.0308,
      "step": 1220
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.5519683361053467,
      "learning_rate": 9.955394375573361e-05,
      "loss": 1.8586,
      "step": 1230
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1987613439559937,
      "learning_rate": 9.954667175581833e-05,
      "loss": 1.9476,
      "step": 1240
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.2605419158935547,
      "learning_rate": 9.95393412268838e-05,
      "loss": 1.8851,
      "step": 1250
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.3246464729309082,
      "learning_rate": 9.953195217758952e-05,
      "loss": 1.9511,
      "step": 1260
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.3357295989990234,
      "learning_rate": 9.952450461666413e-05,
      "loss": 1.9677,
      "step": 1270
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.6135836839675903,
      "learning_rate": 9.951699855290532e-05,
      "loss": 1.8416,
      "step": 1280
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.519885540008545,
      "learning_rate": 9.950943399517996e-05,
      "loss": 1.9564,
      "step": 1290
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.4396135807037354,
      "learning_rate": 9.9501810952424e-05,
      "loss": 2.0028,
      "step": 1300
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.541260004043579,
      "learning_rate": 9.949412943364243e-05,
      "loss": 1.98,
      "step": 1310
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.982517957687378,
      "learning_rate": 9.948638944790938e-05,
      "loss": 2.0438,
      "step": 1320
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1321220397949219,
      "learning_rate": 9.947859100436803e-05,
      "loss": 1.9603,
      "step": 1330
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2955299615859985,
      "learning_rate": 9.947073411223061e-05,
      "loss": 1.9579,
      "step": 1340
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2244479656219482,
      "learning_rate": 9.946281878077836e-05,
      "loss": 1.817,
      "step": 1350
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.349514365196228,
      "learning_rate": 9.945484501936163e-05,
      "loss": 1.8938,
      "step": 1360
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2811793088912964,
      "learning_rate": 9.944681283739972e-05,
      "loss": 1.9297,
      "step": 1370
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.373838186264038,
      "learning_rate": 9.943872224438098e-05,
      "loss": 1.9262,
      "step": 1380
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.084328055381775,
      "learning_rate": 9.943057324986276e-05,
      "loss": 1.9764,
      "step": 1390
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.283052921295166,
      "learning_rate": 9.942236586347138e-05,
      "loss": 1.9303,
      "step": 1400
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1633683443069458,
      "learning_rate": 9.941410009490215e-05,
      "loss": 1.8248,
      "step": 1410
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1090760231018066,
      "learning_rate": 9.940577595391934e-05,
      "loss": 1.8405,
      "step": 1420
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1312284469604492,
      "learning_rate": 9.93973934503562e-05,
      "loss": 1.9925,
      "step": 1430
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.330076813697815,
      "learning_rate": 9.93889525941149e-05,
      "loss": 1.9649,
      "step": 1440
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.4264854192733765,
      "learning_rate": 9.93804533951665e-05,
      "loss": 1.8762,
      "step": 1450
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.4301811456680298,
      "learning_rate": 9.937189586355109e-05,
      "loss": 1.9204,
      "step": 1460
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2070345878601074,
      "learning_rate": 9.936328000937757e-05,
      "loss": 1.8896,
      "step": 1470
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2438045740127563,
      "learning_rate": 9.935460584282376e-05,
      "loss": 1.9174,
      "step": 1480
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0822436809539795,
      "learning_rate": 9.934587337413638e-05,
      "loss": 1.8811,
      "step": 1490
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1998202800750732,
      "learning_rate": 9.933708261363101e-05,
      "loss": 1.9781,
      "step": 1500
    },
    {
      "epoch": 0.16,
      "eval_loss": 1.9233237504959106,
      "eval_runtime": 367.5947,
      "eval_samples_per_second": 23.303,
      "eval_steps_per_second": 23.303,
      "step": 1500
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1191717386245728,
      "learning_rate": 9.93282335716921e-05,
      "loss": 1.8832,
      "step": 1510
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.4346668720245361,
      "learning_rate": 9.931932625877294e-05,
      "loss": 2.0099,
      "step": 1520
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.4434292316436768,
      "learning_rate": 9.931036068539565e-05,
      "loss": 1.8757,
      "step": 1530
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.2124180793762207,
      "learning_rate": 9.93013368621512e-05,
      "loss": 1.9125,
      "step": 1540
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1659369468688965,
      "learning_rate": 9.929225479969931e-05,
      "loss": 1.8972,
      "step": 1550
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.6318631172180176,
      "learning_rate": 9.928311450876853e-05,
      "loss": 2.0478,
      "step": 1560
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.2871863842010498,
      "learning_rate": 9.927391600015626e-05,
      "loss": 2.0235,
      "step": 1570
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8378371000289917,
      "learning_rate": 9.926465928472857e-05,
      "loss": 1.961,
      "step": 1580
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.5127803087234497,
      "learning_rate": 9.925534437342032e-05,
      "loss": 1.9737,
      "step": 1590
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.2696549892425537,
      "learning_rate": 9.924597127723516e-05,
      "loss": 1.832,
      "step": 1600
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.7112587690353394,
      "learning_rate": 9.92365400072454e-05,
      "loss": 1.9635,
      "step": 1610
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.316847324371338,
      "learning_rate": 9.922705057459217e-05,
      "loss": 1.8482,
      "step": 1620
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.2892694473266602,
      "learning_rate": 9.92175029904852e-05,
      "loss": 2.0402,
      "step": 1630
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.4557090997695923,
      "learning_rate": 9.920789726620296e-05,
      "loss": 1.8802,
      "step": 1640
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.1897321939468384,
      "learning_rate": 9.919823341309264e-05,
      "loss": 1.9016,
      "step": 1650
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.772607684135437,
      "learning_rate": 9.918851144257002e-05,
      "loss": 1.8824,
      "step": 1660
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.195408821105957,
      "learning_rate": 9.917873136611961e-05,
      "loss": 1.8971,
      "step": 1670
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.278441071510315,
      "learning_rate": 9.916889319529447e-05,
      "loss": 1.9411,
      "step": 1680
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.6476083993911743,
      "learning_rate": 9.91589969417164e-05,
      "loss": 1.9539,
      "step": 1690
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1250412464141846,
      "learning_rate": 9.914904261707572e-05,
      "loss": 1.9074,
      "step": 1700
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.629538655281067,
      "learning_rate": 9.913903023313137e-05,
      "loss": 1.93,
      "step": 1710
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0817729234695435,
      "learning_rate": 9.91289598017109e-05,
      "loss": 1.8816,
      "step": 1720
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0644022226333618,
      "learning_rate": 9.911883133471043e-05,
      "loss": 1.9924,
      "step": 1730
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.2989319562911987,
      "learning_rate": 9.910864484409459e-05,
      "loss": 1.8,
      "step": 1740
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1235140562057495,
      "learning_rate": 9.909840034189662e-05,
      "loss": 1.9504,
      "step": 1750
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.3750884532928467,
      "learning_rate": 9.908809784021822e-05,
      "loss": 1.7909,
      "step": 1760
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.247138261795044,
      "learning_rate": 9.907773735122969e-05,
      "loss": 1.9118,
      "step": 1770
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.326485514640808,
      "learning_rate": 9.906731888716971e-05,
      "loss": 2.016,
      "step": 1780
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.2223094701766968,
      "learning_rate": 9.905684246034557e-05,
      "loss": 1.9973,
      "step": 1790
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.3330416679382324,
      "learning_rate": 9.904630808313295e-05,
      "loss": 1.8202,
      "step": 1800
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.3139312267303467,
      "learning_rate": 9.903571576797601e-05,
      "loss": 1.7029,
      "step": 1810
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.6132348775863647,
      "learning_rate": 9.902506552738737e-05,
      "loss": 1.9202,
      "step": 1820
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1996703147888184,
      "learning_rate": 9.901435737394805e-05,
      "loss": 1.9854,
      "step": 1830
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.285736083984375,
      "learning_rate": 9.900359132030747e-05,
      "loss": 1.8192,
      "step": 1840
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.0520519018173218,
      "learning_rate": 9.89927673791835e-05,
      "loss": 1.9143,
      "step": 1850
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.184327483177185,
      "learning_rate": 9.898188556336234e-05,
      "loss": 1.9097,
      "step": 1860
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9577056169509888,
      "learning_rate": 9.897094588569859e-05,
      "loss": 1.8449,
      "step": 1870
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9208815097808838,
      "learning_rate": 9.89599483591152e-05,
      "loss": 1.9275,
      "step": 1880
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.102009654045105,
      "learning_rate": 9.894889299660341e-05,
      "loss": 1.8297,
      "step": 1890
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.3681584596633911,
      "learning_rate": 9.893777981122284e-05,
      "loss": 1.9156,
      "step": 1900
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.372844934463501,
      "learning_rate": 9.892660881610138e-05,
      "loss": 1.9851,
      "step": 1910
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1357895135879517,
      "learning_rate": 9.891538002443523e-05,
      "loss": 1.8153,
      "step": 1920
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.2411600351333618,
      "learning_rate": 9.890409344948888e-05,
      "loss": 1.9885,
      "step": 1930
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.3761184215545654,
      "learning_rate": 9.8892749104595e-05,
      "loss": 1.8968,
      "step": 1940
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.2744836807250977,
      "learning_rate": 9.888134700315461e-05,
      "loss": 1.7934,
      "step": 1950
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.2728124856948853,
      "learning_rate": 9.886988715863688e-05,
      "loss": 1.9575,
      "step": 1960
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.217281699180603,
      "learning_rate": 9.88583695845792e-05,
      "loss": 1.9851,
      "step": 1970
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.3564103841781616,
      "learning_rate": 9.884679429458721e-05,
      "loss": 1.8413,
      "step": 1980
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2866371870040894,
      "learning_rate": 9.883516130233467e-05,
      "loss": 1.9004,
      "step": 1990
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.1449459791183472,
      "learning_rate": 9.882347062156354e-05,
      "loss": 1.8874,
      "step": 2000
    },
    {
      "epoch": 0.21,
      "eval_loss": 1.9129083156585693,
      "eval_runtime": 366.9043,
      "eval_samples_per_second": 23.347,
      "eval_steps_per_second": 23.347,
      "step": 2000
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2006951570510864,
      "learning_rate": 9.881172226608391e-05,
      "loss": 1.768,
      "step": 2010
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.4904550313949585,
      "learning_rate": 9.879991624977398e-05,
      "loss": 1.9791,
      "step": 2020
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.9717516899108887,
      "learning_rate": 9.87880525865801e-05,
      "loss": 1.8668,
      "step": 2030
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.1186176538467407,
      "learning_rate": 9.877613129051671e-05,
      "loss": 1.8858,
      "step": 2040
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.68100106716156,
      "learning_rate": 9.876415237566632e-05,
      "loss": 1.8685,
      "step": 2050
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0900403261184692,
      "learning_rate": 9.87521158561795e-05,
      "loss": 2.0441,
      "step": 2060
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.3327440023422241,
      "learning_rate": 9.87400217462749e-05,
      "loss": 1.9401,
      "step": 2070
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.3107335567474365,
      "learning_rate": 9.872787006023915e-05,
      "loss": 1.963,
      "step": 2080
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.3871779441833496,
      "learning_rate": 9.871566081242696e-05,
      "loss": 1.9555,
      "step": 2090
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.008401393890381,
      "learning_rate": 9.870339401726096e-05,
      "loss": 1.8778,
      "step": 2100
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.2999873161315918,
      "learning_rate": 9.869106968923184e-05,
      "loss": 1.9212,
      "step": 2110
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.024322271347046,
      "learning_rate": 9.867868784289819e-05,
      "loss": 1.882,
      "step": 2120
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.6984754800796509,
      "learning_rate": 9.866624849288657e-05,
      "loss": 1.9519,
      "step": 2130
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.5482186079025269,
      "learning_rate": 9.865375165389145e-05,
      "loss": 1.8955,
      "step": 2140
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.4446063041687012,
      "learning_rate": 9.864119734067527e-05,
      "loss": 1.8332,
      "step": 2150
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.0607186555862427,
      "learning_rate": 9.86285855680683e-05,
      "loss": 1.8506,
      "step": 2160
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.1737873554229736,
      "learning_rate": 9.86159163509687e-05,
      "loss": 1.8631,
      "step": 2170
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.2850552797317505,
      "learning_rate": 9.860318970434253e-05,
      "loss": 1.9204,
      "step": 2180
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.3338735103607178,
      "learning_rate": 9.859040564322362e-05,
      "loss": 1.8555,
      "step": 2190
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.1600805521011353,
      "learning_rate": 9.857756418271366e-05,
      "loss": 1.7804,
      "step": 2200
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.1657906770706177,
      "learning_rate": 9.856466533798219e-05,
      "loss": 1.8175,
      "step": 2210
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.175584077835083,
      "learning_rate": 9.855170912426645e-05,
      "loss": 2.0617,
      "step": 2220
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.3679964542388916,
      "learning_rate": 9.853869555687154e-05,
      "loss": 1.8418,
      "step": 2230
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.055014729499817,
      "learning_rate": 9.852562465117021e-05,
      "loss": 1.8516,
      "step": 2240
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.3957337141036987,
      "learning_rate": 9.851249642260305e-05,
      "loss": 1.967,
      "step": 2250
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.3009533882141113,
      "learning_rate": 9.849931088667828e-05,
      "loss": 1.9379,
      "step": 2260
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.2758631706237793,
      "learning_rate": 9.848606805897185e-05,
      "loss": 1.815,
      "step": 2270
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.16309928894043,
      "learning_rate": 9.847276795512742e-05,
      "loss": 1.8918,
      "step": 2280
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1270828247070312,
      "learning_rate": 9.845941059085624e-05,
      "loss": 1.7842,
      "step": 2290
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.302154302597046,
      "learning_rate": 9.844599598193726e-05,
      "loss": 1.9207,
      "step": 2300
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.4483224153518677,
      "learning_rate": 9.843252414421702e-05,
      "loss": 1.7939,
      "step": 2310
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.3084766864776611,
      "learning_rate": 9.84189950936097e-05,
      "loss": 1.9258,
      "step": 2320
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.3359342813491821,
      "learning_rate": 9.840540884609701e-05,
      "loss": 1.934,
      "step": 2330
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.080154299736023,
      "learning_rate": 9.839176541772829e-05,
      "loss": 1.8242,
      "step": 2340
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.4928549528121948,
      "learning_rate": 9.837806482462035e-05,
      "loss": 1.8766,
      "step": 2350
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0808944702148438,
      "learning_rate": 9.836430708295762e-05,
      "loss": 1.8289,
      "step": 2360
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.4004955291748047,
      "learning_rate": 9.835049220899197e-05,
      "loss": 1.8957,
      "step": 2370
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.2012100219726562,
      "learning_rate": 9.833662021904277e-05,
      "loss": 1.894,
      "step": 2380
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.4306405782699585,
      "learning_rate": 9.832269112949688e-05,
      "loss": 1.9426,
      "step": 2390
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.3068381547927856,
      "learning_rate": 9.83087049568086e-05,
      "loss": 1.9103,
      "step": 2400
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.9251827001571655,
      "learning_rate": 9.829466171749967e-05,
      "loss": 1.8876,
      "step": 2410
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.1709377765655518,
      "learning_rate": 9.828056142815924e-05,
      "loss": 1.9892,
      "step": 2420
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.3135764598846436,
      "learning_rate": 9.826640410544385e-05,
      "loss": 1.8937,
      "step": 2430
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.4660407304763794,
      "learning_rate": 9.825218976607741e-05,
      "loss": 1.7988,
      "step": 2440
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.1355113983154297,
      "learning_rate": 9.82379184268512e-05,
      "loss": 1.9238,
      "step": 2450
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0882935523986816,
      "learning_rate": 9.822359010462379e-05,
      "loss": 1.8132,
      "step": 2460
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.2666460275650024,
      "learning_rate": 9.82092048163211e-05,
      "loss": 1.8498,
      "step": 2470
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.4137804508209229,
      "learning_rate": 9.819476257893636e-05,
      "loss": 2.0311,
      "step": 2480
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.3400444984436035,
      "learning_rate": 9.818026340953001e-05,
      "loss": 1.9022,
      "step": 2490
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.430566668510437,
      "learning_rate": 9.816570732522983e-05,
      "loss": 1.9058,
      "step": 2500
    },
    {
      "epoch": 0.26,
      "eval_loss": 1.9055557250976562,
      "eval_runtime": 366.8817,
      "eval_samples_per_second": 23.348,
      "eval_steps_per_second": 23.348,
      "step": 2500
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.390392541885376,
      "learning_rate": 9.815109434323075e-05,
      "loss": 1.8377,
      "step": 2510
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1712201833724976,
      "learning_rate": 9.813642448079497e-05,
      "loss": 1.8731,
      "step": 2520
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1831932067871094,
      "learning_rate": 9.812169775525184e-05,
      "loss": 1.8236,
      "step": 2530
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.9596810936927795,
      "learning_rate": 9.810691418399794e-05,
      "loss": 1.9337,
      "step": 2540
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.2482579946517944,
      "learning_rate": 9.809207378449691e-05,
      "loss": 1.8582,
      "step": 2550
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1048187017440796,
      "learning_rate": 9.807717657427961e-05,
      "loss": 1.8982,
      "step": 2560
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1940521001815796,
      "learning_rate": 9.806222257094397e-05,
      "loss": 1.8612,
      "step": 2570
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.139265775680542,
      "learning_rate": 9.804721179215503e-05,
      "loss": 1.9676,
      "step": 2580
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.3588240146636963,
      "learning_rate": 9.803214425564485e-05,
      "loss": 1.9828,
      "step": 2590
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.0471245050430298,
      "learning_rate": 9.80170199792126e-05,
      "loss": 1.8761,
      "step": 2600
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.201779842376709,
      "learning_rate": 9.800183898072441e-05,
      "loss": 1.8208,
      "step": 2610
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.3006184101104736,
      "learning_rate": 9.798660127811349e-05,
      "loss": 1.9606,
      "step": 2620
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.2009518146514893,
      "learning_rate": 9.797130688937997e-05,
      "loss": 1.9515,
      "step": 2630
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.2485417127609253,
      "learning_rate": 9.795595583259098e-05,
      "loss": 1.8546,
      "step": 2640
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1194862127304077,
      "learning_rate": 9.794054812588058e-05,
      "loss": 1.9,
      "step": 2650
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.3971278667449951,
      "learning_rate": 9.792508378744974e-05,
      "loss": 1.8973,
      "step": 2660
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.3404372930526733,
      "learning_rate": 9.790956283556633e-05,
      "loss": 1.9383,
      "step": 2670
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.0257877111434937,
      "learning_rate": 9.789398528856515e-05,
      "loss": 1.8599,
      "step": 2680
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.3446204662322998,
      "learning_rate": 9.787835116484776e-05,
      "loss": 1.8796,
      "step": 2690
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.218338966369629,
      "learning_rate": 9.786266048288261e-05,
      "loss": 1.81,
      "step": 2700
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1390804052352905,
      "learning_rate": 9.784691326120498e-05,
      "loss": 1.9608,
      "step": 2710
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.5648021697998047,
      "learning_rate": 9.783110951841692e-05,
      "loss": 1.9763,
      "step": 2720
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1660994291305542,
      "learning_rate": 9.781524927318721e-05,
      "loss": 1.8808,
      "step": 2730
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.2432525157928467,
      "learning_rate": 9.779933254425144e-05,
      "loss": 1.8603,
      "step": 2740
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.296244502067566,
      "learning_rate": 9.778335935041188e-05,
      "loss": 1.905,
      "step": 2750
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.2046602964401245,
      "learning_rate": 9.77673297105375e-05,
      "loss": 1.8958,
      "step": 2760
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0660979747772217,
      "learning_rate": 9.775124364356399e-05,
      "loss": 1.8699,
      "step": 2770
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.7363357543945312,
      "learning_rate": 9.773510116849364e-05,
      "loss": 1.9855,
      "step": 2780
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.5393579006195068,
      "learning_rate": 9.771890230439543e-05,
      "loss": 1.875,
      "step": 2790
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.340720295906067,
      "learning_rate": 9.770264707040491e-05,
      "loss": 1.9526,
      "step": 2800
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.1169335842132568,
      "learning_rate": 9.768633548572426e-05,
      "loss": 1.8919,
      "step": 2810
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.3957808017730713,
      "learning_rate": 9.766996756962219e-05,
      "loss": 1.7634,
      "step": 2820
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.1817854642868042,
      "learning_rate": 9.765354334143395e-05,
      "loss": 1.9869,
      "step": 2830
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.4207180738449097,
      "learning_rate": 9.763706282056133e-05,
      "loss": 1.9133,
      "step": 2840
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.8868556022644043,
      "learning_rate": 9.762052602647264e-05,
      "loss": 1.9265,
      "step": 2850
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.149946928024292,
      "learning_rate": 9.760393297870263e-05,
      "loss": 1.9578,
      "step": 2860
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.8257719278335571,
      "learning_rate": 9.758728369685248e-05,
      "loss": 1.873,
      "step": 2870
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.331789255142212,
      "learning_rate": 9.757057820058988e-05,
      "loss": 1.8962,
      "step": 2880
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.7372641563415527,
      "learning_rate": 9.755381650964884e-05,
      "loss": 1.8518,
      "step": 2890
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.2455333471298218,
      "learning_rate": 9.753699864382982e-05,
      "loss": 1.8607,
      "step": 2900
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.2481223344802856,
      "learning_rate": 9.752012462299956e-05,
      "loss": 1.9617,
      "step": 2910
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.2227085828781128,
      "learning_rate": 9.750319446709123e-05,
      "loss": 1.8281,
      "step": 2920
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.2796789407730103,
      "learning_rate": 9.748620819610423e-05,
      "loss": 1.8923,
      "step": 2930
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.3319967985153198,
      "learning_rate": 9.746916583010433e-05,
      "loss": 1.854,
      "step": 2940
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.06770658493042,
      "learning_rate": 9.745206738922346e-05,
      "loss": 1.9059,
      "step": 2950
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.391363263130188,
      "learning_rate": 9.743491289365987e-05,
      "loss": 2.07,
      "step": 2960
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.4405254125595093,
      "learning_rate": 9.741770236367802e-05,
      "loss": 1.9249,
      "step": 2970
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.5518547296524048,
      "learning_rate": 9.740043581960853e-05,
      "loss": 1.9213,
      "step": 2980
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.2034802436828613,
      "learning_rate": 9.738311328184824e-05,
      "loss": 1.9364,
      "step": 2990
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.3065752983093262,
      "learning_rate": 9.736573477086004e-05,
      "loss": 1.8286,
      "step": 3000
    },
    {
      "epoch": 0.31,
      "eval_loss": 1.8980950117111206,
      "eval_runtime": 366.7643,
      "eval_samples_per_second": 23.356,
      "eval_steps_per_second": 23.356,
      "step": 3000
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1970986127853394,
      "learning_rate": 9.734830030717305e-05,
      "loss": 1.9273,
      "step": 3010
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0602500438690186,
      "learning_rate": 9.733080991138243e-05,
      "loss": 1.9468,
      "step": 3020
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.40758216381073,
      "learning_rate": 9.731326360414944e-05,
      "loss": 1.8527,
      "step": 3030
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.077184796333313,
      "learning_rate": 9.72956614062013e-05,
      "loss": 1.976,
      "step": 3040
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0950570106506348,
      "learning_rate": 9.727800333833139e-05,
      "loss": 1.9017,
      "step": 3050
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.1896791458129883,
      "learning_rate": 9.7260289421399e-05,
      "loss": 1.902,
      "step": 3060
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.2575609683990479,
      "learning_rate": 9.72425196763294e-05,
      "loss": 1.8713,
      "step": 3070
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.1428688764572144,
      "learning_rate": 9.722469412411383e-05,
      "loss": 1.8121,
      "step": 3080
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.124295711517334,
      "learning_rate": 9.720681278580947e-05,
      "loss": 1.8914,
      "step": 3090
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.477231502532959,
      "learning_rate": 9.718887568253936e-05,
      "loss": 1.8563,
      "step": 3100
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.2660480737686157,
      "learning_rate": 9.717088283549242e-05,
      "loss": 1.9634,
      "step": 3110
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.651862382888794,
      "learning_rate": 9.715283426592346e-05,
      "loss": 1.9612,
      "step": 3120
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.3694193363189697,
      "learning_rate": 9.713472999515305e-05,
      "loss": 1.8671,
      "step": 3130
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.0030521154403687,
      "learning_rate": 9.711657004456762e-05,
      "loss": 1.8371,
      "step": 3140
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.3520866632461548,
      "learning_rate": 9.709835443561935e-05,
      "loss": 1.8507,
      "step": 3150
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.3723517656326294,
      "learning_rate": 9.708008318982615e-05,
      "loss": 1.9367,
      "step": 3160
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.274095892906189,
      "learning_rate": 9.70617563287717e-05,
      "loss": 1.9464,
      "step": 3170
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.3360955715179443,
      "learning_rate": 9.704337387410534e-05,
      "loss": 1.8654,
      "step": 3180
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1730475425720215,
      "learning_rate": 9.702493584754206e-05,
      "loss": 1.8102,
      "step": 3190
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.4477630853652954,
      "learning_rate": 9.700644227086258e-05,
      "loss": 1.8132,
      "step": 3200
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1527029275894165,
      "learning_rate": 9.698789316591315e-05,
      "loss": 1.7825,
      "step": 3210
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.3097779750823975,
      "learning_rate": 9.696928855460565e-05,
      "loss": 1.8201,
      "step": 3220
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.1579948663711548,
      "learning_rate": 9.695062845891758e-05,
      "loss": 1.944,
      "step": 3230
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.173251748085022,
      "learning_rate": 9.693191290089188e-05,
      "loss": 1.8749,
      "step": 3240
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.4801100492477417,
      "learning_rate": 9.69131419026371e-05,
      "loss": 1.815,
      "step": 3250
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.5207817554473877,
      "learning_rate": 9.689431548632723e-05,
      "loss": 1.9557,
      "step": 3260
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.1299411058425903,
      "learning_rate": 9.687543367420176e-05,
      "loss": 1.8523,
      "step": 3270
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.5102691650390625,
      "learning_rate": 9.685649648856556e-05,
      "loss": 1.8512,
      "step": 3280
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.4162689447402954,
      "learning_rate": 9.683750395178897e-05,
      "loss": 1.8165,
      "step": 3290
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.3897703886032104,
      "learning_rate": 9.681845608630771e-05,
      "loss": 1.937,
      "step": 3300
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.2177544832229614,
      "learning_rate": 9.679935291462281e-05,
      "loss": 1.9061,
      "step": 3310
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.2111514806747437,
      "learning_rate": 9.67801944593007e-05,
      "loss": 1.9719,
      "step": 3320
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.2387864589691162,
      "learning_rate": 9.676098074297308e-05,
      "loss": 1.9553,
      "step": 3330
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1408045291900635,
      "learning_rate": 9.674171178833692e-05,
      "loss": 1.8035,
      "step": 3340
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.2929739952087402,
      "learning_rate": 9.672238761815447e-05,
      "loss": 1.837,
      "step": 3350
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.3283116817474365,
      "learning_rate": 9.670300825525317e-05,
      "loss": 1.7595,
      "step": 3360
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.3428665399551392,
      "learning_rate": 9.66835737225257e-05,
      "loss": 1.7404,
      "step": 3370
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1941709518432617,
      "learning_rate": 9.666408404292988e-05,
      "loss": 1.8777,
      "step": 3380
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1079694032669067,
      "learning_rate": 9.664453923948868e-05,
      "loss": 1.8732,
      "step": 3390
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.2605249881744385,
      "learning_rate": 9.662493933529022e-05,
      "loss": 1.8439,
      "step": 3400
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.162503957748413,
      "learning_rate": 9.660528435348766e-05,
      "loss": 1.7793,
      "step": 3410
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.6288714408874512,
      "learning_rate": 9.658557431729924e-05,
      "loss": 1.9427,
      "step": 3420
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.3868273496627808,
      "learning_rate": 9.656580925000828e-05,
      "loss": 1.9244,
      "step": 3430
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.3622410297393799,
      "learning_rate": 9.654598917496303e-05,
      "loss": 1.8693,
      "step": 3440
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.3476730585098267,
      "learning_rate": 9.652611411557677e-05,
      "loss": 1.8115,
      "step": 3450
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.2312155961990356,
      "learning_rate": 9.650618409532773e-05,
      "loss": 1.805,
      "step": 3460
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.2663480043411255,
      "learning_rate": 9.648619913775903e-05,
      "loss": 2.0053,
      "step": 3470
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.9859250783920288,
      "learning_rate": 9.646615926647874e-05,
      "loss": 1.9253,
      "step": 3480
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0416538715362549,
      "learning_rate": 9.644606450515976e-05,
      "loss": 1.8792,
      "step": 3490
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.5110756158828735,
      "learning_rate": 9.642591487753987e-05,
      "loss": 1.8911,
      "step": 3500
    },
    {
      "epoch": 0.36,
      "eval_loss": 1.8920246362686157,
      "eval_runtime": 366.5161,
      "eval_samples_per_second": 23.371,
      "eval_steps_per_second": 23.371,
      "step": 3500
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0128272771835327,
      "learning_rate": 9.640571040742159e-05,
      "loss": 1.8263,
      "step": 3510
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.217980980873108,
      "learning_rate": 9.63854511186723e-05,
      "loss": 1.9834,
      "step": 3520
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.2107921838760376,
      "learning_rate": 9.636513703522411e-05,
      "loss": 1.8012,
      "step": 3530
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.375425100326538,
      "learning_rate": 9.634476818107386e-05,
      "loss": 1.9259,
      "step": 3540
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1643146276474,
      "learning_rate": 9.632434458028306e-05,
      "loss": 1.807,
      "step": 3550
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.4985930919647217,
      "learning_rate": 9.630386625697794e-05,
      "loss": 1.8642,
      "step": 3560
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.2583208084106445,
      "learning_rate": 9.628333323534935e-05,
      "loss": 1.8144,
      "step": 3570
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.423667550086975,
      "learning_rate": 9.626274553965273e-05,
      "loss": 1.9645,
      "step": 3580
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.2595587968826294,
      "learning_rate": 9.624210319420819e-05,
      "loss": 1.888,
      "step": 3590
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9112789630889893,
      "learning_rate": 9.622140622340028e-05,
      "loss": 1.9077,
      "step": 3600
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.3023933172225952,
      "learning_rate": 9.620065465167817e-05,
      "loss": 1.7787,
      "step": 3610
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1867339611053467,
      "learning_rate": 9.617984850355548e-05,
      "loss": 1.8482,
      "step": 3620
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.2711926698684692,
      "learning_rate": 9.615898780361033e-05,
      "loss": 1.8053,
      "step": 3630
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.4452406167984009,
      "learning_rate": 9.613807257648529e-05,
      "loss": 1.8834,
      "step": 3640
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.2744396924972534,
      "learning_rate": 9.611710284688726e-05,
      "loss": 1.893,
      "step": 3650
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1610547304153442,
      "learning_rate": 9.609607863958765e-05,
      "loss": 1.898,
      "step": 3660
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1862521171569824,
      "learning_rate": 9.60749999794221e-05,
      "loss": 1.7959,
      "step": 3670
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.4292514324188232,
      "learning_rate": 9.60538668912907e-05,
      "loss": 1.8582,
      "step": 3680
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.2543585300445557,
      "learning_rate": 9.603267940015772e-05,
      "loss": 1.8559,
      "step": 3690
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.3074952363967896,
      "learning_rate": 9.601143753105177e-05,
      "loss": 1.8689,
      "step": 3700
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.935351848602295,
      "learning_rate": 9.599014130906565e-05,
      "loss": 1.8879,
      "step": 3710
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.4446467161178589,
      "learning_rate": 9.59687907593564e-05,
      "loss": 1.855,
      "step": 3720
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.3464128971099854,
      "learning_rate": 9.594738590714524e-05,
      "loss": 1.879,
      "step": 3730
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.2125015258789062,
      "learning_rate": 9.592592677771748e-05,
      "loss": 1.9041,
      "step": 3740
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1180996894836426,
      "learning_rate": 9.590441339642263e-05,
      "loss": 1.8461,
      "step": 3750
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.3871665000915527,
      "learning_rate": 9.588284578867422e-05,
      "loss": 1.8831,
      "step": 3760
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.481705665588379,
      "learning_rate": 9.586122397994987e-05,
      "loss": 1.9265,
      "step": 3770
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.3083562850952148,
      "learning_rate": 9.583954799579123e-05,
      "loss": 1.7325,
      "step": 3780
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.638769507408142,
      "learning_rate": 9.581781786180392e-05,
      "loss": 1.8518,
      "step": 3790
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1363548040390015,
      "learning_rate": 9.579603360365757e-05,
      "loss": 1.8104,
      "step": 3800
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1855546236038208,
      "learning_rate": 9.577419524708568e-05,
      "loss": 1.8248,
      "step": 3810
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.4437260627746582,
      "learning_rate": 9.575230281788574e-05,
      "loss": 1.7011,
      "step": 3820
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.3695156574249268,
      "learning_rate": 9.573035634191902e-05,
      "loss": 1.8749,
      "step": 3830
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1437406539916992,
      "learning_rate": 9.570835584511076e-05,
      "loss": 1.8532,
      "step": 3840
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.5793355703353882,
      "learning_rate": 9.568630135344986e-05,
      "loss": 1.8896,
      "step": 3850
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.442604660987854,
      "learning_rate": 9.566419289298914e-05,
      "loss": 1.9738,
      "step": 3860
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2717708349227905,
      "learning_rate": 9.56420304898451e-05,
      "loss": 1.9224,
      "step": 3870
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2093579769134521,
      "learning_rate": 9.561981417019797e-05,
      "loss": 1.7655,
      "step": 3880
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.405189871788025,
      "learning_rate": 9.559754396029169e-05,
      "loss": 1.8819,
      "step": 3890
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0871700048446655,
      "learning_rate": 9.557521988643386e-05,
      "loss": 1.9104,
      "step": 3900
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.2899553775787354,
      "learning_rate": 9.555284197499566e-05,
      "loss": 1.8685,
      "step": 3910
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.2162015438079834,
      "learning_rate": 9.553041025241196e-05,
      "loss": 1.9298,
      "step": 3920
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.1025956869125366,
      "learning_rate": 9.550792474518111e-05,
      "loss": 1.9128,
      "step": 3930
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.372735857963562,
      "learning_rate": 9.548538547986505e-05,
      "loss": 1.8991,
      "step": 3940
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.5023759603500366,
      "learning_rate": 9.546279248308918e-05,
      "loss": 1.8759,
      "step": 3950
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.4809777736663818,
      "learning_rate": 9.544014578154242e-05,
      "loss": 1.9614,
      "step": 3960
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8439801931381226,
      "learning_rate": 9.541744540197709e-05,
      "loss": 1.8599,
      "step": 3970
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.1665129661560059,
      "learning_rate": 9.539469137120893e-05,
      "loss": 1.7707,
      "step": 3980
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.3213847875595093,
      "learning_rate": 9.537188371611707e-05,
      "loss": 1.8218,
      "step": 3990
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0751019716262817,
      "learning_rate": 9.5349022463644e-05,
      "loss": 1.9629,
      "step": 4000
    },
    {
      "epoch": 0.42,
      "eval_loss": 1.887223243713379,
      "eval_runtime": 366.731,
      "eval_samples_per_second": 23.358,
      "eval_steps_per_second": 23.358,
      "step": 4000
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.1644079685211182,
      "learning_rate": 9.532610764079546e-05,
      "loss": 1.7939,
      "step": 4010
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0794748067855835,
      "learning_rate": 9.530313927464055e-05,
      "loss": 1.881,
      "step": 4020
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3728387355804443,
      "learning_rate": 9.528011739231158e-05,
      "loss": 1.7809,
      "step": 4030
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2181425094604492,
      "learning_rate": 9.525704202100408e-05,
      "loss": 1.8918,
      "step": 4040
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3761200904846191,
      "learning_rate": 9.523391318797678e-05,
      "loss": 1.8994,
      "step": 4050
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.1817177534103394,
      "learning_rate": 9.521073092055153e-05,
      "loss": 1.8938,
      "step": 4060
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.1208860874176025,
      "learning_rate": 9.518749524611335e-05,
      "loss": 1.8716,
      "step": 4070
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.327409029006958,
      "learning_rate": 9.51642061921103e-05,
      "loss": 1.8638,
      "step": 4080
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.4683349132537842,
      "learning_rate": 9.514086378605355e-05,
      "loss": 1.8589,
      "step": 4090
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0925639867782593,
      "learning_rate": 9.511746805551724e-05,
      "loss": 2.0422,
      "step": 4100
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.1538748741149902,
      "learning_rate": 9.509401902813854e-05,
      "loss": 1.8295,
      "step": 4110
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.3187772035598755,
      "learning_rate": 9.507051673161757e-05,
      "loss": 1.8934,
      "step": 4120
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.1880378723144531,
      "learning_rate": 9.504696119371738e-05,
      "loss": 1.9451,
      "step": 4130
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.6231422424316406,
      "learning_rate": 9.502335244226388e-05,
      "loss": 1.8785,
      "step": 4140
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.3791389465332031,
      "learning_rate": 9.499969050514588e-05,
      "loss": 1.7933,
      "step": 4150
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.291886568069458,
      "learning_rate": 9.4975975410315e-05,
      "loss": 1.9307,
      "step": 4160
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.5937042236328125,
      "learning_rate": 9.495220718578568e-05,
      "loss": 1.8614,
      "step": 4170
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.6371915340423584,
      "learning_rate": 9.492838585963507e-05,
      "loss": 1.8209,
      "step": 4180
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.1108934879302979,
      "learning_rate": 9.49045114600031e-05,
      "loss": 1.8949,
      "step": 4190
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.477900743484497,
      "learning_rate": 9.488058401509238e-05,
      "loss": 2.0506,
      "step": 4200
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.300325632095337,
      "learning_rate": 9.485660355316815e-05,
      "loss": 1.9421,
      "step": 4210
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.350095272064209,
      "learning_rate": 9.483257010255834e-05,
      "loss": 1.8055,
      "step": 4220
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.9414539337158203,
      "learning_rate": 9.48084836916534e-05,
      "loss": 1.9022,
      "step": 4230
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.220956802368164,
      "learning_rate": 9.478434434890642e-05,
      "loss": 1.8253,
      "step": 4240
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0120455026626587,
      "learning_rate": 9.476015210283297e-05,
      "loss": 1.8304,
      "step": 4250
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.062432885169983,
      "learning_rate": 9.47359069820111e-05,
      "loss": 1.9044,
      "step": 4260
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.574942708015442,
      "learning_rate": 9.471160901508136e-05,
      "loss": 1.8617,
      "step": 4270
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.4404311180114746,
      "learning_rate": 9.468725823074672e-05,
      "loss": 1.9782,
      "step": 4280
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.2559937238693237,
      "learning_rate": 9.466285465777251e-05,
      "loss": 1.7704,
      "step": 4290
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.2168586254119873,
      "learning_rate": 9.463839832498649e-05,
      "loss": 1.9625,
      "step": 4300
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.1843544244766235,
      "learning_rate": 9.461388926127864e-05,
      "loss": 1.9876,
      "step": 4310
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.7632819414138794,
      "learning_rate": 9.45893274956013e-05,
      "loss": 1.8168,
      "step": 4320
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.2343624830245972,
      "learning_rate": 9.456471305696907e-05,
      "loss": 1.8431,
      "step": 4330
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.147160530090332,
      "learning_rate": 9.454004597445876e-05,
      "loss": 1.8445,
      "step": 4340
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0489610433578491,
      "learning_rate": 9.451532627720936e-05,
      "loss": 1.8383,
      "step": 4350
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.4890613555908203,
      "learning_rate": 9.4490553994422e-05,
      "loss": 1.8883,
      "step": 4360
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0732814073562622,
      "learning_rate": 9.446572915535996e-05,
      "loss": 1.8087,
      "step": 4370
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.1092497110366821,
      "learning_rate": 9.444085178934858e-05,
      "loss": 1.8792,
      "step": 4380
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1456178426742554,
      "learning_rate": 9.441592192577529e-05,
      "loss": 1.8087,
      "step": 4390
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.2989466190338135,
      "learning_rate": 9.439093959408945e-05,
      "loss": 1.8452,
      "step": 4400
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.0722458362579346,
      "learning_rate": 9.43659048238025e-05,
      "loss": 1.7455,
      "step": 4410
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.255698561668396,
      "learning_rate": 9.434081764448776e-05,
      "loss": 1.9021,
      "step": 4420
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.3022916316986084,
      "learning_rate": 9.431567808578049e-05,
      "loss": 1.8431,
      "step": 4430
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.2129663228988647,
      "learning_rate": 9.42904861773778e-05,
      "loss": 1.9074,
      "step": 4440
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.587853193283081,
      "learning_rate": 9.426524194903865e-05,
      "loss": 1.7934,
      "step": 4450
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1769555807113647,
      "learning_rate": 9.423994543058385e-05,
      "loss": 1.7808,
      "step": 4460
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.2619781494140625,
      "learning_rate": 9.421459665189592e-05,
      "loss": 1.8456,
      "step": 4470
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1261783838272095,
      "learning_rate": 9.41891956429191e-05,
      "loss": 1.9505,
      "step": 4480
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1357741355895996,
      "learning_rate": 9.416374243365942e-05,
      "loss": 1.8613,
      "step": 4490
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2594653367996216,
      "learning_rate": 9.413823705418448e-05,
      "loss": 1.8378,
      "step": 4500
    },
    {
      "epoch": 0.47,
      "eval_loss": 1.8791934251785278,
      "eval_runtime": 366.8294,
      "eval_samples_per_second": 23.351,
      "eval_steps_per_second": 23.351,
      "step": 4500
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1135061979293823,
      "learning_rate": 9.411267953462357e-05,
      "loss": 1.9997,
      "step": 4510
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3938403129577637,
      "learning_rate": 9.408706990516752e-05,
      "loss": 1.909,
      "step": 4520
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.0880783796310425,
      "learning_rate": 9.406140819606876e-05,
      "loss": 1.9161,
      "step": 4530
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.363459587097168,
      "learning_rate": 9.403569443764125e-05,
      "loss": 1.9128,
      "step": 4540
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1134246587753296,
      "learning_rate": 9.400992866026039e-05,
      "loss": 1.9034,
      "step": 4550
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1541831493377686,
      "learning_rate": 9.398411089436303e-05,
      "loss": 1.8053,
      "step": 4560
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2605434656143188,
      "learning_rate": 9.395824117044749e-05,
      "loss": 1.8713,
      "step": 4570
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0941296815872192,
      "learning_rate": 9.393231951907343e-05,
      "loss": 1.9537,
      "step": 4580
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.581882357597351,
      "learning_rate": 9.390634597086181e-05,
      "loss": 1.8902,
      "step": 4590
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.228540062904358,
      "learning_rate": 9.388032055649499e-05,
      "loss": 1.9236,
      "step": 4600
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.1632477045059204,
      "learning_rate": 9.385424330671653e-05,
      "loss": 1.9382,
      "step": 4610
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.6765294075012207,
      "learning_rate": 9.382811425233124e-05,
      "loss": 1.8733,
      "step": 4620
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0772429704666138,
      "learning_rate": 9.380193342420514e-05,
      "loss": 1.8786,
      "step": 4630
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3676981925964355,
      "learning_rate": 9.377570085326537e-05,
      "loss": 1.8658,
      "step": 4640
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3036165237426758,
      "learning_rate": 9.374941657050025e-05,
      "loss": 1.9467,
      "step": 4650
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3713546991348267,
      "learning_rate": 9.372308060695913e-05,
      "loss": 1.8217,
      "step": 4660
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3181354999542236,
      "learning_rate": 9.369669299375245e-05,
      "loss": 1.8638,
      "step": 4670
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.98048335313797,
      "learning_rate": 9.367025376205167e-05,
      "loss": 1.9657,
      "step": 4680
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4917519092559814,
      "learning_rate": 9.364376294308917e-05,
      "loss": 1.7734,
      "step": 4690
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2729915380477905,
      "learning_rate": 9.361722056815832e-05,
      "loss": 1.8919,
      "step": 4700
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.6618400812149048,
      "learning_rate": 9.359062666861341e-05,
      "loss": 1.8066,
      "step": 4710
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.1908977031707764,
      "learning_rate": 9.356398127586949e-05,
      "loss": 1.8995,
      "step": 4720
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.1560096740722656,
      "learning_rate": 9.353728442140259e-05,
      "loss": 1.8534,
      "step": 4730
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8150779008865356,
      "learning_rate": 9.351053613674942e-05,
      "loss": 1.8883,
      "step": 4740
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8764927387237549,
      "learning_rate": 9.348373645350748e-05,
      "loss": 1.8503,
      "step": 4750
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.6999326944351196,
      "learning_rate": 9.3456885403335e-05,
      "loss": 1.819,
      "step": 4760
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.4342561960220337,
      "learning_rate": 9.342998301795086e-05,
      "loss": 1.7594,
      "step": 4770
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2796025276184082,
      "learning_rate": 9.340302932913457e-05,
      "loss": 1.774,
      "step": 4780
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2454503774642944,
      "learning_rate": 9.33760243687263e-05,
      "loss": 1.878,
      "step": 4790
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.3131487369537354,
      "learning_rate": 9.334896816862677e-05,
      "loss": 1.9965,
      "step": 4800
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7950263023376465,
      "learning_rate": 9.332186076079719e-05,
      "loss": 1.9098,
      "step": 4810
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1630984544754028,
      "learning_rate": 9.329470217725931e-05,
      "loss": 1.8658,
      "step": 4820
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1864477396011353,
      "learning_rate": 9.326749245009527e-05,
      "loss": 1.887,
      "step": 4830
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8202589750289917,
      "learning_rate": 9.324023161144772e-05,
      "loss": 1.8267,
      "step": 4840
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2011773586273193,
      "learning_rate": 9.321291969351958e-05,
      "loss": 1.9654,
      "step": 4850
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.3985005617141724,
      "learning_rate": 9.318555672857421e-05,
      "loss": 1.8584,
      "step": 4860
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.0834888219833374,
      "learning_rate": 9.31581427489352e-05,
      "loss": 1.9065,
      "step": 4870
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.4202816486358643,
      "learning_rate": 9.31306777869864e-05,
      "loss": 1.7748,
      "step": 4880
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.3004167079925537,
      "learning_rate": 9.310316187517198e-05,
      "loss": 1.751,
      "step": 4890
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.217227578163147,
      "learning_rate": 9.307559504599617e-05,
      "loss": 1.8208,
      "step": 4900
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.1922448873519897,
      "learning_rate": 9.304797733202344e-05,
      "loss": 1.789,
      "step": 4910
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.393514633178711,
      "learning_rate": 9.302030876587833e-05,
      "loss": 1.7764,
      "step": 4920
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2780038118362427,
      "learning_rate": 9.299258938024545e-05,
      "loss": 1.8329,
      "step": 4930
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.318576455116272,
      "learning_rate": 9.296481920786944e-05,
      "loss": 1.9342,
      "step": 4940
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.407495379447937,
      "learning_rate": 9.293699828155496e-05,
      "loss": 1.9435,
      "step": 4950
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.402744174003601,
      "learning_rate": 9.29091266341666e-05,
      "loss": 1.7547,
      "step": 4960
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5588665008544922,
      "learning_rate": 9.28812042986289e-05,
      "loss": 1.8727,
      "step": 4970
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.1831389665603638,
      "learning_rate": 9.285323130792622e-05,
      "loss": 1.8712,
      "step": 4980
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.1076412200927734,
      "learning_rate": 9.282520769510284e-05,
      "loss": 1.9272,
      "step": 4990
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5933916568756104,
      "learning_rate": 9.279713349326274e-05,
      "loss": 1.8603,
      "step": 5000
    },
    {
      "epoch": 0.52,
      "eval_loss": 1.8738056421279907,
      "eval_runtime": 366.5324,
      "eval_samples_per_second": 23.37,
      "eval_steps_per_second": 23.37,
      "step": 5000
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.7111289501190186,
      "learning_rate": 9.276900873556973e-05,
      "loss": 1.8577,
      "step": 5010
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.263175129890442,
      "learning_rate": 9.274083345524733e-05,
      "loss": 1.8955,
      "step": 5020
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.2468907833099365,
      "learning_rate": 9.271260768557873e-05,
      "loss": 1.8501,
      "step": 5030
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.1587516069412231,
      "learning_rate": 9.268433145990676e-05,
      "loss": 1.9023,
      "step": 5040
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0422303676605225,
      "learning_rate": 9.265600481163388e-05,
      "loss": 1.8768,
      "step": 5050
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.430557370185852,
      "learning_rate": 9.262762777422207e-05,
      "loss": 1.9223,
      "step": 5060
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.196294903755188,
      "learning_rate": 9.259920038119288e-05,
      "loss": 1.8049,
      "step": 5070
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.4902108907699585,
      "learning_rate": 9.25707226661273e-05,
      "loss": 2.0202,
      "step": 5080
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.2070845365524292,
      "learning_rate": 9.25421946626658e-05,
      "loss": 1.7898,
      "step": 5090
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.3973077535629272,
      "learning_rate": 9.251361640450825e-05,
      "loss": 1.946,
      "step": 5100
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.3325005769729614,
      "learning_rate": 9.248498792541388e-05,
      "loss": 1.8537,
      "step": 5110
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.0888108015060425,
      "learning_rate": 9.245630925920124e-05,
      "loss": 1.8546,
      "step": 5120
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.373206615447998,
      "learning_rate": 9.242758043974815e-05,
      "loss": 1.8953,
      "step": 5130
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1667509078979492,
      "learning_rate": 9.239880150099172e-05,
      "loss": 1.9386,
      "step": 5140
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.5854040384292603,
      "learning_rate": 9.236997247692823e-05,
      "loss": 1.8428,
      "step": 5150
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.1624703407287598,
      "learning_rate": 9.234109340161316e-05,
      "loss": 1.8631,
      "step": 5160
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.4796473979949951,
      "learning_rate": 9.231216430916105e-05,
      "loss": 1.9173,
      "step": 5170
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.0457905530929565,
      "learning_rate": 9.228318523374559e-05,
      "loss": 1.9208,
      "step": 5180
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.293452262878418,
      "learning_rate": 9.225415620959948e-05,
      "loss": 1.8372,
      "step": 5190
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.4192715883255005,
      "learning_rate": 9.222507727101446e-05,
      "loss": 1.777,
      "step": 5200
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.1395723819732666,
      "learning_rate": 9.219594845234117e-05,
      "loss": 1.8119,
      "step": 5210
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.3244692087173462,
      "learning_rate": 9.216676978798924e-05,
      "loss": 1.8224,
      "step": 5220
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8815300464630127,
      "learning_rate": 9.213754131242714e-05,
      "loss": 1.9229,
      "step": 5230
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.0769461393356323,
      "learning_rate": 9.210826306018219e-05,
      "loss": 1.7372,
      "step": 5240
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8527717590332031,
      "learning_rate": 9.207893506584053e-05,
      "loss": 1.9848,
      "step": 5250
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.2815076112747192,
      "learning_rate": 9.204955736404703e-05,
      "loss": 1.7749,
      "step": 5260
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.0987316370010376,
      "learning_rate": 9.202012998950531e-05,
      "loss": 1.8221,
      "step": 5270
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8387808799743652,
      "learning_rate": 9.199065297697764e-05,
      "loss": 1.8234,
      "step": 5280
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.3636865615844727,
      "learning_rate": 9.196112636128493e-05,
      "loss": 1.8229,
      "step": 5290
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.6281315088272095,
      "learning_rate": 9.193155017730672e-05,
      "loss": 1.8349,
      "step": 5300
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.2790933847427368,
      "learning_rate": 9.190192445998107e-05,
      "loss": 1.9077,
      "step": 5310
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.3766629695892334,
      "learning_rate": 9.187224924430455e-05,
      "loss": 1.8087,
      "step": 5320
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.4151496887207031,
      "learning_rate": 9.18425245653322e-05,
      "loss": 1.8439,
      "step": 5330
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.2307305335998535,
      "learning_rate": 9.181275045817756e-05,
      "loss": 1.8136,
      "step": 5340
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.088962435722351,
      "learning_rate": 9.178292695801245e-05,
      "loss": 1.9969,
      "step": 5350
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.0592089891433716,
      "learning_rate": 9.175305410006712e-05,
      "loss": 1.9096,
      "step": 5360
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.1332486867904663,
      "learning_rate": 9.172313191963009e-05,
      "loss": 1.8339,
      "step": 5370
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.3760439157485962,
      "learning_rate": 9.169316045204814e-05,
      "loss": 1.8921,
      "step": 5380
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.3057087659835815,
      "learning_rate": 9.16631397327263e-05,
      "loss": 1.8437,
      "step": 5390
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.5352245569229126,
      "learning_rate": 9.163306979712776e-05,
      "loss": 1.8739,
      "step": 5400
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6762914657592773,
      "learning_rate": 9.160295068077384e-05,
      "loss": 1.7059,
      "step": 5410
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.5340338945388794,
      "learning_rate": 9.1572782419244e-05,
      "loss": 1.7821,
      "step": 5420
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.3205645084381104,
      "learning_rate": 9.154256504817571e-05,
      "loss": 1.8232,
      "step": 5430
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.1378345489501953,
      "learning_rate": 9.151229860326446e-05,
      "loss": 1.8667,
      "step": 5440
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.2626161575317383,
      "learning_rate": 9.148198312026372e-05,
      "loss": 1.9885,
      "step": 5450
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.318849802017212,
      "learning_rate": 9.145161863498488e-05,
      "loss": 1.9261,
      "step": 5460
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.3650269508361816,
      "learning_rate": 9.142120518329724e-05,
      "loss": 1.8429,
      "step": 5470
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.2786381244659424,
      "learning_rate": 9.139074280112792e-05,
      "loss": 1.8115,
      "step": 5480
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.4478602409362793,
      "learning_rate": 9.136023152446183e-05,
      "loss": 1.9421,
      "step": 5490
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.3948795795440674,
      "learning_rate": 9.132967138934167e-05,
      "loss": 1.7926,
      "step": 5500
    },
    {
      "epoch": 0.57,
      "eval_loss": 1.8695440292358398,
      "eval_runtime": 367.1566,
      "eval_samples_per_second": 23.331,
      "eval_steps_per_second": 23.331,
      "step": 5500
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.2317475080490112,
      "learning_rate": 9.129906243186784e-05,
      "loss": 1.7832,
      "step": 5510
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.1972947120666504,
      "learning_rate": 9.126840468819842e-05,
      "loss": 1.796,
      "step": 5520
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.0411559343338013,
      "learning_rate": 9.12376981945491e-05,
      "loss": 1.9245,
      "step": 5530
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.0191385746002197,
      "learning_rate": 9.12069429871932e-05,
      "loss": 1.8193,
      "step": 5540
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6832857131958008,
      "learning_rate": 9.117613910246152e-05,
      "loss": 1.9005,
      "step": 5550
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.3700491189956665,
      "learning_rate": 9.114528657674243e-05,
      "loss": 1.8632,
      "step": 5560
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.3630105257034302,
      "learning_rate": 9.111438544648175e-05,
      "loss": 1.9948,
      "step": 5570
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.22893488407135,
      "learning_rate": 9.108343574818264e-05,
      "loss": 1.917,
      "step": 5580
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.3166815042495728,
      "learning_rate": 9.105243751840571e-05,
      "loss": 1.8755,
      "step": 5590
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.3575091361999512,
      "learning_rate": 9.102139079376888e-05,
      "loss": 1.712,
      "step": 5600
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.2646842002868652,
      "learning_rate": 9.099029561094738e-05,
      "loss": 1.7134,
      "step": 5610
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.4692426919937134,
      "learning_rate": 9.095915200667361e-05,
      "loss": 1.8815,
      "step": 5620
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.2447230815887451,
      "learning_rate": 9.092796001773727e-05,
      "loss": 1.7277,
      "step": 5630
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.5459586381912231,
      "learning_rate": 9.089671968098514e-05,
      "loss": 1.9536,
      "step": 5640
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.3183249235153198,
      "learning_rate": 9.086543103332113e-05,
      "loss": 1.8392,
      "step": 5650
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.1779793500900269,
      "learning_rate": 9.083409411170623e-05,
      "loss": 1.7476,
      "step": 5660
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.1092090606689453,
      "learning_rate": 9.080270895315846e-05,
      "loss": 1.7466,
      "step": 5670
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.8177053928375244,
      "learning_rate": 9.07712755947528e-05,
      "loss": 1.7812,
      "step": 5680
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.4125479459762573,
      "learning_rate": 9.07397940736212e-05,
      "loss": 1.9731,
      "step": 5690
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.4386640787124634,
      "learning_rate": 9.070826442695247e-05,
      "loss": 1.8456,
      "step": 5700
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.0971543788909912,
      "learning_rate": 9.06766866919923e-05,
      "loss": 1.8278,
      "step": 5710
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.330437183380127,
      "learning_rate": 9.064506090604317e-05,
      "loss": 1.8494,
      "step": 5720
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.157304048538208,
      "learning_rate": 9.061338710646431e-05,
      "loss": 1.8248,
      "step": 5730
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.4588769674301147,
      "learning_rate": 9.058166533067169e-05,
      "loss": 1.8175,
      "step": 5740
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.6504454612731934,
      "learning_rate": 9.054989561613796e-05,
      "loss": 1.9753,
      "step": 5750
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.2827867269515991,
      "learning_rate": 9.051807800039238e-05,
      "loss": 1.8489,
      "step": 5760
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.179870843887329,
      "learning_rate": 9.048621252102079e-05,
      "loss": 1.713,
      "step": 5770
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0548617839813232,
      "learning_rate": 9.045429921566559e-05,
      "loss": 1.8562,
      "step": 5780
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.2447856664657593,
      "learning_rate": 9.042233812202567e-05,
      "loss": 1.7899,
      "step": 5790
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.5216083526611328,
      "learning_rate": 9.039032927785636e-05,
      "loss": 1.8862,
      "step": 5800
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.155204176902771,
      "learning_rate": 9.035827272096942e-05,
      "loss": 1.8658,
      "step": 5810
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.2172291278839111,
      "learning_rate": 9.032616848923297e-05,
      "loss": 1.8849,
      "step": 5820
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.5079632997512817,
      "learning_rate": 9.029401662057141e-05,
      "loss": 1.7979,
      "step": 5830
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.6203091144561768,
      "learning_rate": 9.026181715296546e-05,
      "loss": 1.8268,
      "step": 5840
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.3764594793319702,
      "learning_rate": 9.022957012445206e-05,
      "loss": 1.9723,
      "step": 5850
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.9970411062240601,
      "learning_rate": 9.01972755731243e-05,
      "loss": 1.8102,
      "step": 5860
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.5408045053482056,
      "learning_rate": 9.016493353713143e-05,
      "loss": 1.8468,
      "step": 5870
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.1895217895507812,
      "learning_rate": 9.013254405467881e-05,
      "loss": 1.7975,
      "step": 5880
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.2412304878234863,
      "learning_rate": 9.010010716402782e-05,
      "loss": 1.8264,
      "step": 5890
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.257868766784668,
      "learning_rate": 9.006762290349588e-05,
      "loss": 1.8322,
      "step": 5900
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.3821626901626587,
      "learning_rate": 9.003509131145631e-05,
      "loss": 1.8156,
      "step": 5910
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.2257890701293945,
      "learning_rate": 9.000251242633839e-05,
      "loss": 1.8096,
      "step": 5920
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3564375638961792,
      "learning_rate": 8.996988628662725e-05,
      "loss": 1.8504,
      "step": 5930
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.1027714014053345,
      "learning_rate": 8.993721293086383e-05,
      "loss": 1.7818,
      "step": 5940
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3075871467590332,
      "learning_rate": 8.99044923976449e-05,
      "loss": 1.844,
      "step": 5950
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.2144945859909058,
      "learning_rate": 8.987172472562289e-05,
      "loss": 1.9179,
      "step": 5960
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.2007830142974854,
      "learning_rate": 8.983890995350593e-05,
      "loss": 1.786,
      "step": 5970
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.180575966835022,
      "learning_rate": 8.980604812005781e-05,
      "loss": 1.9179,
      "step": 5980
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.1973254680633545,
      "learning_rate": 8.977313926409794e-05,
      "loss": 1.8636,
      "step": 5990
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.1221868991851807,
      "learning_rate": 8.97401834245012e-05,
      "loss": 1.9403,
      "step": 6000
    },
    {
      "epoch": 0.62,
      "eval_loss": 1.8636480569839478,
      "eval_runtime": 366.3202,
      "eval_samples_per_second": 23.384,
      "eval_steps_per_second": 23.384,
      "step": 6000
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.111856460571289,
      "learning_rate": 8.970718064019806e-05,
      "loss": 1.8723,
      "step": 6010
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.421526312828064,
      "learning_rate": 8.967413095017436e-05,
      "loss": 1.8154,
      "step": 6020
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.296915888786316,
      "learning_rate": 8.96410343934714e-05,
      "loss": 1.912,
      "step": 6030
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6496514081954956,
      "learning_rate": 8.960789100918582e-05,
      "loss": 1.9171,
      "step": 6040
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.0320074558258057,
      "learning_rate": 8.957470083646962e-05,
      "loss": 1.9179,
      "step": 6050
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.3065941333770752,
      "learning_rate": 8.954146391453002e-05,
      "loss": 1.9099,
      "step": 6060
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.4124634265899658,
      "learning_rate": 8.950818028262951e-05,
      "loss": 1.9097,
      "step": 6070
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.1614569425582886,
      "learning_rate": 8.947484998008568e-05,
      "loss": 1.9621,
      "step": 6080
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.0338237285614014,
      "learning_rate": 8.944147304627136e-05,
      "loss": 1.9046,
      "step": 6090
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.331355094909668,
      "learning_rate": 8.940804952061437e-05,
      "loss": 1.9202,
      "step": 6100
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.4524503946304321,
      "learning_rate": 8.937457944259761e-05,
      "loss": 1.8059,
      "step": 6110
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3773236274719238,
      "learning_rate": 8.9341062851759e-05,
      "loss": 1.7755,
      "step": 6120
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.2229775190353394,
      "learning_rate": 8.930749978769138e-05,
      "loss": 1.7271,
      "step": 6130
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3836688995361328,
      "learning_rate": 8.927389029004242e-05,
      "loss": 1.8926,
      "step": 6140
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.620068073272705,
      "learning_rate": 8.924023439851476e-05,
      "loss": 1.8374,
      "step": 6150
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.505396842956543,
      "learning_rate": 8.920653215286579e-05,
      "loss": 1.87,
      "step": 6160
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.378472924232483,
      "learning_rate": 8.917278359290762e-05,
      "loss": 1.8653,
      "step": 6170
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.2217961549758911,
      "learning_rate": 8.913898875850713e-05,
      "loss": 1.718,
      "step": 6180
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.378886103630066,
      "learning_rate": 8.910514768958584e-05,
      "loss": 1.8023,
      "step": 6190
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3640000820159912,
      "learning_rate": 8.90712604261199e-05,
      "loss": 1.876,
      "step": 6200
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.214893102645874,
      "learning_rate": 8.903732700814e-05,
      "loss": 1.7,
      "step": 6210
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.3208630084991455,
      "learning_rate": 8.900334747573138e-05,
      "loss": 1.852,
      "step": 6220
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.3683927059173584,
      "learning_rate": 8.896932186903373e-05,
      "loss": 1.8835,
      "step": 6230
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.2017478942871094,
      "learning_rate": 8.893525022824119e-05,
      "loss": 1.9196,
      "step": 6240
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.278352975845337,
      "learning_rate": 8.890113259360227e-05,
      "loss": 1.8306,
      "step": 6250
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.4690165519714355,
      "learning_rate": 8.886696900541982e-05,
      "loss": 1.8655,
      "step": 6260
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.1104421615600586,
      "learning_rate": 8.883275950405094e-05,
      "loss": 1.8107,
      "step": 6270
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.164045810699463,
      "learning_rate": 8.879850412990702e-05,
      "loss": 1.818,
      "step": 6280
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.3412177562713623,
      "learning_rate": 8.87642029234536e-05,
      "loss": 1.8023,
      "step": 6290
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.2280077934265137,
      "learning_rate": 8.872985592521037e-05,
      "loss": 1.821,
      "step": 6300
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.2011808156967163,
      "learning_rate": 8.869546317575112e-05,
      "loss": 1.8641,
      "step": 6310
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1954251527786255,
      "learning_rate": 8.86610247157037e-05,
      "loss": 1.7567,
      "step": 6320
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.927219033241272,
      "learning_rate": 8.862654058574993e-05,
      "loss": 1.8436,
      "step": 6330
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.3722741603851318,
      "learning_rate": 8.859201082662559e-05,
      "loss": 1.8119,
      "step": 6340
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.5894099473953247,
      "learning_rate": 8.855743547912035e-05,
      "loss": 1.7959,
      "step": 6350
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.5844143629074097,
      "learning_rate": 8.852281458407774e-05,
      "loss": 1.8363,
      "step": 6360
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.390685796737671,
      "learning_rate": 8.849161686919551e-05,
      "loss": 1.7826,
      "step": 6370
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.3025015592575073,
      "learning_rate": 8.845690954654853e-05,
      "loss": 1.8485,
      "step": 6380
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1227631568908691,
      "learning_rate": 8.842215679511453e-05,
      "loss": 1.8253,
      "step": 6390
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.5197064876556396,
      "learning_rate": 8.838735865594662e-05,
      "loss": 1.7519,
      "step": 6400
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.2879068851470947,
      "learning_rate": 8.835251517015152e-05,
      "loss": 1.8252,
      "step": 6410
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.164923906326294,
      "learning_rate": 8.83176263788895e-05,
      "loss": 1.8626,
      "step": 6420
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.2622877359390259,
      "learning_rate": 8.828269232337435e-05,
      "loss": 1.872,
      "step": 6430
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.4164596796035767,
      "learning_rate": 8.824771304487337e-05,
      "loss": 1.9556,
      "step": 6440
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.710131287574768,
      "learning_rate": 8.821268858470724e-05,
      "loss": 1.7991,
      "step": 6450
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.2503412961959839,
      "learning_rate": 8.817761898425004e-05,
      "loss": 1.834,
      "step": 6460
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.2369825839996338,
      "learning_rate": 8.814250428492913e-05,
      "loss": 1.8245,
      "step": 6470
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.2477402687072754,
      "learning_rate": 8.81073445282252e-05,
      "loss": 1.8402,
      "step": 6480
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.3350290060043335,
      "learning_rate": 8.807213975567214e-05,
      "loss": 1.9946,
      "step": 6490
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.773672342300415,
      "learning_rate": 8.803689000885701e-05,
      "loss": 1.779,
      "step": 6500
    },
    {
      "epoch": 0.67,
      "eval_loss": 1.8612024784088135,
      "eval_runtime": 366.6984,
      "eval_samples_per_second": 23.36,
      "eval_steps_per_second": 23.36,
      "step": 6500
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.1529189348220825,
      "learning_rate": 8.800159532942002e-05,
      "loss": 1.7936,
      "step": 6510
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.3035722970962524,
      "learning_rate": 8.796625575905444e-05,
      "loss": 1.9338,
      "step": 6520
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.2999241352081299,
      "learning_rate": 8.793087133950655e-05,
      "loss": 1.8808,
      "step": 6530
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.4964187145233154,
      "learning_rate": 8.789544211257566e-05,
      "loss": 1.7679,
      "step": 6540
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5242985486984253,
      "learning_rate": 8.785996812011398e-05,
      "loss": 1.8812,
      "step": 6550
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.2304612398147583,
      "learning_rate": 8.782444940402658e-05,
      "loss": 1.8869,
      "step": 6560
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9642748832702637,
      "learning_rate": 8.778888600627144e-05,
      "loss": 1.9014,
      "step": 6570
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9519716501235962,
      "learning_rate": 8.775327796885922e-05,
      "loss": 1.997,
      "step": 6580
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.4832923412322998,
      "learning_rate": 8.771762533385337e-05,
      "loss": 1.8102,
      "step": 6590
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.442187786102295,
      "learning_rate": 8.768192814337002e-05,
      "loss": 2.0182,
      "step": 6600
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.3790661096572876,
      "learning_rate": 8.764618643957792e-05,
      "loss": 1.9122,
      "step": 6610
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.324776291847229,
      "learning_rate": 8.761040026469842e-05,
      "loss": 1.8889,
      "step": 6620
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.36198091506958,
      "learning_rate": 8.757456966100542e-05,
      "loss": 1.8098,
      "step": 6630
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.1700446605682373,
      "learning_rate": 8.75386946708252e-05,
      "loss": 1.9096,
      "step": 6640
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.1447672843933105,
      "learning_rate": 8.750277533653662e-05,
      "loss": 1.738,
      "step": 6650
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.339389443397522,
      "learning_rate": 8.746681170057083e-05,
      "loss": 1.9721,
      "step": 6660
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.314806580543518,
      "learning_rate": 8.743080380541133e-05,
      "loss": 1.8307,
      "step": 6670
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.4162870645523071,
      "learning_rate": 8.739475169359392e-05,
      "loss": 1.8641,
      "step": 6680
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.5134984254837036,
      "learning_rate": 8.735865540770662e-05,
      "loss": 1.8785,
      "step": 6690
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.265143871307373,
      "learning_rate": 8.732251499038962e-05,
      "loss": 1.7251,
      "step": 6700
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2712703943252563,
      "learning_rate": 8.728633048433528e-05,
      "loss": 1.8724,
      "step": 6710
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.3843508958816528,
      "learning_rate": 8.7250101932288e-05,
      "loss": 1.9399,
      "step": 6720
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2522175312042236,
      "learning_rate": 8.721382937704424e-05,
      "loss": 1.8431,
      "step": 6730
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.1972858905792236,
      "learning_rate": 8.717751286145241e-05,
      "loss": 1.8636,
      "step": 6740
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.5503087043762207,
      "learning_rate": 8.71411524284129e-05,
      "loss": 1.8036,
      "step": 6750
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2269750833511353,
      "learning_rate": 8.710474812087792e-05,
      "loss": 1.9512,
      "step": 6760
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.194738745689392,
      "learning_rate": 8.706829998185156e-05,
      "loss": 1.7879,
      "step": 6770
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.0451303720474243,
      "learning_rate": 8.703180805438966e-05,
      "loss": 1.8817,
      "step": 6780
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2489569187164307,
      "learning_rate": 8.69952723815998e-05,
      "loss": 1.9774,
      "step": 6790
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.3844479322433472,
      "learning_rate": 8.695869300664118e-05,
      "loss": 1.8225,
      "step": 6800
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.345611333847046,
      "learning_rate": 8.692206997272474e-05,
      "loss": 1.7852,
      "step": 6810
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.0711076259613037,
      "learning_rate": 8.688540332311288e-05,
      "loss": 1.7701,
      "step": 6820
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.37032151222229,
      "learning_rate": 8.684869310111958e-05,
      "loss": 1.9893,
      "step": 6830
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.2678624391555786,
      "learning_rate": 8.68119393501103e-05,
      "loss": 1.8951,
      "step": 6840
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.196427822113037,
      "learning_rate": 8.677514211350188e-05,
      "loss": 1.8451,
      "step": 6850
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.137353777885437,
      "learning_rate": 8.673830143476258e-05,
      "loss": 1.8485,
      "step": 6860
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.2530993223190308,
      "learning_rate": 8.67014173574119e-05,
      "loss": 1.8541,
      "step": 6870
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.29634428024292,
      "learning_rate": 8.666448992502071e-05,
      "loss": 1.8376,
      "step": 6880
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.4641207456588745,
      "learning_rate": 8.6627519181211e-05,
      "loss": 1.8412,
      "step": 6890
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8042821884155273,
      "learning_rate": 8.659050516965598e-05,
      "loss": 1.9223,
      "step": 6900
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.2969146966934204,
      "learning_rate": 8.655344793407996e-05,
      "loss": 1.7743,
      "step": 6910
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.4755163192749023,
      "learning_rate": 8.651634751825828e-05,
      "loss": 1.85,
      "step": 6920
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.2213678359985352,
      "learning_rate": 8.647920396601734e-05,
      "loss": 1.9045,
      "step": 6930
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.3431546688079834,
      "learning_rate": 8.644201732123446e-05,
      "loss": 1.8042,
      "step": 6940
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.3679207563400269,
      "learning_rate": 8.640478762783788e-05,
      "loss": 1.7534,
      "step": 6950
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.1546931266784668,
      "learning_rate": 8.636751492980667e-05,
      "loss": 1.9044,
      "step": 6960
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0265477895736694,
      "learning_rate": 8.633019927117075e-05,
      "loss": 1.8539,
      "step": 6970
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0683962106704712,
      "learning_rate": 8.629284069601074e-05,
      "loss": 1.9993,
      "step": 6980
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.2882198095321655,
      "learning_rate": 8.625543924845798e-05,
      "loss": 1.9408,
      "step": 6990
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.4180341958999634,
      "learning_rate": 8.621799497269444e-05,
      "loss": 1.9105,
      "step": 7000
    },
    {
      "epoch": 0.73,
      "eval_loss": 1.8564287424087524,
      "eval_runtime": 366.7632,
      "eval_samples_per_second": 23.356,
      "eval_steps_per_second": 23.356,
      "step": 7000
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.1581506729125977,
      "learning_rate": 8.61805079129527e-05,
      "loss": 1.8346,
      "step": 7010
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.2686560153961182,
      "learning_rate": 8.614297811351586e-05,
      "loss": 1.9806,
      "step": 7020
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9375722408294678,
      "learning_rate": 8.610540561871754e-05,
      "loss": 1.87,
      "step": 7030
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.0610846281051636,
      "learning_rate": 8.606779047294178e-05,
      "loss": 1.7586,
      "step": 7040
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.2211990356445312,
      "learning_rate": 8.603013272062297e-05,
      "loss": 1.8201,
      "step": 7050
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.256550669670105,
      "learning_rate": 8.599243240624589e-05,
      "loss": 1.871,
      "step": 7060
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.1612802743911743,
      "learning_rate": 8.595468957434554e-05,
      "loss": 1.7348,
      "step": 7070
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.4552675485610962,
      "learning_rate": 8.591690426950721e-05,
      "loss": 1.859,
      "step": 7080
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.2138007879257202,
      "learning_rate": 8.587907653636628e-05,
      "loss": 1.7921,
      "step": 7090
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.290405511856079,
      "learning_rate": 8.584120641960833e-05,
      "loss": 1.7628,
      "step": 7100
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.389992117881775,
      "learning_rate": 8.580329396396898e-05,
      "loss": 1.8854,
      "step": 7110
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.4354197978973389,
      "learning_rate": 8.576533921423384e-05,
      "loss": 1.7654,
      "step": 7120
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.2825429439544678,
      "learning_rate": 8.57273422152385e-05,
      "loss": 1.8024,
      "step": 7130
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.463667869567871,
      "learning_rate": 8.568930301186847e-05,
      "loss": 1.7983,
      "step": 7140
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.5567270517349243,
      "learning_rate": 8.56512216490591e-05,
      "loss": 1.9343,
      "step": 7150
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.1525498628616333,
      "learning_rate": 8.561309817179554e-05,
      "loss": 1.9179,
      "step": 7160
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.3805795907974243,
      "learning_rate": 8.557493262511271e-05,
      "loss": 1.908,
      "step": 7170
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.3384593725204468,
      "learning_rate": 8.55367250540952e-05,
      "loss": 1.775,
      "step": 7180
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.5110951662063599,
      "learning_rate": 8.549847550387727e-05,
      "loss": 1.8869,
      "step": 7190
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.4080793857574463,
      "learning_rate": 8.546018401964276e-05,
      "loss": 1.7093,
      "step": 7200
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.0990006923675537,
      "learning_rate": 8.5421850646625e-05,
      "loss": 1.8636,
      "step": 7210
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.1817728281021118,
      "learning_rate": 8.538347543010687e-05,
      "loss": 1.9104,
      "step": 7220
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.6651332378387451,
      "learning_rate": 8.534505841542068e-05,
      "loss": 1.8024,
      "step": 7230
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.0466920137405396,
      "learning_rate": 8.530659964794806e-05,
      "loss": 1.8517,
      "step": 7240
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.243816375732422,
      "learning_rate": 8.526809917312e-05,
      "loss": 1.8307,
      "step": 7250
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.3755496740341187,
      "learning_rate": 8.522955703641674e-05,
      "loss": 1.9389,
      "step": 7260
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.4063136577606201,
      "learning_rate": 8.519097328336776e-05,
      "loss": 1.8448,
      "step": 7270
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.2725110054016113,
      "learning_rate": 8.515234795955168e-05,
      "loss": 1.8488,
      "step": 7280
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.350780963897705,
      "learning_rate": 8.511368111059624e-05,
      "loss": 1.7632,
      "step": 7290
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.1213080883026123,
      "learning_rate": 8.50749727821782e-05,
      "loss": 1.8202,
      "step": 7300
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.3821749687194824,
      "learning_rate": 8.503622302002338e-05,
      "loss": 1.8127,
      "step": 7310
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8692501783370972,
      "learning_rate": 8.49974318699065e-05,
      "loss": 1.8307,
      "step": 7320
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.2248265743255615,
      "learning_rate": 8.495859937765116e-05,
      "loss": 1.7999,
      "step": 7330
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.6034048795700073,
      "learning_rate": 8.491972558912985e-05,
      "loss": 1.8863,
      "step": 7340
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.5968034267425537,
      "learning_rate": 8.48808105502638e-05,
      "loss": 1.8793,
      "step": 7350
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.6542829275131226,
      "learning_rate": 8.484185430702299e-05,
      "loss": 1.6515,
      "step": 7360
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.2504326105117798,
      "learning_rate": 8.480285690542604e-05,
      "loss": 1.789,
      "step": 7370
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.4363268613815308,
      "learning_rate": 8.476381839154023e-05,
      "loss": 1.8758,
      "step": 7380
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.1910572052001953,
      "learning_rate": 8.472473881148139e-05,
      "loss": 1.7493,
      "step": 7390
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.3316017389297485,
      "learning_rate": 8.46856182114139e-05,
      "loss": 1.8238,
      "step": 7400
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.2354134321212769,
      "learning_rate": 8.464645663755049e-05,
      "loss": 1.9932,
      "step": 7410
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.297447681427002,
      "learning_rate": 8.46072541361524e-05,
      "loss": 1.8374,
      "step": 7420
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.174715518951416,
      "learning_rate": 8.456801075352916e-05,
      "loss": 1.9284,
      "step": 7430
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.3555338382720947,
      "learning_rate": 8.452872653603862e-05,
      "loss": 1.9043,
      "step": 7440
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.2431564331054688,
      "learning_rate": 8.448940153008689e-05,
      "loss": 1.8958,
      "step": 7450
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.1658650636672974,
      "learning_rate": 8.445003578212818e-05,
      "loss": 1.9442,
      "step": 7460
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.6157559156417847,
      "learning_rate": 8.441062933866491e-05,
      "loss": 1.7742,
      "step": 7470
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.3868778944015503,
      "learning_rate": 8.437118224624752e-05,
      "loss": 1.8254,
      "step": 7480
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.3807159662246704,
      "learning_rate": 8.43316945514745e-05,
      "loss": 1.8387,
      "step": 7490
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.0322526693344116,
      "learning_rate": 8.42921663009923e-05,
      "loss": 1.7674,
      "step": 7500
    },
    {
      "epoch": 0.78,
      "eval_loss": 1.8519151210784912,
      "eval_runtime": 366.5931,
      "eval_samples_per_second": 23.367,
      "eval_steps_per_second": 23.367,
      "step": 7500
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.379886269569397,
      "learning_rate": 8.425259754149525e-05,
      "loss": 1.8306,
      "step": 7510
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.1668291091918945,
      "learning_rate": 8.421298831972562e-05,
      "loss": 1.808,
      "step": 7520
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.306023359298706,
      "learning_rate": 8.417333868247334e-05,
      "loss": 1.6947,
      "step": 7530
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.3636126518249512,
      "learning_rate": 8.413364867657617e-05,
      "loss": 1.8183,
      "step": 7540
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.5521408319473267,
      "learning_rate": 8.409391834891957e-05,
      "loss": 1.8781,
      "step": 7550
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.26325523853302,
      "learning_rate": 8.405414774643659e-05,
      "loss": 1.7876,
      "step": 7560
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.5430735349655151,
      "learning_rate": 8.401433691610785e-05,
      "loss": 1.8412,
      "step": 7570
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.4004969596862793,
      "learning_rate": 8.397448590496154e-05,
      "loss": 1.777,
      "step": 7580
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.2849950790405273,
      "learning_rate": 8.393459476007328e-05,
      "loss": 1.8113,
      "step": 7590
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.341662049293518,
      "learning_rate": 8.38946635285661e-05,
      "loss": 1.8223,
      "step": 7600
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.1409193277359009,
      "learning_rate": 8.385469225761038e-05,
      "loss": 1.7469,
      "step": 7610
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.2725664377212524,
      "learning_rate": 8.381468099442382e-05,
      "loss": 1.8876,
      "step": 7620
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.1325451135635376,
      "learning_rate": 8.377462978627135e-05,
      "loss": 1.8276,
      "step": 7630
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.1064032316207886,
      "learning_rate": 8.37345386804651e-05,
      "loss": 1.8125,
      "step": 7640
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.1958969831466675,
      "learning_rate": 8.369440772436428e-05,
      "loss": 1.8332,
      "step": 7650
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.5302842855453491,
      "learning_rate": 8.365423696537524e-05,
      "loss": 2.0198,
      "step": 7660
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.152862548828125,
      "learning_rate": 8.361402645095134e-05,
      "loss": 1.9223,
      "step": 7670
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3599653244018555,
      "learning_rate": 8.357377622859283e-05,
      "loss": 1.7457,
      "step": 7680
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3290473222732544,
      "learning_rate": 8.353348634584699e-05,
      "loss": 1.7812,
      "step": 7690
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.473454475402832,
      "learning_rate": 8.34931568503078e-05,
      "loss": 1.7328,
      "step": 7700
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.0676876306533813,
      "learning_rate": 8.345278778961619e-05,
      "loss": 1.7924,
      "step": 7710
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3229472637176514,
      "learning_rate": 8.341237921145973e-05,
      "loss": 1.9785,
      "step": 7720
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.1216609477996826,
      "learning_rate": 8.337193116357265e-05,
      "loss": 1.8695,
      "step": 7730
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.4565387964248657,
      "learning_rate": 8.33314436937359e-05,
      "loss": 1.7697,
      "step": 7740
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.1569759845733643,
      "learning_rate": 8.329091684977695e-05,
      "loss": 1.8539,
      "step": 7750
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.8392508029937744,
      "learning_rate": 8.325035067956975e-05,
      "loss": 1.9969,
      "step": 7760
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.5089936256408691,
      "learning_rate": 8.320974523103477e-05,
      "loss": 1.7399,
      "step": 7770
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.3853974342346191,
      "learning_rate": 8.316910055213883e-05,
      "loss": 1.8256,
      "step": 7780
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.3812845945358276,
      "learning_rate": 8.31284166908951e-05,
      "loss": 1.82,
      "step": 7790
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.273285150527954,
      "learning_rate": 8.308769369536305e-05,
      "loss": 1.7971,
      "step": 7800
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.5274019241333008,
      "learning_rate": 8.304693161364836e-05,
      "loss": 1.8443,
      "step": 7810
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.337242841720581,
      "learning_rate": 8.300613049390294e-05,
      "loss": 1.8967,
      "step": 7820
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.7643126249313354,
      "learning_rate": 8.296529038432473e-05,
      "loss": 1.821,
      "step": 7830
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.330336093902588,
      "learning_rate": 8.292441133315777e-05,
      "loss": 1.8119,
      "step": 7840
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.3335286378860474,
      "learning_rate": 8.288349338869211e-05,
      "loss": 1.7689,
      "step": 7850
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.40888249874115,
      "learning_rate": 8.284253659926375e-05,
      "loss": 1.856,
      "step": 7860
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.6466553211212158,
      "learning_rate": 8.280154101325454e-05,
      "loss": 1.9095,
      "step": 7870
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9332740306854248,
      "learning_rate": 8.276050667909218e-05,
      "loss": 1.7898,
      "step": 7880
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.4952834844589233,
      "learning_rate": 8.271943364525017e-05,
      "loss": 1.8308,
      "step": 7890
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.246487021446228,
      "learning_rate": 8.267832196024767e-05,
      "loss": 1.8458,
      "step": 7900
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.3690129518508911,
      "learning_rate": 8.263717167264955e-05,
      "loss": 1.7955,
      "step": 7910
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.4296410083770752,
      "learning_rate": 8.259598283106624e-05,
      "loss": 1.7179,
      "step": 7920
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.2388663291931152,
      "learning_rate": 8.255475548415375e-05,
      "loss": 1.7914,
      "step": 7930
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.5574833154678345,
      "learning_rate": 8.251348968061354e-05,
      "loss": 1.9226,
      "step": 7940
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.7175371646881104,
      "learning_rate": 8.247218546919255e-05,
      "loss": 1.8678,
      "step": 7950
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.682112216949463,
      "learning_rate": 8.243084289868303e-05,
      "loss": 1.8327,
      "step": 7960
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.3728792667388916,
      "learning_rate": 8.238946201792256e-05,
      "loss": 1.9664,
      "step": 7970
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.1115258932113647,
      "learning_rate": 8.234804287579403e-05,
      "loss": 1.7562,
      "step": 7980
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.1676445007324219,
      "learning_rate": 8.230658552122545e-05,
      "loss": 1.7169,
      "step": 7990
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.3030370473861694,
      "learning_rate": 8.226509000319003e-05,
      "loss": 1.8626,
      "step": 8000
    },
    {
      "epoch": 0.83,
      "eval_loss": 1.850253939628601,
      "eval_runtime": 366.6889,
      "eval_samples_per_second": 23.36,
      "eval_steps_per_second": 23.36,
      "step": 8000
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.6149202585220337,
      "learning_rate": 8.2223556370706e-05,
      "loss": 1.8016,
      "step": 8010
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.3578393459320068,
      "learning_rate": 8.218198467283668e-05,
      "loss": 1.8438,
      "step": 8020
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.4356809854507446,
      "learning_rate": 8.214037495869031e-05,
      "loss": 1.8442,
      "step": 8030
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.288702368736267,
      "learning_rate": 8.209872727742009e-05,
      "loss": 1.7889,
      "step": 8040
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.2270656824111938,
      "learning_rate": 8.205704167822399e-05,
      "loss": 1.7729,
      "step": 8050
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.537142276763916,
      "learning_rate": 8.201531821034485e-05,
      "loss": 1.8242,
      "step": 8060
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.4229117631912231,
      "learning_rate": 8.197355692307018e-05,
      "loss": 1.7185,
      "step": 8070
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.4006454944610596,
      "learning_rate": 8.193175786573225e-05,
      "loss": 1.8333,
      "step": 8080
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7611584663391113,
      "learning_rate": 8.188992108770784e-05,
      "loss": 1.8625,
      "step": 8090
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.6591644287109375,
      "learning_rate": 8.184804663841838e-05,
      "loss": 1.8206,
      "step": 8100
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.3700799942016602,
      "learning_rate": 8.180613456732975e-05,
      "loss": 1.7973,
      "step": 8110
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.4643012285232544,
      "learning_rate": 8.176418492395228e-05,
      "loss": 1.8489,
      "step": 8120
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.2490394115447998,
      "learning_rate": 8.17221977578407e-05,
      "loss": 1.829,
      "step": 8130
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.2397711277008057,
      "learning_rate": 8.168017311859406e-05,
      "loss": 1.9443,
      "step": 8140
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.6475558280944824,
      "learning_rate": 8.163811105585565e-05,
      "loss": 1.9198,
      "step": 8150
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.3216804265975952,
      "learning_rate": 8.159601161931305e-05,
      "loss": 1.7956,
      "step": 8160
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.3058379888534546,
      "learning_rate": 8.155387485869785e-05,
      "loss": 1.9482,
      "step": 8170
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.3009862899780273,
      "learning_rate": 8.151170082378587e-05,
      "loss": 1.8692,
      "step": 8180
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.385819673538208,
      "learning_rate": 8.146948956439688e-05,
      "loss": 1.7495,
      "step": 8190
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.3981002569198608,
      "learning_rate": 8.142724113039464e-05,
      "loss": 1.7984,
      "step": 8200
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.2160917520523071,
      "learning_rate": 8.138495557168685e-05,
      "loss": 1.9332,
      "step": 8210
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.4532819986343384,
      "learning_rate": 8.134263293822502e-05,
      "loss": 1.9213,
      "step": 8220
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.4385968446731567,
      "learning_rate": 8.130027328000449e-05,
      "loss": 1.7178,
      "step": 8230
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.0392892360687256,
      "learning_rate": 8.125787664706432e-05,
      "loss": 1.8267,
      "step": 8240
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.3125698566436768,
      "learning_rate": 8.121544308948729e-05,
      "loss": 1.9152,
      "step": 8250
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.805675983428955,
      "learning_rate": 8.117297265739972e-05,
      "loss": 1.9477,
      "step": 8260
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.375909447669983,
      "learning_rate": 8.113046540097155e-05,
      "loss": 1.9325,
      "step": 8270
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.3734619617462158,
      "learning_rate": 8.108792137041623e-05,
      "loss": 1.9349,
      "step": 8280
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.2910903692245483,
      "learning_rate": 8.104534061599058e-05,
      "loss": 1.8749,
      "step": 8290
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.2140471935272217,
      "learning_rate": 8.100272318799486e-05,
      "loss": 1.8993,
      "step": 8300
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.377224326133728,
      "learning_rate": 8.096006913677267e-05,
      "loss": 1.8501,
      "step": 8310
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.5570913553237915,
      "learning_rate": 8.09173785127108e-05,
      "loss": 1.7748,
      "step": 8320
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.453762412071228,
      "learning_rate": 8.08746513662393e-05,
      "loss": 1.8937,
      "step": 8330
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.3366622924804688,
      "learning_rate": 8.083188774783134e-05,
      "loss": 1.7977,
      "step": 8340
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.3020743131637573,
      "learning_rate": 8.07890877080032e-05,
      "loss": 1.8361,
      "step": 8350
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.2078949213027954,
      "learning_rate": 8.074625129731416e-05,
      "loss": 1.7763,
      "step": 8360
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.3103013038635254,
      "learning_rate": 8.070337856636648e-05,
      "loss": 1.8694,
      "step": 8370
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.539026141166687,
      "learning_rate": 8.066046956580528e-05,
      "loss": 1.9913,
      "step": 8380
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.1709808111190796,
      "learning_rate": 8.061752434631859e-05,
      "loss": 1.8194,
      "step": 8390
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.3749122619628906,
      "learning_rate": 8.05745429586372e-05,
      "loss": 1.8575,
      "step": 8400
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.5985227823257446,
      "learning_rate": 8.053152545353461e-05,
      "loss": 1.8157,
      "step": 8410
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.6297037601470947,
      "learning_rate": 8.048847188182698e-05,
      "loss": 1.7156,
      "step": 8420
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.033834457397461,
      "learning_rate": 8.044538229437313e-05,
      "loss": 1.8395,
      "step": 8430
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.44020676612854,
      "learning_rate": 8.040225674207433e-05,
      "loss": 1.8325,
      "step": 8440
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.2248479127883911,
      "learning_rate": 8.035909527587444e-05,
      "loss": 1.8598,
      "step": 8450
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.4745174646377563,
      "learning_rate": 8.031589794675969e-05,
      "loss": 1.816,
      "step": 8460
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.46824049949646,
      "learning_rate": 8.027266480575864e-05,
      "loss": 1.8458,
      "step": 8470
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.640622615814209,
      "learning_rate": 8.022939590394225e-05,
      "loss": 1.9011,
      "step": 8480
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.523335576057434,
      "learning_rate": 8.018609129242362e-05,
      "loss": 1.847,
      "step": 8490
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.4425750970840454,
      "learning_rate": 8.014275102235813e-05,
      "loss": 1.8678,
      "step": 8500
    },
    {
      "epoch": 0.88,
      "eval_loss": 1.8454698324203491,
      "eval_runtime": 366.5395,
      "eval_samples_per_second": 23.37,
      "eval_steps_per_second": 23.37,
      "step": 8500
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.3467251062393188,
      "learning_rate": 8.009937514494319e-05,
      "loss": 1.9542,
      "step": 8510
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.4718908071517944,
      "learning_rate": 8.005596371141834e-05,
      "loss": 1.8437,
      "step": 8520
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.4715832471847534,
      "learning_rate": 8.001251677306511e-05,
      "loss": 1.7873,
      "step": 8530
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.1936166286468506,
      "learning_rate": 7.996903438120693e-05,
      "loss": 1.8466,
      "step": 8540
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.536365270614624,
      "learning_rate": 7.992551658720917e-05,
      "loss": 1.9355,
      "step": 8550
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.44581139087677,
      "learning_rate": 7.9881963442479e-05,
      "loss": 1.8904,
      "step": 8560
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.408708095550537,
      "learning_rate": 7.98383749984653e-05,
      "loss": 1.8386,
      "step": 8570
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.1394267082214355,
      "learning_rate": 7.979911526052171e-05,
      "loss": 1.9742,
      "step": 8580
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.3758563995361328,
      "learning_rate": 7.975545988976043e-05,
      "loss": 1.8605,
      "step": 8590
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.1485910415649414,
      "learning_rate": 7.97117693691531e-05,
      "loss": 2.0167,
      "step": 8600
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.1070667505264282,
      "learning_rate": 7.966804375031093e-05,
      "loss": 1.8605,
      "step": 8610
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.5416510105133057,
      "learning_rate": 7.96242830848866e-05,
      "loss": 1.736,
      "step": 8620
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.4716075658798218,
      "learning_rate": 7.958048742457415e-05,
      "loss": 1.9304,
      "step": 8630
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.3059636354446411,
      "learning_rate": 7.953665682110898e-05,
      "loss": 1.8565,
      "step": 8640
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5440123081207275,
      "learning_rate": 7.94927913262678e-05,
      "loss": 1.8638,
      "step": 8650
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.21095871925354,
      "learning_rate": 7.944889099186846e-05,
      "loss": 1.8463,
      "step": 8660
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.383499264717102,
      "learning_rate": 7.940495586977006e-05,
      "loss": 1.8137,
      "step": 8670
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.3751959800720215,
      "learning_rate": 7.936098601187274e-05,
      "loss": 1.7728,
      "step": 8680
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.3152254819869995,
      "learning_rate": 7.931698147011766e-05,
      "loss": 1.733,
      "step": 8690
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.1739518642425537,
      "learning_rate": 7.9272942296487e-05,
      "loss": 1.8359,
      "step": 8700
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5679134130477905,
      "learning_rate": 7.92288685430038e-05,
      "loss": 1.7656,
      "step": 8710
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.411684274673462,
      "learning_rate": 7.918476026173198e-05,
      "loss": 1.8433,
      "step": 8720
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.3079924583435059,
      "learning_rate": 7.914061750477625e-05,
      "loss": 1.7858,
      "step": 8730
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.3056178092956543,
      "learning_rate": 7.909644032428202e-05,
      "loss": 1.834,
      "step": 8740
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.2650178670883179,
      "learning_rate": 7.905222877243539e-05,
      "loss": 1.7827,
      "step": 8750
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.1287466287612915,
      "learning_rate": 7.900798290146304e-05,
      "loss": 1.7518,
      "step": 8760
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.3502320051193237,
      "learning_rate": 7.896370276363221e-05,
      "loss": 1.7986,
      "step": 8770
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.1670207977294922,
      "learning_rate": 7.891938841125063e-05,
      "loss": 1.8135,
      "step": 8780
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.2937437295913696,
      "learning_rate": 7.88750398966664e-05,
      "loss": 1.8354,
      "step": 8790
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.3319228887557983,
      "learning_rate": 7.883065727226801e-05,
      "loss": 1.7645,
      "step": 8800
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.3090885877609253,
      "learning_rate": 7.878624059048425e-05,
      "loss": 1.7959,
      "step": 8810
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.5884851217269897,
      "learning_rate": 7.874178990378413e-05,
      "loss": 1.8312,
      "step": 8820
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.34256911277771,
      "learning_rate": 7.869730526467683e-05,
      "loss": 1.8535,
      "step": 8830
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.7482064962387085,
      "learning_rate": 7.865278672571164e-05,
      "loss": 1.7784,
      "step": 8840
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.2891227006912231,
      "learning_rate": 7.86126910997287e-05,
      "loss": 1.8253,
      "step": 8850
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.2957650423049927,
      "learning_rate": 7.856810829595017e-05,
      "loss": 1.8556,
      "step": 8860
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.330323576927185,
      "learning_rate": 7.852349174493288e-05,
      "loss": 1.8371,
      "step": 8870
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.2345898151397705,
      "learning_rate": 7.847884149938199e-05,
      "loss": 1.7787,
      "step": 8880
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.6142464876174927,
      "learning_rate": 7.843415761204241e-05,
      "loss": 1.8691,
      "step": 8890
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.4383594989776611,
      "learning_rate": 7.838944013569877e-05,
      "loss": 2.0014,
      "step": 8900
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.7498388290405273,
      "learning_rate": 7.834468912317546e-05,
      "loss": 1.8138,
      "step": 8910
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.5373802185058594,
      "learning_rate": 7.829990462733637e-05,
      "loss": 1.827,
      "step": 8920
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.2622456550598145,
      "learning_rate": 7.825508670108503e-05,
      "loss": 1.8678,
      "step": 8930
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.484681487083435,
      "learning_rate": 7.821023539736447e-05,
      "loss": 1.949,
      "step": 8940
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8572169542312622,
      "learning_rate": 7.816535076915706e-05,
      "loss": 1.779,
      "step": 8950
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3269578218460083,
      "learning_rate": 7.812043286948463e-05,
      "loss": 1.8328,
      "step": 8960
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3478196859359741,
      "learning_rate": 7.807548175140824e-05,
      "loss": 1.8272,
      "step": 8970
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.4908534288406372,
      "learning_rate": 7.803049746802826e-05,
      "loss": 1.8057,
      "step": 8980
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3175005912780762,
      "learning_rate": 7.798548007248419e-05,
      "loss": 1.8665,
      "step": 8990
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3064860105514526,
      "learning_rate": 7.794042961795464e-05,
      "loss": 1.9112,
      "step": 9000
    },
    {
      "epoch": 0.93,
      "eval_loss": 1.8426729440689087,
      "eval_runtime": 366.5653,
      "eval_samples_per_second": 23.368,
      "eval_steps_per_second": 23.368,
      "step": 9000
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.3557406663894653,
      "learning_rate": 7.789534615765732e-05,
      "loss": 1.7922,
      "step": 9010
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.5328632593154907,
      "learning_rate": 7.785022974484887e-05,
      "loss": 1.9367,
      "step": 9020
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.2684170007705688,
      "learning_rate": 7.78050804328249e-05,
      "loss": 1.9185,
      "step": 9030
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4708771705627441,
      "learning_rate": 7.77598982749199e-05,
      "loss": 1.7312,
      "step": 9040
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.3523820638656616,
      "learning_rate": 7.771468332450707e-05,
      "loss": 1.8142,
      "step": 9050
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.41968834400177,
      "learning_rate": 7.766943563499844e-05,
      "loss": 1.8323,
      "step": 9060
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.654643177986145,
      "learning_rate": 7.762415525984468e-05,
      "loss": 1.7608,
      "step": 9070
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.5549540519714355,
      "learning_rate": 7.757884225253507e-05,
      "loss": 1.8394,
      "step": 9080
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.0728341341018677,
      "learning_rate": 7.753349666659743e-05,
      "loss": 1.7916,
      "step": 9090
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.641764521598816,
      "learning_rate": 7.74881185555981e-05,
      "loss": 1.8211,
      "step": 9100
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.539664387702942,
      "learning_rate": 7.744270797314183e-05,
      "loss": 1.8199,
      "step": 9110
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.4050012826919556,
      "learning_rate": 7.739726497287167e-05,
      "loss": 1.9622,
      "step": 9120
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2472484111785889,
      "learning_rate": 7.735178960846902e-05,
      "loss": 1.8259,
      "step": 9130
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2386137247085571,
      "learning_rate": 7.730628193365353e-05,
      "loss": 1.9281,
      "step": 9140
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2598259449005127,
      "learning_rate": 7.726074200218298e-05,
      "loss": 1.8265,
      "step": 9150
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.4394208192825317,
      "learning_rate": 7.721516986785325e-05,
      "loss": 1.8025,
      "step": 9160
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.3319947719573975,
      "learning_rate": 7.716956558449827e-05,
      "loss": 1.9413,
      "step": 9170
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2220442295074463,
      "learning_rate": 7.712392920598998e-05,
      "loss": 1.9076,
      "step": 9180
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2991900444030762,
      "learning_rate": 7.70782607862382e-05,
      "loss": 1.7701,
      "step": 9190
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.0033278465270996,
      "learning_rate": 7.703256037919058e-05,
      "loss": 1.8322,
      "step": 9200
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4751296043395996,
      "learning_rate": 7.698682803883262e-05,
      "loss": 1.8704,
      "step": 9210
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.0729990005493164,
      "learning_rate": 7.694106381918749e-05,
      "loss": 1.816,
      "step": 9220
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3068068027496338,
      "learning_rate": 7.689526777431603e-05,
      "loss": 1.8336,
      "step": 9230
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3896647691726685,
      "learning_rate": 7.684943995831665e-05,
      "loss": 1.7261,
      "step": 9240
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.5278639793395996,
      "learning_rate": 7.680358042532539e-05,
      "loss": 1.9356,
      "step": 9250
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.1648176908493042,
      "learning_rate": 7.675768922951563e-05,
      "loss": 1.8708,
      "step": 9260
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.521006464958191,
      "learning_rate": 7.671176642509824e-05,
      "loss": 1.7709,
      "step": 9270
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3912885189056396,
      "learning_rate": 7.666581206632136e-05,
      "loss": 1.7987,
      "step": 9280
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.2722928524017334,
      "learning_rate": 7.661982620747047e-05,
      "loss": 1.8679,
      "step": 9290
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.474441647529602,
      "learning_rate": 7.657380890286826e-05,
      "loss": 1.7183,
      "step": 9300
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.3806160688400269,
      "learning_rate": 7.65277602068745e-05,
      "loss": 1.7723,
      "step": 9310
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.5451167821884155,
      "learning_rate": 7.648168017388609e-05,
      "loss": 1.7965,
      "step": 9320
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.3016395568847656,
      "learning_rate": 7.643556885833696e-05,
      "loss": 1.8034,
      "step": 9330
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.2240121364593506,
      "learning_rate": 7.638942631469796e-05,
      "loss": 1.8003,
      "step": 9340
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.4312586784362793,
      "learning_rate": 7.634325259747685e-05,
      "loss": 1.7778,
      "step": 9350
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.1554054021835327,
      "learning_rate": 7.62970477612182e-05,
      "loss": 1.7757,
      "step": 9360
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.6238118410110474,
      "learning_rate": 7.625081186050335e-05,
      "loss": 1.8048,
      "step": 9370
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.3563638925552368,
      "learning_rate": 7.620454494995038e-05,
      "loss": 1.9228,
      "step": 9380
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.5206834077835083,
      "learning_rate": 7.615824708421389e-05,
      "loss": 1.8794,
      "step": 9390
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.226208448410034,
      "learning_rate": 7.611191831798516e-05,
      "loss": 1.8889,
      "step": 9400
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.4700249433517456,
      "learning_rate": 7.606555870599192e-05,
      "loss": 1.8524,
      "step": 9410
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.5360691547393799,
      "learning_rate": 7.601916830299833e-05,
      "loss": 1.8548,
      "step": 9420
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.530318260192871,
      "learning_rate": 7.597274716380496e-05,
      "loss": 1.8659,
      "step": 9430
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.340884804725647,
      "learning_rate": 7.592629534324864e-05,
      "loss": 1.7592,
      "step": 9440
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.2263202667236328,
      "learning_rate": 7.587981289620251e-05,
      "loss": 1.8715,
      "step": 9450
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.2673914432525635,
      "learning_rate": 7.583329987757582e-05,
      "loss": 1.8426,
      "step": 9460
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.345834493637085,
      "learning_rate": 7.578675634231396e-05,
      "loss": 1.8917,
      "step": 9470
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.6502972841262817,
      "learning_rate": 7.574018234539837e-05,
      "loss": 1.7635,
      "step": 9480
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.492119312286377,
      "learning_rate": 7.56935779418465e-05,
      "loss": 1.7678,
      "step": 9490
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.268418550491333,
      "learning_rate": 7.56469431867117e-05,
      "loss": 1.9299,
      "step": 9500
    },
    {
      "epoch": 0.99,
      "eval_loss": 1.8397008180618286,
      "eval_runtime": 366.4665,
      "eval_samples_per_second": 23.375,
      "eval_steps_per_second": 23.375,
      "step": 9500
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.635665774345398,
      "learning_rate": 7.560027813508314e-05,
      "loss": 1.8245,
      "step": 9510
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.5133763551712036,
      "learning_rate": 7.555358284208582e-05,
      "loss": 1.8815,
      "step": 9520
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.404654860496521,
      "learning_rate": 7.550685736288046e-05,
      "loss": 1.9106,
      "step": 9530
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.3974592685699463,
      "learning_rate": 7.546010175266341e-05,
      "loss": 1.8801,
      "step": 9540
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0088465213775635,
      "learning_rate": 7.541331606666665e-05,
      "loss": 1.9085,
      "step": 9550
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.5764731168746948,
      "learning_rate": 7.536650036015767e-05,
      "loss": 1.787,
      "step": 9560
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0038435459136963,
      "learning_rate": 7.531965468843945e-05,
      "loss": 1.9154,
      "step": 9570
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.4340277910232544,
      "learning_rate": 7.527277910685029e-05,
      "loss": 1.7606,
      "step": 9580
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.1549139022827148,
      "learning_rate": 7.522587367076391e-05,
      "loss": 1.7296,
      "step": 9590
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7137365341186523,
      "learning_rate": 7.517893843558928e-05,
      "loss": 1.8271,
      "step": 9600
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.407348871231079,
      "learning_rate": 7.51319734567705e-05,
      "loss": 1.8395,
      "step": 9610
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.2973639965057373,
      "learning_rate": 7.50849787897869e-05,
      "loss": 1.7812,
      "step": 9620
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.392414927482605,
      "learning_rate": 7.503795449015284e-05,
      "loss": 1.7802,
      "step": 9630
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.4879316091537476,
      "learning_rate": 7.499090061341766e-05,
      "loss": 1.8493,
      "step": 9640
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.5800716876983643,
      "learning_rate": 7.49438172151657e-05,
      "loss": 1.7619,
      "step": 9650
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.3397351503372192,
      "learning_rate": 7.48967043510161e-05,
      "loss": 1.7042,
      "step": 9660
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.3634625673294067,
      "learning_rate": 7.484956207662288e-05,
      "loss": 1.8478,
      "step": 9670
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.2586348056793213,
      "learning_rate": 7.480239044767474e-05,
      "loss": 1.7795,
      "step": 9680
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.3912103176116943,
      "learning_rate": 7.475518951989508e-05,
      "loss": 1.8516,
      "step": 9690
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.1455297470092773,
      "learning_rate": 7.470795934904194e-05,
      "loss": 1.8757,
      "step": 9700
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.217566967010498,
      "learning_rate": 7.466069999090786e-05,
      "loss": 1.6675,
      "step": 9710
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.1927844285964966,
      "learning_rate": 7.461341150131989e-05,
      "loss": 1.7322,
      "step": 9720
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.294305443763733,
      "learning_rate": 7.456609393613944e-05,
      "loss": 1.7408,
      "step": 9730
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.550795078277588,
      "learning_rate": 7.451874735126237e-05,
      "loss": 1.7457,
      "step": 9740
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.5070613622665405,
      "learning_rate": 7.447137180261873e-05,
      "loss": 1.795,
      "step": 9750
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.4619884490966797,
      "learning_rate": 7.442396734617278e-05,
      "loss": 1.758,
      "step": 9760
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.357365369796753,
      "learning_rate": 7.437653403792301e-05,
      "loss": 1.7829,
      "step": 9770
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.4118754863739014,
      "learning_rate": 7.432907193390191e-05,
      "loss": 1.6167,
      "step": 9780
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.685619831085205,
      "learning_rate": 7.428158109017602e-05,
      "loss": 1.7598,
      "step": 9790
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.5478030443191528,
      "learning_rate": 7.423406156284585e-05,
      "loss": 1.7164,
      "step": 9800
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.58006751537323,
      "learning_rate": 7.418651340804574e-05,
      "loss": 1.8158,
      "step": 9810
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.4218461513519287,
      "learning_rate": 7.413893668194392e-05,
      "loss": 1.744,
      "step": 9820
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.6627758741378784,
      "learning_rate": 7.409133144074232e-05,
      "loss": 1.8194,
      "step": 9830
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.5285098552703857,
      "learning_rate": 7.404369774067654e-05,
      "loss": 1.6595,
      "step": 9840
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.4392732381820679,
      "learning_rate": 7.399603563801584e-05,
      "loss": 1.7456,
      "step": 9850
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.643349289894104,
      "learning_rate": 7.394834518906302e-05,
      "loss": 1.7889,
      "step": 9860
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.435349941253662,
      "learning_rate": 7.390062645015436e-05,
      "loss": 1.6921,
      "step": 9870
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.5656712055206299,
      "learning_rate": 7.385287947765953e-05,
      "loss": 1.8332,
      "step": 9880
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.780347466468811,
      "learning_rate": 7.380510432798164e-05,
      "loss": 1.7754,
      "step": 9890
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.6304978132247925,
      "learning_rate": 7.375730105755697e-05,
      "loss": 1.8085,
      "step": 9900
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.4173012971878052,
      "learning_rate": 7.37094697228551e-05,
      "loss": 1.7343,
      "step": 9910
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.6246740818023682,
      "learning_rate": 7.366161038037875e-05,
      "loss": 1.683,
      "step": 9920
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.6764740943908691,
      "learning_rate": 7.36137230866637e-05,
      "loss": 1.7559,
      "step": 9930
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.4345505237579346,
      "learning_rate": 7.356580789827876e-05,
      "loss": 1.768,
      "step": 9940
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.3541297912597656,
      "learning_rate": 7.35178648718257e-05,
      "loss": 1.7965,
      "step": 9950
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.8235328197479248,
      "learning_rate": 7.346989406393913e-05,
      "loss": 1.8893,
      "step": 9960
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.5757057666778564,
      "learning_rate": 7.342189553128659e-05,
      "loss": 1.7876,
      "step": 9970
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.3202686309814453,
      "learning_rate": 7.337386933056823e-05,
      "loss": 1.8469,
      "step": 9980
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.2940977811813354,
      "learning_rate": 7.332581551851698e-05,
      "loss": 1.8624,
      "step": 9990
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.617182970046997,
      "learning_rate": 7.327773415189836e-05,
      "loss": 1.7281,
      "step": 10000
    },
    {
      "epoch": 1.04,
      "eval_loss": 1.8386505842208862,
      "eval_runtime": 366.5355,
      "eval_samples_per_second": 23.37,
      "eval_steps_per_second": 23.37,
      "step": 10000
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.3637614250183105,
      "learning_rate": 7.322962528751044e-05,
      "loss": 1.7033,
      "step": 10010
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.5358995199203491,
      "learning_rate": 7.318148898218375e-05,
      "loss": 1.6941,
      "step": 10020
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.5953730344772339,
      "learning_rate": 7.313332529278127e-05,
      "loss": 1.6681,
      "step": 10030
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.7331655025482178,
      "learning_rate": 7.308513427619832e-05,
      "loss": 1.7077,
      "step": 10040
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.408300757408142,
      "learning_rate": 7.30369159893625e-05,
      "loss": 1.6914,
      "step": 10050
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.5234582424163818,
      "learning_rate": 7.298867048923362e-05,
      "loss": 1.8248,
      "step": 10060
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.3713598251342773,
      "learning_rate": 7.29403978328036e-05,
      "loss": 1.7708,
      "step": 10070
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.539892315864563,
      "learning_rate": 7.289209807709651e-05,
      "loss": 1.8486,
      "step": 10080
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.4534276723861694,
      "learning_rate": 7.284377127916841e-05,
      "loss": 1.7526,
      "step": 10090
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.832877516746521,
      "learning_rate": 7.279541749610728e-05,
      "loss": 1.7749,
      "step": 10100
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.5829330682754517,
      "learning_rate": 7.274703678503299e-05,
      "loss": 1.7697,
      "step": 10110
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.461203932762146,
      "learning_rate": 7.26986292030972e-05,
      "loss": 1.7686,
      "step": 10120
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.6246585845947266,
      "learning_rate": 7.265019480748337e-05,
      "loss": 1.7742,
      "step": 10130
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.3142071962356567,
      "learning_rate": 7.260173365540659e-05,
      "loss": 1.9205,
      "step": 10140
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.7390228509902954,
      "learning_rate": 7.255324580411354e-05,
      "loss": 1.7773,
      "step": 10150
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.265831470489502,
      "learning_rate": 7.250473131088249e-05,
      "loss": 1.8965,
      "step": 10160
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.2718979120254517,
      "learning_rate": 7.245619023302315e-05,
      "loss": 1.8348,
      "step": 10170
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.579537272453308,
      "learning_rate": 7.240762262787662e-05,
      "loss": 1.7503,
      "step": 10180
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.715876817703247,
      "learning_rate": 7.23590285528154e-05,
      "loss": 1.6873,
      "step": 10190
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.6746644973754883,
      "learning_rate": 7.231040806524318e-05,
      "loss": 1.9597,
      "step": 10200
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.8026297092437744,
      "learning_rate": 7.22617612225949e-05,
      "loss": 1.7994,
      "step": 10210
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.3553736209869385,
      "learning_rate": 7.221308808233663e-05,
      "loss": 1.7249,
      "step": 10220
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.462778091430664,
      "learning_rate": 7.216438870196545e-05,
      "loss": 1.7355,
      "step": 10230
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.6846989393234253,
      "learning_rate": 7.211566313900955e-05,
      "loss": 1.7117,
      "step": 10240
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.143319845199585,
      "learning_rate": 7.206691145102792e-05,
      "loss": 1.7459,
      "step": 10250
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.1214302778244019,
      "learning_rate": 7.20181336956105e-05,
      "loss": 1.7925,
      "step": 10260
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.3965920209884644,
      "learning_rate": 7.1969329930378e-05,
      "loss": 1.7393,
      "step": 10270
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.4149163961410522,
      "learning_rate": 7.192050021298185e-05,
      "loss": 1.6902,
      "step": 10280
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.5890201330184937,
      "learning_rate": 7.187164460110412e-05,
      "loss": 1.8124,
      "step": 10290
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.6035205125808716,
      "learning_rate": 7.182276315245749e-05,
      "loss": 1.7181,
      "step": 10300
    },
    {
      "epoch": 1.07,
      "grad_norm": 2.1921443939208984,
      "learning_rate": 7.177385592478518e-05,
      "loss": 1.7473,
      "step": 10310
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.322502851486206,
      "learning_rate": 7.172492297586083e-05,
      "loss": 1.798,
      "step": 10320
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.686367154121399,
      "learning_rate": 7.167596436348846e-05,
      "loss": 1.8058,
      "step": 10330
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.362020492553711,
      "learning_rate": 7.162698014550242e-05,
      "loss": 1.6741,
      "step": 10340
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.6652777194976807,
      "learning_rate": 7.157797037976733e-05,
      "loss": 1.8395,
      "step": 10350
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.1593962907791138,
      "learning_rate": 7.152893512417796e-05,
      "loss": 1.6599,
      "step": 10360
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.599507451057434,
      "learning_rate": 7.147987443665917e-05,
      "loss": 1.7478,
      "step": 10370
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.3584308624267578,
      "learning_rate": 7.143078837516593e-05,
      "loss": 1.742,
      "step": 10380
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.6704785823822021,
      "learning_rate": 7.138167699768312e-05,
      "loss": 1.7828,
      "step": 10390
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.7059308290481567,
      "learning_rate": 7.133254036222556e-05,
      "loss": 1.7089,
      "step": 10400
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.7085273265838623,
      "learning_rate": 7.12833785268379e-05,
      "loss": 1.7541,
      "step": 10410
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.6493581533432007,
      "learning_rate": 7.123419154959455e-05,
      "loss": 1.7705,
      "step": 10420
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.3798115253448486,
      "learning_rate": 7.118497948859963e-05,
      "loss": 1.7283,
      "step": 10430
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.565738558769226,
      "learning_rate": 7.113574240198688e-05,
      "loss": 1.7752,
      "step": 10440
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.6751394271850586,
      "learning_rate": 7.10864803479196e-05,
      "loss": 1.7671,
      "step": 10450
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.630086898803711,
      "learning_rate": 7.103719338459063e-05,
      "loss": 1.773,
      "step": 10460
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.625101089477539,
      "learning_rate": 7.098788157022215e-05,
      "loss": 1.8566,
      "step": 10470
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.8987184762954712,
      "learning_rate": 7.09385449630658e-05,
      "loss": 1.8026,
      "step": 10480
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.7688863277435303,
      "learning_rate": 7.088918362140239e-05,
      "loss": 1.7363,
      "step": 10490
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.3970592021942139,
      "learning_rate": 7.083979760354204e-05,
      "loss": 1.7473,
      "step": 10500
    },
    {
      "epoch": 1.09,
      "eval_loss": 1.8369386196136475,
      "eval_runtime": 366.1715,
      "eval_samples_per_second": 23.393,
      "eval_steps_per_second": 23.393,
      "step": 10500
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.3410817384719849,
      "learning_rate": 7.079038696782401e-05,
      "loss": 1.7042,
      "step": 10510
    },
    {
      "epoch": 1.09,
      "grad_norm": 3.3532917499542236,
      "learning_rate": 7.074095177261659e-05,
      "loss": 1.9836,
      "step": 10520
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.4853280782699585,
      "learning_rate": 7.069149207631712e-05,
      "loss": 1.8409,
      "step": 10530
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.5096548795700073,
      "learning_rate": 7.06420079373519e-05,
      "loss": 1.8164,
      "step": 10540
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.2814596891403198,
      "learning_rate": 7.059249941417603e-05,
      "loss": 1.8576,
      "step": 10550
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.2796434164047241,
      "learning_rate": 7.054296656527353e-05,
      "loss": 1.7739,
      "step": 10560
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.561684489250183,
      "learning_rate": 7.049340944915704e-05,
      "loss": 1.6898,
      "step": 10570
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.561280369758606,
      "learning_rate": 7.044382812436792e-05,
      "loss": 1.7395,
      "step": 10580
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.5695266723632812,
      "learning_rate": 7.039422264947614e-05,
      "loss": 1.6987,
      "step": 10590
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.4865307807922363,
      "learning_rate": 7.034459308308021e-05,
      "loss": 1.7307,
      "step": 10600
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.3898495435714722,
      "learning_rate": 7.029493948380701e-05,
      "loss": 1.7132,
      "step": 10610
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.8249731063842773,
      "learning_rate": 7.024526191031191e-05,
      "loss": 1.7817,
      "step": 10620
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.1918551921844482,
      "learning_rate": 7.019556042127857e-05,
      "loss": 1.7294,
      "step": 10630
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.4275397062301636,
      "learning_rate": 7.014583507541886e-05,
      "loss": 1.6923,
      "step": 10640
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.4257373809814453,
      "learning_rate": 7.00960859314729e-05,
      "loss": 1.7065,
      "step": 10650
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.6325699090957642,
      "learning_rate": 7.004631304820887e-05,
      "loss": 1.7349,
      "step": 10660
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.6409729719161987,
      "learning_rate": 6.9996516484423e-05,
      "loss": 1.8981,
      "step": 10670
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.5218122005462646,
      "learning_rate": 6.994669629893952e-05,
      "loss": 1.7175,
      "step": 10680
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.4977328777313232,
      "learning_rate": 6.989685255061056e-05,
      "loss": 1.7814,
      "step": 10690
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.7451039552688599,
      "learning_rate": 6.984698529831606e-05,
      "loss": 1.6316,
      "step": 10700
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.3744562864303589,
      "learning_rate": 6.979709460096372e-05,
      "loss": 1.703,
      "step": 10710
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.1557157039642334,
      "learning_rate": 6.974718051748897e-05,
      "loss": 1.7809,
      "step": 10720
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.7959240674972534,
      "learning_rate": 6.969724310685487e-05,
      "loss": 1.6877,
      "step": 10730
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.699397325515747,
      "learning_rate": 6.964728242805198e-05,
      "loss": 1.8711,
      "step": 10740
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.7955100536346436,
      "learning_rate": 6.959729854009841e-05,
      "loss": 1.5996,
      "step": 10750
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.543482780456543,
      "learning_rate": 6.954729150203962e-05,
      "loss": 1.7321,
      "step": 10760
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.4668526649475098,
      "learning_rate": 6.94972613729485e-05,
      "loss": 1.6811,
      "step": 10770
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.9979809522628784,
      "learning_rate": 6.944720821192516e-05,
      "loss": 1.9194,
      "step": 10780
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.7938156127929688,
      "learning_rate": 6.93971320780969e-05,
      "loss": 1.6885,
      "step": 10790
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.4642530679702759,
      "learning_rate": 6.934703303061825e-05,
      "loss": 1.8132,
      "step": 10800
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.4020192623138428,
      "learning_rate": 6.929691112867068e-05,
      "loss": 1.8317,
      "step": 10810
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.7371653318405151,
      "learning_rate": 6.924676643146275e-05,
      "loss": 1.7778,
      "step": 10820
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.8030290603637695,
      "learning_rate": 6.919659899822994e-05,
      "loss": 1.7349,
      "step": 10830
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.6913377046585083,
      "learning_rate": 6.914640888823454e-05,
      "loss": 1.9305,
      "step": 10840
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.6971285343170166,
      "learning_rate": 6.909619616076567e-05,
      "loss": 1.7045,
      "step": 10850
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.526504397392273,
      "learning_rate": 6.904596087513915e-05,
      "loss": 1.6798,
      "step": 10860
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.5055655241012573,
      "learning_rate": 6.899570309069745e-05,
      "loss": 1.6361,
      "step": 10870
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.631902813911438,
      "learning_rate": 6.894542286680963e-05,
      "loss": 1.757,
      "step": 10880
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.7339316606521606,
      "learning_rate": 6.889512026287123e-05,
      "loss": 1.7202,
      "step": 10890
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.5690231323242188,
      "learning_rate": 6.884479533830428e-05,
      "loss": 1.6294,
      "step": 10900
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.8120580911636353,
      "learning_rate": 6.87944481525571e-05,
      "loss": 1.7323,
      "step": 10910
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.5435948371887207,
      "learning_rate": 6.874407876510437e-05,
      "loss": 1.7237,
      "step": 10920
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.4637327194213867,
      "learning_rate": 6.869368723544699e-05,
      "loss": 1.8564,
      "step": 10930
    },
    {
      "epoch": 1.14,
      "grad_norm": 2.122763156890869,
      "learning_rate": 6.864327362311197e-05,
      "loss": 1.7252,
      "step": 10940
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.3699411153793335,
      "learning_rate": 6.859283798765246e-05,
      "loss": 1.8282,
      "step": 10950
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.5836918354034424,
      "learning_rate": 6.854238038864759e-05,
      "loss": 1.5944,
      "step": 10960
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.6732536554336548,
      "learning_rate": 6.849190088570248e-05,
      "loss": 1.7407,
      "step": 10970
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.5064153671264648,
      "learning_rate": 6.844139953844804e-05,
      "loss": 1.771,
      "step": 10980
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.4736394882202148,
      "learning_rate": 6.839087640654108e-05,
      "loss": 1.6897,
      "step": 10990
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.5194165706634521,
      "learning_rate": 6.834033154966409e-05,
      "loss": 1.8333,
      "step": 11000
    },
    {
      "epoch": 1.14,
      "eval_loss": 1.8354893922805786,
      "eval_runtime": 366.3138,
      "eval_samples_per_second": 23.384,
      "eval_steps_per_second": 23.384,
      "step": 11000
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.6065263748168945,
      "learning_rate": 6.828976502752523e-05,
      "loss": 1.7549,
      "step": 11010
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.5176324844360352,
      "learning_rate": 6.823917689985828e-05,
      "loss": 1.7629,
      "step": 11020
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.6587461233139038,
      "learning_rate": 6.818856722642251e-05,
      "loss": 1.8642,
      "step": 11030
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.7045470476150513,
      "learning_rate": 6.813793606700263e-05,
      "loss": 1.7475,
      "step": 11040
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.527640461921692,
      "learning_rate": 6.80872834814088e-05,
      "loss": 1.8052,
      "step": 11050
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.5012835264205933,
      "learning_rate": 6.803660952947641e-05,
      "loss": 1.7403,
      "step": 11060
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.5064682960510254,
      "learning_rate": 6.798591427106613e-05,
      "loss": 1.7326,
      "step": 11070
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.39541757106781,
      "learning_rate": 6.793519776606381e-05,
      "loss": 1.7208,
      "step": 11080
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.5581045150756836,
      "learning_rate": 6.788446007438036e-05,
      "loss": 1.8234,
      "step": 11090
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.6255282163619995,
      "learning_rate": 6.783370125595176e-05,
      "loss": 1.8278,
      "step": 11100
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.4352625608444214,
      "learning_rate": 6.77829213707389e-05,
      "loss": 1.7236,
      "step": 11110
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.5299686193466187,
      "learning_rate": 6.773212047872762e-05,
      "loss": 1.7872,
      "step": 11120
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.7320921421051025,
      "learning_rate": 6.768129863992849e-05,
      "loss": 1.7537,
      "step": 11130
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.6976137161254883,
      "learning_rate": 6.763045591437693e-05,
      "loss": 1.776,
      "step": 11140
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.355952501296997,
      "learning_rate": 6.757959236213292e-05,
      "loss": 1.7135,
      "step": 11150
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.1932777166366577,
      "learning_rate": 6.752870804328115e-05,
      "loss": 1.7424,
      "step": 11160
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.569100260734558,
      "learning_rate": 6.747780301793075e-05,
      "loss": 1.8019,
      "step": 11170
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.5850708484649658,
      "learning_rate": 6.742687734621536e-05,
      "loss": 1.7636,
      "step": 11180
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.080655574798584,
      "learning_rate": 6.737593108829301e-05,
      "loss": 1.7937,
      "step": 11190
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.5634980201721191,
      "learning_rate": 6.7324964304346e-05,
      "loss": 1.8349,
      "step": 11200
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.5732179880142212,
      "learning_rate": 6.727397705458098e-05,
      "loss": 1.7037,
      "step": 11210
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.5955157279968262,
      "learning_rate": 6.722296939922866e-05,
      "loss": 1.7376,
      "step": 11220
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.7168227434158325,
      "learning_rate": 6.71719413985439e-05,
      "loss": 1.6735,
      "step": 11230
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.4757975339889526,
      "learning_rate": 6.712089311280564e-05,
      "loss": 1.7513,
      "step": 11240
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.6071910858154297,
      "learning_rate": 6.706982460231672e-05,
      "loss": 1.7034,
      "step": 11250
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.8951220512390137,
      "learning_rate": 6.701873592740388e-05,
      "loss": 1.7147,
      "step": 11260
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.6171891689300537,
      "learning_rate": 6.696762714841772e-05,
      "loss": 1.8586,
      "step": 11270
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.3782402276992798,
      "learning_rate": 6.691649832573255e-05,
      "loss": 1.669,
      "step": 11280
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.4618324041366577,
      "learning_rate": 6.686534951974636e-05,
      "loss": 1.7777,
      "step": 11290
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.503341555595398,
      "learning_rate": 6.681418079088075e-05,
      "loss": 1.8289,
      "step": 11300
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.7628077268600464,
      "learning_rate": 6.676299219958089e-05,
      "loss": 1.7328,
      "step": 11310
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.5912538766860962,
      "learning_rate": 6.671178380631536e-05,
      "loss": 1.7837,
      "step": 11320
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.5727825164794922,
      "learning_rate": 6.666055567157616e-05,
      "loss": 1.6313,
      "step": 11330
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.4529109001159668,
      "learning_rate": 6.660930785587862e-05,
      "loss": 1.6853,
      "step": 11340
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.4991427659988403,
      "learning_rate": 6.65580404197613e-05,
      "loss": 1.8602,
      "step": 11350
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.3996585607528687,
      "learning_rate": 6.65067534237859e-05,
      "loss": 1.7222,
      "step": 11360
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.4519402980804443,
      "learning_rate": 6.645544692853732e-05,
      "loss": 1.7927,
      "step": 11370
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.394717812538147,
      "learning_rate": 6.640412099462343e-05,
      "loss": 1.6934,
      "step": 11380
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.3610739707946777,
      "learning_rate": 6.635277568267506e-05,
      "loss": 1.7911,
      "step": 11390
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.509315013885498,
      "learning_rate": 6.630141105334596e-05,
      "loss": 1.785,
      "step": 11400
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.3075449466705322,
      "learning_rate": 6.625002716731268e-05,
      "loss": 1.7932,
      "step": 11410
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.6188746690750122,
      "learning_rate": 6.619862408527451e-05,
      "loss": 1.7891,
      "step": 11420
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.658141016960144,
      "learning_rate": 6.614720186795344e-05,
      "loss": 1.7754,
      "step": 11430
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.6702865362167358,
      "learning_rate": 6.609576057609409e-05,
      "loss": 1.7053,
      "step": 11440
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.380040168762207,
      "learning_rate": 6.604430027046352e-05,
      "loss": 1.7222,
      "step": 11450
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.6351826190948486,
      "learning_rate": 6.599282101185133e-05,
      "loss": 1.6657,
      "step": 11460
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.592006802558899,
      "learning_rate": 6.594132286106949e-05,
      "loss": 1.6912,
      "step": 11470
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.6125730276107788,
      "learning_rate": 6.588980587895228e-05,
      "loss": 1.781,
      "step": 11480
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.5635854005813599,
      "learning_rate": 6.583827012635622e-05,
      "loss": 1.7282,
      "step": 11490
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.4492199420928955,
      "learning_rate": 6.578671566416004e-05,
      "loss": 1.8227,
      "step": 11500
    },
    {
      "epoch": 1.19,
      "eval_loss": 1.8334530591964722,
      "eval_runtime": 366.3567,
      "eval_samples_per_second": 23.382,
      "eval_steps_per_second": 23.382,
      "step": 11500
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.644437551498413,
      "learning_rate": 6.57351425532645e-05,
      "loss": 1.7419,
      "step": 11510
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.6477506160736084,
      "learning_rate": 6.568355085459245e-05,
      "loss": 1.8703,
      "step": 11520
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.5174845457077026,
      "learning_rate": 6.563194062908871e-05,
      "loss": 1.8371,
      "step": 11530
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.7911386489868164,
      "learning_rate": 6.558031193771992e-05,
      "loss": 1.7128,
      "step": 11540
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.3908261060714722,
      "learning_rate": 6.552866484147458e-05,
      "loss": 1.6488,
      "step": 11550
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.2591063976287842,
      "learning_rate": 6.547699940136293e-05,
      "loss": 1.8029,
      "step": 11560
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.6683392524719238,
      "learning_rate": 6.542531567841686e-05,
      "loss": 1.8233,
      "step": 11570
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.2613881826400757,
      "learning_rate": 6.537361373368986e-05,
      "loss": 1.7008,
      "step": 11580
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.7780234813690186,
      "learning_rate": 6.532189362825698e-05,
      "loss": 1.6076,
      "step": 11590
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.7313984632492065,
      "learning_rate": 6.527015542321467e-05,
      "loss": 1.7568,
      "step": 11600
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.6625521183013916,
      "learning_rate": 6.52183991796808e-05,
      "loss": 1.7515,
      "step": 11610
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.5994044542312622,
      "learning_rate": 6.516662495879453e-05,
      "loss": 1.6859,
      "step": 11620
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.427980661392212,
      "learning_rate": 6.511483282171627e-05,
      "loss": 1.7436,
      "step": 11630
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.862599492073059,
      "learning_rate": 6.506302282962758e-05,
      "loss": 1.7769,
      "step": 11640
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.8122222423553467,
      "learning_rate": 6.50111950437311e-05,
      "loss": 1.7493,
      "step": 11650
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.6749465465545654,
      "learning_rate": 6.495934952525055e-05,
      "loss": 1.844,
      "step": 11660
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.720221996307373,
      "learning_rate": 6.490748633543051e-05,
      "loss": 1.7135,
      "step": 11670
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.4476760625839233,
      "learning_rate": 6.485560553553652e-05,
      "loss": 1.7619,
      "step": 11680
    },
    {
      "epoch": 1.21,
      "grad_norm": 2.172729015350342,
      "learning_rate": 6.480370718685486e-05,
      "loss": 1.7134,
      "step": 11690
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.5696722269058228,
      "learning_rate": 6.475179135069257e-05,
      "loss": 1.9048,
      "step": 11700
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.5940563678741455,
      "learning_rate": 6.469985808837736e-05,
      "loss": 1.7341,
      "step": 11710
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.430154800415039,
      "learning_rate": 6.464790746125746e-05,
      "loss": 1.6789,
      "step": 11720
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.3422582149505615,
      "learning_rate": 6.459593953070169e-05,
      "loss": 1.8131,
      "step": 11730
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.7877891063690186,
      "learning_rate": 6.454395435809927e-05,
      "loss": 1.7021,
      "step": 11740
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.797081470489502,
      "learning_rate": 6.449195200485981e-05,
      "loss": 1.6889,
      "step": 11750
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.0272927284240723,
      "learning_rate": 6.44399325324132e-05,
      "loss": 1.7453,
      "step": 11760
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.4742647409439087,
      "learning_rate": 6.438789600220954e-05,
      "loss": 1.7395,
      "step": 11770
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.7974255084991455,
      "learning_rate": 6.433584247571911e-05,
      "loss": 1.8358,
      "step": 11780
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.5777887105941772,
      "learning_rate": 6.428377201443225e-05,
      "loss": 1.7345,
      "step": 11790
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.7995076179504395,
      "learning_rate": 6.423168467985929e-05,
      "loss": 1.7328,
      "step": 11800
    },
    {
      "epoch": 1.23,
      "grad_norm": 2.052778959274292,
      "learning_rate": 6.417958053353056e-05,
      "loss": 1.6231,
      "step": 11810
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.5328391790390015,
      "learning_rate": 6.412745963699614e-05,
      "loss": 1.7437,
      "step": 11820
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.7549622058868408,
      "learning_rate": 6.407532205182602e-05,
      "loss": 1.7112,
      "step": 11830
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.6644105911254883,
      "learning_rate": 6.402316783960977e-05,
      "loss": 1.8031,
      "step": 11840
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.6642972230911255,
      "learning_rate": 6.397099706195673e-05,
      "loss": 1.76,
      "step": 11850
    },
    {
      "epoch": 1.23,
      "grad_norm": 2.008166551589966,
      "learning_rate": 6.391880978049572e-05,
      "loss": 1.8819,
      "step": 11860
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.5763808488845825,
      "learning_rate": 6.386660605687508e-05,
      "loss": 1.8399,
      "step": 11870
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.5367350578308105,
      "learning_rate": 6.381438595276264e-05,
      "loss": 1.7282,
      "step": 11880
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.6909501552581787,
      "learning_rate": 6.376214952984545e-05,
      "loss": 1.8038,
      "step": 11890
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.8044668436050415,
      "learning_rate": 6.370989684982992e-05,
      "loss": 1.6681,
      "step": 11900
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.7326502799987793,
      "learning_rate": 6.36576279744417e-05,
      "loss": 1.6578,
      "step": 11910
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.5415889024734497,
      "learning_rate": 6.360534296542545e-05,
      "loss": 1.6526,
      "step": 11920
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.8507980108261108,
      "learning_rate": 6.355304188454502e-05,
      "loss": 1.7638,
      "step": 11930
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.5403555631637573,
      "learning_rate": 6.350072479358315e-05,
      "loss": 1.7316,
      "step": 11940
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.4999446868896484,
      "learning_rate": 6.344839175434157e-05,
      "loss": 1.7438,
      "step": 11950
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.4298726320266724,
      "learning_rate": 6.339604282864074e-05,
      "loss": 1.7307,
      "step": 11960
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.8210235834121704,
      "learning_rate": 6.334367807832002e-05,
      "loss": 1.8194,
      "step": 11970
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.487496018409729,
      "learning_rate": 6.32912975652374e-05,
      "loss": 1.7644,
      "step": 11980
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.661650538444519,
      "learning_rate": 6.323890135126944e-05,
      "loss": 1.721,
      "step": 11990
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.8690851926803589,
      "learning_rate": 6.318648949831134e-05,
      "loss": 1.7638,
      "step": 12000
    },
    {
      "epoch": 1.25,
      "eval_loss": 1.8308436870574951,
      "eval_runtime": 366.2596,
      "eval_samples_per_second": 23.388,
      "eval_steps_per_second": 23.388,
      "step": 12000
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.5556210279464722,
      "learning_rate": 6.313406206827672e-05,
      "loss": 1.6989,
      "step": 12010
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.6621414422988892,
      "learning_rate": 6.308161912309759e-05,
      "loss": 1.7577,
      "step": 12020
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.528090000152588,
      "learning_rate": 6.302916072472434e-05,
      "loss": 1.627,
      "step": 12030
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.5772641897201538,
      "learning_rate": 6.297668693512556e-05,
      "loss": 1.7682,
      "step": 12040
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.6365677118301392,
      "learning_rate": 6.292419781628807e-05,
      "loss": 1.7102,
      "step": 12050
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.620903491973877,
      "learning_rate": 6.287169343021676e-05,
      "loss": 1.7855,
      "step": 12060
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.4373348951339722,
      "learning_rate": 6.281917383893456e-05,
      "loss": 1.6511,
      "step": 12070
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.446887731552124,
      "learning_rate": 6.276663910448242e-05,
      "loss": 1.731,
      "step": 12080
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.551694393157959,
      "learning_rate": 6.271408928891906e-05,
      "loss": 1.7784,
      "step": 12090
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.461963176727295,
      "learning_rate": 6.266152445432112e-05,
      "loss": 1.78,
      "step": 12100
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.4551537036895752,
      "learning_rate": 6.260894466278296e-05,
      "loss": 1.7303,
      "step": 12110
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.6768091917037964,
      "learning_rate": 6.255634997641656e-05,
      "loss": 1.8421,
      "step": 12120
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.8282746076583862,
      "learning_rate": 6.250374045735157e-05,
      "loss": 1.7348,
      "step": 12130
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.5056909322738647,
      "learning_rate": 6.245111616773509e-05,
      "loss": 1.7478,
      "step": 12140
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.753960371017456,
      "learning_rate": 6.23984771697317e-05,
      "loss": 1.7937,
      "step": 12150
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.8515664339065552,
      "learning_rate": 6.234582352552341e-05,
      "loss": 1.672,
      "step": 12160
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.4932794570922852,
      "learning_rate": 6.229315529730939e-05,
      "loss": 1.7266,
      "step": 12170
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.6403062343597412,
      "learning_rate": 6.224047254730619e-05,
      "loss": 1.7814,
      "step": 12180
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.4059104919433594,
      "learning_rate": 6.218777533774742e-05,
      "loss": 1.6973,
      "step": 12190
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.7059972286224365,
      "learning_rate": 6.213506373088382e-05,
      "loss": 1.7299,
      "step": 12200
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.6710761785507202,
      "learning_rate": 6.20823377889831e-05,
      "loss": 1.7735,
      "step": 12210
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.881569266319275,
      "learning_rate": 6.202959757432993e-05,
      "loss": 1.828,
      "step": 12220
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.526668667793274,
      "learning_rate": 6.197684314922583e-05,
      "loss": 1.7269,
      "step": 12230
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.5415568351745605,
      "learning_rate": 6.192407457598909e-05,
      "loss": 1.7516,
      "step": 12240
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.7099617719650269,
      "learning_rate": 6.187129191695477e-05,
      "loss": 1.9201,
      "step": 12250
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.8070985078811646,
      "learning_rate": 6.181849523447449e-05,
      "loss": 1.8588,
      "step": 12260
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.4305651187896729,
      "learning_rate": 6.176568459091652e-05,
      "loss": 1.7985,
      "step": 12270
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.4569562673568726,
      "learning_rate": 6.171286004866553e-05,
      "loss": 1.7709,
      "step": 12280
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.9882559776306152,
      "learning_rate": 6.166002167012268e-05,
      "loss": 1.7053,
      "step": 12290
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.6442766189575195,
      "learning_rate": 6.160716951770546e-05,
      "loss": 1.7147,
      "step": 12300
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.985135555267334,
      "learning_rate": 6.155430365384762e-05,
      "loss": 1.8525,
      "step": 12310
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.4956777095794678,
      "learning_rate": 6.15014241409991e-05,
      "loss": 1.853,
      "step": 12320
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.5383658409118652,
      "learning_rate": 6.144853104162598e-05,
      "loss": 1.741,
      "step": 12330
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.8247491121292114,
      "learning_rate": 6.139562441821038e-05,
      "loss": 1.7844,
      "step": 12340
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.8184800148010254,
      "learning_rate": 6.134270433325038e-05,
      "loss": 1.8365,
      "step": 12350
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.6261634826660156,
      "learning_rate": 6.128977084926004e-05,
      "loss": 1.8528,
      "step": 12360
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.899342656135559,
      "learning_rate": 6.123682402876912e-05,
      "loss": 1.6681,
      "step": 12370
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.5271797180175781,
      "learning_rate": 6.118386393432324e-05,
      "loss": 1.7572,
      "step": 12380
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.5805224180221558,
      "learning_rate": 6.113089062848365e-05,
      "loss": 1.7366,
      "step": 12390
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.6213390827178955,
      "learning_rate": 6.107790417382722e-05,
      "loss": 1.7525,
      "step": 12400
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.5612833499908447,
      "learning_rate": 6.102490463294639e-05,
      "loss": 1.7054,
      "step": 12410
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.6600855588912964,
      "learning_rate": 6.097189206844895e-05,
      "loss": 1.92,
      "step": 12420
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.4308459758758545,
      "learning_rate": 6.091886654295822e-05,
      "loss": 1.7987,
      "step": 12430
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.521848440170288,
      "learning_rate": 6.08658281191127e-05,
      "loss": 1.7127,
      "step": 12440
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.594058632850647,
      "learning_rate": 6.081277685956621e-05,
      "loss": 1.8956,
      "step": 12450
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.5762743949890137,
      "learning_rate": 6.075971282698769e-05,
      "loss": 1.7414,
      "step": 12460
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.9154243469238281,
      "learning_rate": 6.070663608406122e-05,
      "loss": 1.8684,
      "step": 12470
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.4116206169128418,
      "learning_rate": 6.065354669348581e-05,
      "loss": 1.8276,
      "step": 12480
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.732428789138794,
      "learning_rate": 6.06004447179755e-05,
      "loss": 1.7304,
      "step": 12490
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.4877734184265137,
      "learning_rate": 6.0547330220259125e-05,
      "loss": 1.8019,
      "step": 12500
    },
    {
      "epoch": 1.3,
      "eval_loss": 1.8287124633789062,
      "eval_runtime": 366.4392,
      "eval_samples_per_second": 23.376,
      "eval_steps_per_second": 23.376,
      "step": 12500
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.498952031135559,
      "learning_rate": 6.049951651768555e-05,
      "loss": 1.7038,
      "step": 12510
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.7181857824325562,
      "learning_rate": 6.044637840064863e-05,
      "loss": 1.7343,
      "step": 12520
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.5969961881637573,
      "learning_rate": 6.0393227943402776e-05,
      "loss": 1.7515,
      "step": 12530
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.5668469667434692,
      "learning_rate": 6.0340065208734085e-05,
      "loss": 1.7633,
      "step": 12540
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.967113971710205,
      "learning_rate": 6.0286890259443244e-05,
      "loss": 1.8551,
      "step": 12550
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.4667702913284302,
      "learning_rate": 6.023370315834528e-05,
      "loss": 1.7032,
      "step": 12560
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.5476218461990356,
      "learning_rate": 6.018050396826964e-05,
      "loss": 1.768,
      "step": 12570
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.6847435235977173,
      "learning_rate": 6.012729275206003e-05,
      "loss": 1.831,
      "step": 12580
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.5591171979904175,
      "learning_rate": 6.0074069572574353e-05,
      "loss": 1.7213,
      "step": 12590
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.7463324069976807,
      "learning_rate": 6.0020834492684655e-05,
      "loss": 1.6837,
      "step": 12600
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.7065342664718628,
      "learning_rate": 5.996758757527704e-05,
      "loss": 1.6961,
      "step": 12610
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.9845762252807617,
      "learning_rate": 5.991432888325159e-05,
      "loss": 1.8763,
      "step": 12620
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.6267237663269043,
      "learning_rate": 5.986105847952229e-05,
      "loss": 1.7771,
      "step": 12630
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.510844349861145,
      "learning_rate": 5.9807776427016984e-05,
      "loss": 1.729,
      "step": 12640
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.3262192010879517,
      "learning_rate": 5.975448278867726e-05,
      "loss": 1.696,
      "step": 12650
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.6460962295532227,
      "learning_rate": 5.970117762745838e-05,
      "loss": 1.7263,
      "step": 12660
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.4960129261016846,
      "learning_rate": 5.9647861006329256e-05,
      "loss": 1.6894,
      "step": 12670
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.369210124015808,
      "learning_rate": 5.959453298827228e-05,
      "loss": 1.749,
      "step": 12680
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.7378549575805664,
      "learning_rate": 5.954119363628336e-05,
      "loss": 1.7688,
      "step": 12690
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.4828171730041504,
      "learning_rate": 5.948784301337179e-05,
      "loss": 1.7922,
      "step": 12700
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.1001012325286865,
      "learning_rate": 5.943448118256013e-05,
      "loss": 1.7342,
      "step": 12710
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.637541651725769,
      "learning_rate": 5.938110820688423e-05,
      "loss": 1.8319,
      "step": 12720
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.0659539699554443,
      "learning_rate": 5.9327724149393075e-05,
      "loss": 1.7544,
      "step": 12730
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.6065609455108643,
      "learning_rate": 5.927432907314874e-05,
      "loss": 1.8324,
      "step": 12740
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.6069363355636597,
      "learning_rate": 5.922092304122637e-05,
      "loss": 1.7153,
      "step": 12750
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.6714648008346558,
      "learning_rate": 5.916750611671398e-05,
      "loss": 1.7065,
      "step": 12760
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.81923246383667,
      "learning_rate": 5.9114078362712475e-05,
      "loss": 1.7707,
      "step": 12770
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.533207654953003,
      "learning_rate": 5.906063984233559e-05,
      "loss": 1.7347,
      "step": 12780
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.7563761472702026,
      "learning_rate": 5.900719061870972e-05,
      "loss": 1.6989,
      "step": 12790
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.5497238636016846,
      "learning_rate": 5.8953730754973944e-05,
      "loss": 1.8181,
      "step": 12800
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.5208886861801147,
      "learning_rate": 5.89002603142799e-05,
      "loss": 1.6787,
      "step": 12810
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.7057934999465942,
      "learning_rate": 5.884677935979173e-05,
      "loss": 1.6479,
      "step": 12820
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.5902373790740967,
      "learning_rate": 5.879328795468595e-05,
      "loss": 1.6707,
      "step": 12830
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.7559661865234375,
      "learning_rate": 5.8739786162151486e-05,
      "loss": 1.6719,
      "step": 12840
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.3729488849639893,
      "learning_rate": 5.86862740453895e-05,
      "loss": 1.7577,
      "step": 12850
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.6184743642807007,
      "learning_rate": 5.863275166761335e-05,
      "loss": 1.8619,
      "step": 12860
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.5584990978240967,
      "learning_rate": 5.857921909204851e-05,
      "loss": 1.813,
      "step": 12870
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.6923226118087769,
      "learning_rate": 5.852567638193254e-05,
      "loss": 1.7146,
      "step": 12880
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.8220608234405518,
      "learning_rate": 5.8472123600514906e-05,
      "loss": 1.8059,
      "step": 12890
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.4888986349105835,
      "learning_rate": 5.841856081105702e-05,
      "loss": 1.7642,
      "step": 12900
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.7719107866287231,
      "learning_rate": 5.8364988076832104e-05,
      "loss": 1.7008,
      "step": 12910
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.7847176790237427,
      "learning_rate": 5.831140546112515e-05,
      "loss": 1.6711,
      "step": 12920
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.3944873809814453,
      "learning_rate": 5.825781302723275e-05,
      "loss": 1.7499,
      "step": 12930
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.69801926612854,
      "learning_rate": 5.820421083846319e-05,
      "loss": 1.6988,
      "step": 12940
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.6143486499786377,
      "learning_rate": 5.815059895813621e-05,
      "loss": 1.6219,
      "step": 12950
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.3846162557601929,
      "learning_rate": 5.809697744958303e-05,
      "loss": 1.7104,
      "step": 12960
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.8294318914413452,
      "learning_rate": 5.8043346376146244e-05,
      "loss": 1.6599,
      "step": 12970
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.721220850944519,
      "learning_rate": 5.798970580117972e-05,
      "loss": 1.6771,
      "step": 12980
    },
    {
      "epoch": 1.35,
      "grad_norm": 2.162527322769165,
      "learning_rate": 5.7936055788048574e-05,
      "loss": 1.7988,
      "step": 12990
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.3968697786331177,
      "learning_rate": 5.7882396400129056e-05,
      "loss": 1.758,
      "step": 13000
    },
    {
      "epoch": 1.35,
      "eval_loss": 1.826695442199707,
      "eval_runtime": 366.2187,
      "eval_samples_per_second": 23.39,
      "eval_steps_per_second": 23.39,
      "step": 13000
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.6730461120605469,
      "learning_rate": 5.7828727700808516e-05,
      "loss": 1.7409,
      "step": 13010
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.903355598449707,
      "learning_rate": 5.7775049753485276e-05,
      "loss": 1.6927,
      "step": 13020
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.7924094200134277,
      "learning_rate": 5.772136262156859e-05,
      "loss": 1.6494,
      "step": 13030
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.9116207361221313,
      "learning_rate": 5.766766636847857e-05,
      "loss": 1.788,
      "step": 13040
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.7220112085342407,
      "learning_rate": 5.761396105764608e-05,
      "loss": 1.8189,
      "step": 13050
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.621961236000061,
      "learning_rate": 5.7560246752512714e-05,
      "loss": 1.7296,
      "step": 13060
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.6412386894226074,
      "learning_rate": 5.75065235165307e-05,
      "loss": 1.7464,
      "step": 13070
    },
    {
      "epoch": 1.36,
      "grad_norm": 2.099155902862549,
      "learning_rate": 5.745279141316275e-05,
      "loss": 1.806,
      "step": 13080
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.6108336448669434,
      "learning_rate": 5.739905050588212e-05,
      "loss": 1.7379,
      "step": 13090
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.775631070137024,
      "learning_rate": 5.734530085817245e-05,
      "loss": 1.7692,
      "step": 13100
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.9777764081954956,
      "learning_rate": 5.729154253352766e-05,
      "loss": 1.7719,
      "step": 13110
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.5708764791488647,
      "learning_rate": 5.723777559545198e-05,
      "loss": 1.7014,
      "step": 13120
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.5968717336654663,
      "learning_rate": 5.7184000107459804e-05,
      "loss": 1.8288,
      "step": 13130
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.6893370151519775,
      "learning_rate": 5.7130216133075586e-05,
      "loss": 1.7775,
      "step": 13140
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.8830387592315674,
      "learning_rate": 5.707642373583383e-05,
      "loss": 1.6765,
      "step": 13150
    },
    {
      "epoch": 1.37,
      "grad_norm": 2.0863354206085205,
      "learning_rate": 5.7022622979279014e-05,
      "loss": 1.8007,
      "step": 13160
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.5927098989486694,
      "learning_rate": 5.6968813926965445e-05,
      "loss": 1.7971,
      "step": 13170
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.5209561586380005,
      "learning_rate": 5.6914996642457254e-05,
      "loss": 1.777,
      "step": 13180
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.7399821281433105,
      "learning_rate": 5.686117118932832e-05,
      "loss": 1.76,
      "step": 13190
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.686311960220337,
      "learning_rate": 5.680733763116213e-05,
      "loss": 1.7535,
      "step": 13200
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.8038480281829834,
      "learning_rate": 5.6753496031551754e-05,
      "loss": 1.649,
      "step": 13210
    },
    {
      "epoch": 1.37,
      "grad_norm": 2.4166643619537354,
      "learning_rate": 5.669964645409978e-05,
      "loss": 1.7389,
      "step": 13220
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.8084722757339478,
      "learning_rate": 5.664578896241819e-05,
      "loss": 1.7542,
      "step": 13230
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.942586064338684,
      "learning_rate": 5.659192362012837e-05,
      "loss": 1.8692,
      "step": 13240
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.745578408241272,
      "learning_rate": 5.6538050490860916e-05,
      "loss": 1.8502,
      "step": 13250
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.0183207988739014,
      "learning_rate": 5.648416963825567e-05,
      "loss": 1.628,
      "step": 13260
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.362847089767456,
      "learning_rate": 5.643028112596156e-05,
      "loss": 1.6156,
      "step": 13270
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.4915764331817627,
      "learning_rate": 5.637638501763659e-05,
      "loss": 1.6691,
      "step": 13280
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.408919095993042,
      "learning_rate": 5.632248137694773e-05,
      "loss": 1.7594,
      "step": 13290
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.7807897329330444,
      "learning_rate": 5.626857026757084e-05,
      "loss": 1.8323,
      "step": 13300
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.8392904996871948,
      "learning_rate": 5.621465175319063e-05,
      "loss": 1.699,
      "step": 13310
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.9200581312179565,
      "learning_rate": 5.6160725897500486e-05,
      "loss": 1.6927,
      "step": 13320
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.9551128149032593,
      "learning_rate": 5.6106792764202565e-05,
      "loss": 1.7351,
      "step": 13330
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.9593976736068726,
      "learning_rate": 5.605285241700756e-05,
      "loss": 1.7653,
      "step": 13340
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.8674736022949219,
      "learning_rate": 5.5998904919634677e-05,
      "loss": 1.8094,
      "step": 13350
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.6164405345916748,
      "learning_rate": 5.5944950335811616e-05,
      "loss": 1.6555,
      "step": 13360
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.572021484375,
      "learning_rate": 5.5890988729274406e-05,
      "loss": 1.7606,
      "step": 13370
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.8193321228027344,
      "learning_rate": 5.5837020163767406e-05,
      "loss": 1.8004,
      "step": 13380
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.5693353414535522,
      "learning_rate": 5.578304470304314e-05,
      "loss": 1.7129,
      "step": 13390
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.73589026927948,
      "learning_rate": 5.572906241086237e-05,
      "loss": 1.6969,
      "step": 13400
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.638378620147705,
      "learning_rate": 5.567507335099381e-05,
      "loss": 1.641,
      "step": 13410
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.711919903755188,
      "learning_rate": 5.562107758721426e-05,
      "loss": 1.7679,
      "step": 13420
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.5035967826843262,
      "learning_rate": 5.556707518330844e-05,
      "loss": 1.712,
      "step": 13430
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.7220559120178223,
      "learning_rate": 5.551306620306882e-05,
      "loss": 1.8028,
      "step": 13440
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.1800966262817383,
      "learning_rate": 5.545905071029574e-05,
      "loss": 1.8082,
      "step": 13450
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.5561935901641846,
      "learning_rate": 5.540502876879721e-05,
      "loss": 1.7315,
      "step": 13460
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.8323582410812378,
      "learning_rate": 5.5351000442388814e-05,
      "loss": 1.8028,
      "step": 13470
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.5720834732055664,
      "learning_rate": 5.529696579489372e-05,
      "loss": 1.7898,
      "step": 13480
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.6592367887496948,
      "learning_rate": 5.5242924890142545e-05,
      "loss": 1.6713,
      "step": 13490
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.8067582845687866,
      "learning_rate": 5.5188877791973305e-05,
      "loss": 1.6836,
      "step": 13500
    },
    {
      "epoch": 1.4,
      "eval_loss": 1.825671911239624,
      "eval_runtime": 366.4241,
      "eval_samples_per_second": 23.377,
      "eval_steps_per_second": 23.377,
      "step": 13500
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.6265206336975098,
      "learning_rate": 5.5134824564231345e-05,
      "loss": 1.7904,
      "step": 13510
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.6071974039077759,
      "learning_rate": 5.508076527076922e-05,
      "loss": 1.7038,
      "step": 13520
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.9928721189498901,
      "learning_rate": 5.502669997544668e-05,
      "loss": 1.6762,
      "step": 13530
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.7896270751953125,
      "learning_rate": 5.497262874213054e-05,
      "loss": 1.7486,
      "step": 13540
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.5956016778945923,
      "learning_rate": 5.4918551634694634e-05,
      "loss": 1.8296,
      "step": 13550
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.6865053176879883,
      "learning_rate": 5.486446871701978e-05,
      "loss": 1.8403,
      "step": 13560
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.5433505773544312,
      "learning_rate": 5.4810380052993585e-05,
      "loss": 1.7835,
      "step": 13570
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.6500554084777832,
      "learning_rate": 5.47562857065105e-05,
      "loss": 1.8128,
      "step": 13580
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.8695333003997803,
      "learning_rate": 5.470218574147165e-05,
      "loss": 1.6859,
      "step": 13590
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.5007987022399902,
      "learning_rate": 5.4648080221784825e-05,
      "loss": 1.7916,
      "step": 13600
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.6831198930740356,
      "learning_rate": 5.4593969211364395e-05,
      "loss": 1.729,
      "step": 13610
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.8984510898590088,
      "learning_rate": 5.453985277413115e-05,
      "loss": 1.7362,
      "step": 13620
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.7757787704467773,
      "learning_rate": 5.448573097401236e-05,
      "loss": 1.8725,
      "step": 13630
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.5691276788711548,
      "learning_rate": 5.443160387494158e-05,
      "loss": 1.8234,
      "step": 13640
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.1832876205444336,
      "learning_rate": 5.437747154085866e-05,
      "loss": 1.7682,
      "step": 13650
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.5735580921173096,
      "learning_rate": 5.4323334035709617e-05,
      "loss": 1.6464,
      "step": 13660
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.4502867460250854,
      "learning_rate": 5.426919142344658e-05,
      "loss": 1.7624,
      "step": 13670
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.453831434249878,
      "learning_rate": 5.42150437680277e-05,
      "loss": 1.8059,
      "step": 13680
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.7388794422149658,
      "learning_rate": 5.416089113341708e-05,
      "loss": 1.7441,
      "step": 13690
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.6214500665664673,
      "learning_rate": 5.4106733583584754e-05,
      "loss": 1.6936,
      "step": 13700
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.8183201551437378,
      "learning_rate": 5.4052571182506515e-05,
      "loss": 1.7358,
      "step": 13710
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.6295475959777832,
      "learning_rate": 5.3998403994163894e-05,
      "loss": 1.7729,
      "step": 13720
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.5975855588912964,
      "learning_rate": 5.39442320825441e-05,
      "loss": 1.7984,
      "step": 13730
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.441107153892517,
      "learning_rate": 5.389005551163988e-05,
      "loss": 1.7762,
      "step": 13740
    },
    {
      "epoch": 1.43,
      "grad_norm": 2.1769912242889404,
      "learning_rate": 5.383587434544953e-05,
      "loss": 1.8924,
      "step": 13750
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.8578184843063354,
      "learning_rate": 5.378168864797675e-05,
      "loss": 1.6785,
      "step": 13760
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.8294827938079834,
      "learning_rate": 5.372749848323057e-05,
      "loss": 1.8135,
      "step": 13770
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.7801967859268188,
      "learning_rate": 5.367330391522538e-05,
      "loss": 1.7536,
      "step": 13780
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.5639870166778564,
      "learning_rate": 5.3619105007980666e-05,
      "loss": 1.807,
      "step": 13790
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.4267475605010986,
      "learning_rate": 5.356490182552112e-05,
      "loss": 1.8009,
      "step": 13800
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.7685785293579102,
      "learning_rate": 5.351069443187643e-05,
      "loss": 1.6727,
      "step": 13810
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.8919309377670288,
      "learning_rate": 5.3456482891081286e-05,
      "loss": 1.7644,
      "step": 13820
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.6742099523544312,
      "learning_rate": 5.34022672671753e-05,
      "loss": 1.678,
      "step": 13830
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.5415277481079102,
      "learning_rate": 5.334804762420284e-05,
      "loss": 1.7833,
      "step": 13840
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.720140814781189,
      "learning_rate": 5.32938240262131e-05,
      "loss": 1.7286,
      "step": 13850
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.5279357433319092,
      "learning_rate": 5.323959653725987e-05,
      "loss": 1.8021,
      "step": 13860
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.3002153635025024,
      "learning_rate": 5.318536522140162e-05,
      "loss": 1.7296,
      "step": 13870
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.6983124017715454,
      "learning_rate": 5.313113014270126e-05,
      "loss": 1.6083,
      "step": 13880
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.6865605115890503,
      "learning_rate": 5.307689136522619e-05,
      "loss": 1.8166,
      "step": 13890
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.7277889251708984,
      "learning_rate": 5.302264895304818e-05,
      "loss": 1.7366,
      "step": 13900
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.828547716140747,
      "learning_rate": 5.296840297024327e-05,
      "loss": 1.7474,
      "step": 13910
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.8004522323608398,
      "learning_rate": 5.291415348089175e-05,
      "loss": 1.79,
      "step": 13920
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.6637243032455444,
      "learning_rate": 5.2859900549078e-05,
      "loss": 1.7098,
      "step": 13930
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.8995916843414307,
      "learning_rate": 5.280564423889054e-05,
      "loss": 1.647,
      "step": 13940
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.8835408687591553,
      "learning_rate": 5.275138461442182e-05,
      "loss": 1.7838,
      "step": 13950
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.6497992277145386,
      "learning_rate": 5.269712173976821e-05,
      "loss": 1.7296,
      "step": 13960
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.9124494791030884,
      "learning_rate": 5.2642855679029967e-05,
      "loss": 1.6574,
      "step": 13970
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.4205090999603271,
      "learning_rate": 5.2588586496311056e-05,
      "loss": 1.7907,
      "step": 13980
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.554434895515442,
      "learning_rate": 5.2534314255719167e-05,
      "loss": 1.7812,
      "step": 13990
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.5145152807235718,
      "learning_rate": 5.24800390213656e-05,
      "loss": 1.6567,
      "step": 14000
    },
    {
      "epoch": 1.45,
      "eval_loss": 1.821977138519287,
      "eval_runtime": 366.7462,
      "eval_samples_per_second": 23.357,
      "eval_steps_per_second": 23.357,
      "step": 14000
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.6053533554077148,
      "learning_rate": 5.242576085736515e-05,
      "loss": 1.8696,
      "step": 14010
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.8217012882232666,
      "learning_rate": 5.237147982783613e-05,
      "loss": 1.8381,
      "step": 14020
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.8006387948989868,
      "learning_rate": 5.23171959969002e-05,
      "loss": 1.685,
      "step": 14030
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.7955118417739868,
      "learning_rate": 5.2262909428682347e-05,
      "loss": 1.7823,
      "step": 14040
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.412663221359253,
      "learning_rate": 5.220862018731079e-05,
      "loss": 1.7113,
      "step": 14050
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.9810339212417603,
      "learning_rate": 5.215432833691688e-05,
      "loss": 1.827,
      "step": 14060
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.557713270187378,
      "learning_rate": 5.2100033941635106e-05,
      "loss": 1.7033,
      "step": 14070
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.4595725536346436,
      "learning_rate": 5.204573706560288e-05,
      "loss": 1.7632,
      "step": 14080
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.782157301902771,
      "learning_rate": 5.199143777296064e-05,
      "loss": 1.8297,
      "step": 14090
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.924964189529419,
      "learning_rate": 5.1937136127851613e-05,
      "loss": 1.7485,
      "step": 14100
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.6294949054718018,
      "learning_rate": 5.1882832194421815e-05,
      "loss": 1.7807,
      "step": 14110
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.92007577419281,
      "learning_rate": 5.1828526036820005e-05,
      "loss": 1.6529,
      "step": 14120
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.633110523223877,
      "learning_rate": 5.1774217719197484e-05,
      "loss": 1.7893,
      "step": 14130
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.7357110977172852,
      "learning_rate": 5.17199073057082e-05,
      "loss": 1.8178,
      "step": 14140
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.767133116722107,
      "learning_rate": 5.1665594860508536e-05,
      "loss": 1.7083,
      "step": 14150
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.9475445747375488,
      "learning_rate": 5.161128044775726e-05,
      "loss": 1.9201,
      "step": 14160
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.8043859004974365,
      "learning_rate": 5.155696413161549e-05,
      "loss": 1.7379,
      "step": 14170
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.8183109760284424,
      "learning_rate": 5.150264597624656e-05,
      "loss": 1.7517,
      "step": 14180
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.6784543991088867,
      "learning_rate": 5.1448326045816044e-05,
      "loss": 1.7473,
      "step": 14190
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.3203253746032715,
      "learning_rate": 5.1394004404491504e-05,
      "loss": 1.7034,
      "step": 14200
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.997971534729004,
      "learning_rate": 5.1339681116442636e-05,
      "loss": 1.6694,
      "step": 14210
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.7126809358596802,
      "learning_rate": 5.128535624584102e-05,
      "loss": 1.8276,
      "step": 14220
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.5733305215835571,
      "learning_rate": 5.123102985686009e-05,
      "loss": 1.8239,
      "step": 14230
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.8597438335418701,
      "learning_rate": 5.117670201367515e-05,
      "loss": 1.817,
      "step": 14240
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.1383540630340576,
      "learning_rate": 5.112237278046311e-05,
      "loss": 1.8507,
      "step": 14250
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.7424226999282837,
      "learning_rate": 5.1068042221402636e-05,
      "loss": 1.7168,
      "step": 14260
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.571008324623108,
      "learning_rate": 5.1013710400673896e-05,
      "loss": 1.7477,
      "step": 14270
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.7364495992660522,
      "learning_rate": 5.095937738245854e-05,
      "loss": 1.8754,
      "step": 14280
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.8223260641098022,
      "learning_rate": 5.090504323093968e-05,
      "loss": 1.76,
      "step": 14290
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.391969680786133,
      "learning_rate": 5.0850708010301716e-05,
      "loss": 1.9626,
      "step": 14300
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.7599396705627441,
      "learning_rate": 5.0796371784730355e-05,
      "loss": 1.7282,
      "step": 14310
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.8202108144760132,
      "learning_rate": 5.074203461841248e-05,
      "loss": 1.8381,
      "step": 14320
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.500203013420105,
      "learning_rate": 5.068769657553604e-05,
      "loss": 1.7582,
      "step": 14330
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.6678798198699951,
      "learning_rate": 5.0633357720290084e-05,
      "loss": 1.7329,
      "step": 14340
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.562424659729004,
      "learning_rate": 5.057901811686459e-05,
      "loss": 1.7936,
      "step": 14350
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.5194463729858398,
      "learning_rate": 5.0524677829450405e-05,
      "loss": 1.7817,
      "step": 14360
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.7204724550247192,
      "learning_rate": 5.0470336922239236e-05,
      "loss": 1.6992,
      "step": 14370
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.752299189567566,
      "learning_rate": 5.0415995459423447e-05,
      "loss": 1.6845,
      "step": 14380
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.7708014249801636,
      "learning_rate": 5.036165350519614e-05,
      "loss": 1.7311,
      "step": 14390
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.874023199081421,
      "learning_rate": 5.030731112375091e-05,
      "loss": 1.8121,
      "step": 14400
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.657963752746582,
      "learning_rate": 5.025296837928194e-05,
      "loss": 1.8468,
      "step": 14410
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.5178446769714355,
      "learning_rate": 5.01986253359838e-05,
      "loss": 1.7467,
      "step": 14420
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.7487653493881226,
      "learning_rate": 5.0144282058051394e-05,
      "loss": 1.721,
      "step": 14430
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.5777119398117065,
      "learning_rate": 5.0089938609679964e-05,
      "loss": 1.7796,
      "step": 14440
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.5313037633895874,
      "learning_rate": 5.003559505506488e-05,
      "loss": 1.5936,
      "step": 14450
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.677104115486145,
      "learning_rate": 4.998125145840171e-05,
      "loss": 1.7079,
      "step": 14460
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.878828763961792,
      "learning_rate": 4.9926907883886006e-05,
      "loss": 1.7936,
      "step": 14470
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.8732277154922485,
      "learning_rate": 4.987256439571333e-05,
      "loss": 1.6431,
      "step": 14480
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.8788660764694214,
      "learning_rate": 4.981822105807914e-05,
      "loss": 1.7387,
      "step": 14490
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.0843684673309326,
      "learning_rate": 4.9763877935178716e-05,
      "loss": 1.7226,
      "step": 14500
    },
    {
      "epoch": 1.5,
      "eval_loss": 1.8211852312088013,
      "eval_runtime": 366.2631,
      "eval_samples_per_second": 23.388,
      "eval_steps_per_second": 23.388,
      "step": 14500
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.064378023147583,
      "learning_rate": 4.970953509120708e-05,
      "loss": 1.8075,
      "step": 14510
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.8801157474517822,
      "learning_rate": 4.9655192590358894e-05,
      "loss": 1.6511,
      "step": 14520
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.743606448173523,
      "learning_rate": 4.96008504968285e-05,
      "loss": 1.7931,
      "step": 14530
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.168301820755005,
      "learning_rate": 4.954650887480967e-05,
      "loss": 1.7814,
      "step": 14540
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.8315531015396118,
      "learning_rate": 4.949216778849566e-05,
      "loss": 1.6259,
      "step": 14550
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.7182848453521729,
      "learning_rate": 4.9437827302079064e-05,
      "loss": 1.7418,
      "step": 14560
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.125535726547241,
      "learning_rate": 4.9383487479751835e-05,
      "loss": 1.8425,
      "step": 14570
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.0244908332824707,
      "learning_rate": 4.9329148385705065e-05,
      "loss": 1.7707,
      "step": 14580
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.056452989578247,
      "learning_rate": 4.9274810084129005e-05,
      "loss": 1.8187,
      "step": 14590
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.6902592182159424,
      "learning_rate": 4.922047263921302e-05,
      "loss": 1.7126,
      "step": 14600
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.085232973098755,
      "learning_rate": 4.91661361151454e-05,
      "loss": 1.6736,
      "step": 14610
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.0044610500335693,
      "learning_rate": 4.911180057611338e-05,
      "loss": 1.7709,
      "step": 14620
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.8221219778060913,
      "learning_rate": 4.9057466086303e-05,
      "loss": 1.8485,
      "step": 14630
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.5554158687591553,
      "learning_rate": 4.900313270989912e-05,
      "loss": 1.7493,
      "step": 14640
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.7602338790893555,
      "learning_rate": 4.8948800511085235e-05,
      "loss": 1.7172,
      "step": 14650
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.4191302061080933,
      "learning_rate": 4.889446955404344e-05,
      "loss": 1.7376,
      "step": 14660
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.6180428266525269,
      "learning_rate": 4.884013990295442e-05,
      "loss": 1.7554,
      "step": 14670
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.7399876117706299,
      "learning_rate": 4.878581162199727e-05,
      "loss": 1.6382,
      "step": 14680
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.01802921295166,
      "learning_rate": 4.873148477534947e-05,
      "loss": 1.7381,
      "step": 14690
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.655501127243042,
      "learning_rate": 4.8677159427186827e-05,
      "loss": 1.7666,
      "step": 14700
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.537058711051941,
      "learning_rate": 4.862283564168337e-05,
      "loss": 1.6591,
      "step": 14710
    },
    {
      "epoch": 1.53,
      "grad_norm": 2.016444683074951,
      "learning_rate": 4.8568513483011265e-05,
      "loss": 1.7994,
      "step": 14720
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.6758239269256592,
      "learning_rate": 4.851419301534076e-05,
      "loss": 1.7313,
      "step": 14730
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.5401253700256348,
      "learning_rate": 4.845987430284014e-05,
      "loss": 1.7872,
      "step": 14740
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.7826755046844482,
      "learning_rate": 4.8405557409675574e-05,
      "loss": 1.6698,
      "step": 14750
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.8011690378189087,
      "learning_rate": 4.8351242400011106e-05,
      "loss": 1.7991,
      "step": 14760
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.693525791168213,
      "learning_rate": 4.829692933800855e-05,
      "loss": 1.7446,
      "step": 14770
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.9777265787124634,
      "learning_rate": 4.824261828782742e-05,
      "loss": 1.6602,
      "step": 14780
    },
    {
      "epoch": 1.53,
      "grad_norm": 2.0273165702819824,
      "learning_rate": 4.8188309313624817e-05,
      "loss": 1.763,
      "step": 14790
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.4257603883743286,
      "learning_rate": 4.813400247955548e-05,
      "loss": 1.6963,
      "step": 14800
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.9660276174545288,
      "learning_rate": 4.807969784977153e-05,
      "loss": 1.8324,
      "step": 14810
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.5245548486709595,
      "learning_rate": 4.8025395488422524e-05,
      "loss": 1.6549,
      "step": 14820
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.439483404159546,
      "learning_rate": 4.7971095459655316e-05,
      "loss": 1.7148,
      "step": 14830
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.6581459045410156,
      "learning_rate": 4.7916797827614046e-05,
      "loss": 1.7787,
      "step": 14840
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.5078065395355225,
      "learning_rate": 4.7862502656439994e-05,
      "loss": 1.7744,
      "step": 14850
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.7068098783493042,
      "learning_rate": 4.780821001027151e-05,
      "loss": 1.7853,
      "step": 14860
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.6072614192962646,
      "learning_rate": 4.775391995324403e-05,
      "loss": 1.6822,
      "step": 14870
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.5209461450576782,
      "learning_rate": 4.769963254948988e-05,
      "loss": 1.7398,
      "step": 14880
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.7656437158584595,
      "learning_rate": 4.764534786313824e-05,
      "loss": 1.6027,
      "step": 14890
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.58052659034729,
      "learning_rate": 4.7591065958315096e-05,
      "loss": 1.6341,
      "step": 14900
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.762023687362671,
      "learning_rate": 4.753678689914319e-05,
      "loss": 1.7207,
      "step": 14910
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.5801668167114258,
      "learning_rate": 4.748251074974184e-05,
      "loss": 1.8831,
      "step": 14920
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.032846689224243,
      "learning_rate": 4.7428237574226954e-05,
      "loss": 1.7461,
      "step": 14930
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.6308143138885498,
      "learning_rate": 4.7373967436710944e-05,
      "loss": 1.8228,
      "step": 14940
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.1434364318847656,
      "learning_rate": 4.73197004013026e-05,
      "loss": 1.8155,
      "step": 14950
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.8763543367385864,
      "learning_rate": 4.7265436532107055e-05,
      "loss": 1.7864,
      "step": 14960
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.6317602396011353,
      "learning_rate": 4.7211175893225724e-05,
      "loss": 1.7465,
      "step": 14970
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.0592129230499268,
      "learning_rate": 4.7156918548756195e-05,
      "loss": 1.7178,
      "step": 14980
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.749716877937317,
      "learning_rate": 4.710266456279216e-05,
      "loss": 1.759,
      "step": 14990
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.5147048234939575,
      "learning_rate": 4.704841399942331e-05,
      "loss": 1.7041,
      "step": 15000
    },
    {
      "epoch": 1.56,
      "eval_loss": 1.8174498081207275,
      "eval_runtime": 366.3462,
      "eval_samples_per_second": 23.382,
      "eval_steps_per_second": 23.382,
      "step": 15000
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.7570401430130005,
      "learning_rate": 4.699416692273538e-05,
      "loss": 1.7879,
      "step": 15010
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.4853447675704956,
      "learning_rate": 4.6939923396809895e-05,
      "loss": 1.6829,
      "step": 15020
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.063084840774536,
      "learning_rate": 4.688568348572423e-05,
      "loss": 1.8177,
      "step": 15030
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.8891421556472778,
      "learning_rate": 4.683144725355151e-05,
      "loss": 1.7505,
      "step": 15040
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.7204490900039673,
      "learning_rate": 4.677721476436046e-05,
      "loss": 1.6809,
      "step": 15050
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.0671417713165283,
      "learning_rate": 4.672298608221541e-05,
      "loss": 1.7766,
      "step": 15060
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.596518874168396,
      "learning_rate": 4.666876127117622e-05,
      "loss": 1.8296,
      "step": 15070
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.4205390214920044,
      "learning_rate": 4.6614540395298135e-05,
      "loss": 1.6437,
      "step": 15080
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.713555097579956,
      "learning_rate": 4.6560323518631773e-05,
      "loss": 1.8356,
      "step": 15090
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.8862496614456177,
      "learning_rate": 4.6506110705222995e-05,
      "loss": 1.7277,
      "step": 15100
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.8511699438095093,
      "learning_rate": 4.645190201911293e-05,
      "loss": 1.6453,
      "step": 15110
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.9584424495697021,
      "learning_rate": 4.639769752433778e-05,
      "loss": 1.7398,
      "step": 15120
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.6440197229385376,
      "learning_rate": 4.634349728492878e-05,
      "loss": 1.785,
      "step": 15130
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.6954493522644043,
      "learning_rate": 4.62893013649122e-05,
      "loss": 1.726,
      "step": 15140
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.585797667503357,
      "learning_rate": 4.623510982830917e-05,
      "loss": 1.7181,
      "step": 15150
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.7916380167007446,
      "learning_rate": 4.6180922739135624e-05,
      "loss": 1.826,
      "step": 15160
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.9900413751602173,
      "learning_rate": 4.612674016140226e-05,
      "loss": 1.794,
      "step": 15170
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.4220386743545532,
      "learning_rate": 4.6072562159114474e-05,
      "loss": 1.7524,
      "step": 15180
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.8379521369934082,
      "learning_rate": 4.601838879627223e-05,
      "loss": 1.7577,
      "step": 15190
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.948577880859375,
      "learning_rate": 4.596422013686997e-05,
      "loss": 1.8218,
      "step": 15200
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.7539385557174683,
      "learning_rate": 4.591005624489669e-05,
      "loss": 1.7418,
      "step": 15210
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.6684986352920532,
      "learning_rate": 4.5855897184335655e-05,
      "loss": 1.7757,
      "step": 15220
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.044492721557617,
      "learning_rate": 4.580174301916445e-05,
      "loss": 1.8309,
      "step": 15230
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.6530320644378662,
      "learning_rate": 4.5747593813354887e-05,
      "loss": 1.8336,
      "step": 15240
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.8742945194244385,
      "learning_rate": 4.569344963087293e-05,
      "loss": 1.7571,
      "step": 15250
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.9047003984451294,
      "learning_rate": 4.563931053567859e-05,
      "loss": 1.6484,
      "step": 15260
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.7135932445526123,
      "learning_rate": 4.5585176591725846e-05,
      "loss": 1.7126,
      "step": 15270
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.9345529079437256,
      "learning_rate": 4.553104786296266e-05,
      "loss": 1.722,
      "step": 15280
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.804878830909729,
      "learning_rate": 4.547692441333075e-05,
      "loss": 1.7946,
      "step": 15290
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.8521320819854736,
      "learning_rate": 4.542280630676567e-05,
      "loss": 1.8168,
      "step": 15300
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.7003892660140991,
      "learning_rate": 4.536869360719663e-05,
      "loss": 1.7608,
      "step": 15310
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.8388439416885376,
      "learning_rate": 4.531458637854646e-05,
      "loss": 1.7169,
      "step": 15320
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.7295011281967163,
      "learning_rate": 4.526048468473149e-05,
      "loss": 1.7333,
      "step": 15330
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.7310831546783447,
      "learning_rate": 4.5206388589661575e-05,
      "loss": 1.682,
      "step": 15340
    },
    {
      "epoch": 1.59,
      "grad_norm": 2.0394797325134277,
      "learning_rate": 4.515229815723992e-05,
      "loss": 1.6405,
      "step": 15350
    },
    {
      "epoch": 1.59,
      "grad_norm": 2.356632947921753,
      "learning_rate": 4.5098213451363044e-05,
      "loss": 1.7967,
      "step": 15360
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.9573661088943481,
      "learning_rate": 4.504413453592069e-05,
      "loss": 1.7936,
      "step": 15370
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.4204388856887817,
      "learning_rate": 4.4990061474795795e-05,
      "loss": 1.6704,
      "step": 15380
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.5864123106002808,
      "learning_rate": 4.493599433186436e-05,
      "loss": 1.8432,
      "step": 15390
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.8927247524261475,
      "learning_rate": 4.488193317099536e-05,
      "loss": 1.7644,
      "step": 15400
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.1565561294555664,
      "learning_rate": 4.482787805605079e-05,
      "loss": 1.7559,
      "step": 15410
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.8506596088409424,
      "learning_rate": 4.477382905088541e-05,
      "loss": 1.642,
      "step": 15420
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.4641767740249634,
      "learning_rate": 4.471978621934683e-05,
      "loss": 1.6942,
      "step": 15430
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.9941233396530151,
      "learning_rate": 4.4665749625275306e-05,
      "loss": 1.6424,
      "step": 15440
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.6294447183609009,
      "learning_rate": 4.4611719332503804e-05,
      "loss": 1.6512,
      "step": 15450
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.9060529470443726,
      "learning_rate": 4.455769540485778e-05,
      "loss": 1.7825,
      "step": 15460
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.7240620851516724,
      "learning_rate": 4.450367790615517e-05,
      "loss": 1.7726,
      "step": 15470
    },
    {
      "epoch": 1.61,
      "grad_norm": 4.409183502197266,
      "learning_rate": 4.444966690020639e-05,
      "loss": 1.6905,
      "step": 15480
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.2974400520324707,
      "learning_rate": 4.439566245081411e-05,
      "loss": 1.6317,
      "step": 15490
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.8778635263442993,
      "learning_rate": 4.4341664621773274e-05,
      "loss": 1.8078,
      "step": 15500
    },
    {
      "epoch": 1.61,
      "eval_loss": 1.8171391487121582,
      "eval_runtime": 366.2013,
      "eval_samples_per_second": 23.392,
      "eval_steps_per_second": 23.392,
      "step": 15500
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.492081880569458,
      "learning_rate": 4.428767347687101e-05,
      "loss": 1.6507,
      "step": 15510
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.768723964691162,
      "learning_rate": 4.423368907988658e-05,
      "loss": 1.6838,
      "step": 15520
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.9660022258758545,
      "learning_rate": 4.4179711494591215e-05,
      "loss": 1.69,
      "step": 15530
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.6948356628417969,
      "learning_rate": 4.412574078474814e-05,
      "loss": 1.9443,
      "step": 15540
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.0443897247314453,
      "learning_rate": 4.4071777014112454e-05,
      "loss": 1.8647,
      "step": 15550
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.7419006824493408,
      "learning_rate": 4.401782024643105e-05,
      "loss": 1.7897,
      "step": 15560
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.7374680042266846,
      "learning_rate": 4.396387054544254e-05,
      "loss": 1.7596,
      "step": 15570
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.4654141664505005,
      "learning_rate": 4.390992797487723e-05,
      "loss": 1.7749,
      "step": 15580
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.8608007431030273,
      "learning_rate": 4.385599259845696e-05,
      "loss": 1.756,
      "step": 15590
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.6012438535690308,
      "learning_rate": 4.3802064479895055e-05,
      "loss": 1.7289,
      "step": 15600
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.629525899887085,
      "learning_rate": 4.3748143682896346e-05,
      "loss": 1.77,
      "step": 15610
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.7283653020858765,
      "learning_rate": 4.3694230271156945e-05,
      "loss": 1.7916,
      "step": 15620
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.723706841468811,
      "learning_rate": 4.364032430836425e-05,
      "loss": 1.7782,
      "step": 15630
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.9755113124847412,
      "learning_rate": 4.3586425858196864e-05,
      "loss": 1.6763,
      "step": 15640
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.8037445545196533,
      "learning_rate": 4.353253498432455e-05,
      "loss": 1.7717,
      "step": 15650
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.9222335815429688,
      "learning_rate": 4.3478651750408084e-05,
      "loss": 1.7416,
      "step": 15660
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.6979451179504395,
      "learning_rate": 4.3424776220099186e-05,
      "loss": 1.7691,
      "step": 15670
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.8028030395507812,
      "learning_rate": 4.3370908457040584e-05,
      "loss": 1.7439,
      "step": 15680
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.4959858655929565,
      "learning_rate": 4.331704852486572e-05,
      "loss": 1.6815,
      "step": 15690
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.7020817995071411,
      "learning_rate": 4.326319648719883e-05,
      "loss": 1.6077,
      "step": 15700
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.7064061164855957,
      "learning_rate": 4.320935240765481e-05,
      "loss": 1.7616,
      "step": 15710
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.2971737384796143,
      "learning_rate": 4.31555163498392e-05,
      "loss": 1.6882,
      "step": 15720
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.8578754663467407,
      "learning_rate": 4.3101688377348e-05,
      "loss": 1.6733,
      "step": 15730
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.5272380113601685,
      "learning_rate": 4.30478685537677e-05,
      "loss": 1.6645,
      "step": 15740
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.7057900428771973,
      "learning_rate": 4.299405694267517e-05,
      "loss": 1.7531,
      "step": 15750
    },
    {
      "epoch": 1.64,
      "grad_norm": 2.186333656311035,
      "learning_rate": 4.294025360763755e-05,
      "loss": 1.8951,
      "step": 15760
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.8391882181167603,
      "learning_rate": 4.28864586122122e-05,
      "loss": 1.7716,
      "step": 15770
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.7556437253952026,
      "learning_rate": 4.2832672019946654e-05,
      "loss": 1.7498,
      "step": 15780
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.6501151323318481,
      "learning_rate": 4.277889389437853e-05,
      "loss": 1.8202,
      "step": 15790
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.7289921045303345,
      "learning_rate": 4.27251242990354e-05,
      "loss": 1.7064,
      "step": 15800
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.8197473287582397,
      "learning_rate": 4.267136329743479e-05,
      "loss": 1.7391,
      "step": 15810
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.4985486268997192,
      "learning_rate": 4.261761095308407e-05,
      "loss": 1.7157,
      "step": 15820
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.9257128238677979,
      "learning_rate": 4.256386732948038e-05,
      "loss": 1.675,
      "step": 15830
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.605758547782898,
      "learning_rate": 4.251013249011055e-05,
      "loss": 1.6865,
      "step": 15840
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.894626498222351,
      "learning_rate": 4.2456406498451065e-05,
      "loss": 1.6771,
      "step": 15850
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.9029922485351562,
      "learning_rate": 4.240268941796791e-05,
      "loss": 1.8081,
      "step": 15860
    },
    {
      "epoch": 1.65,
      "grad_norm": 2.079777717590332,
      "learning_rate": 4.234898131211657e-05,
      "loss": 1.7065,
      "step": 15870
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.944622278213501,
      "learning_rate": 4.229528224434196e-05,
      "loss": 1.8179,
      "step": 15880
    },
    {
      "epoch": 1.65,
      "grad_norm": 2.0569510459899902,
      "learning_rate": 4.224159227807826e-05,
      "loss": 1.734,
      "step": 15890
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.7914897203445435,
      "learning_rate": 4.218791147674892e-05,
      "loss": 1.7031,
      "step": 15900
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.9844390153884888,
      "learning_rate": 4.213423990376657e-05,
      "loss": 1.796,
      "step": 15910
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.6550064086914062,
      "learning_rate": 4.208057762253295e-05,
      "loss": 1.7537,
      "step": 15920
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.8154542446136475,
      "learning_rate": 4.2026924696438805e-05,
      "loss": 1.7374,
      "step": 15930
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.8795181512832642,
      "learning_rate": 4.197328118886382e-05,
      "loss": 1.7686,
      "step": 15940
    },
    {
      "epoch": 1.66,
      "grad_norm": 2.1783502101898193,
      "learning_rate": 4.191964716317659e-05,
      "loss": 1.6984,
      "step": 15950
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.5463947057724,
      "learning_rate": 4.186602268273448e-05,
      "loss": 1.7079,
      "step": 15960
    },
    {
      "epoch": 1.66,
      "grad_norm": 2.1245930194854736,
      "learning_rate": 4.181240781088358e-05,
      "loss": 1.7961,
      "step": 15970
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.9698606729507446,
      "learning_rate": 4.175880261095861e-05,
      "loss": 1.689,
      "step": 15980
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.8922842741012573,
      "learning_rate": 4.170520714628296e-05,
      "loss": 1.7517,
      "step": 15990
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.6341304779052734,
      "learning_rate": 4.16516214801684e-05,
      "loss": 1.7383,
      "step": 16000
    },
    {
      "epoch": 1.66,
      "eval_loss": 1.81662118434906,
      "eval_runtime": 366.3101,
      "eval_samples_per_second": 23.385,
      "eval_steps_per_second": 23.385,
      "step": 16000
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.9299207925796509,
      "learning_rate": 4.1598045675915155e-05,
      "loss": 1.6792,
      "step": 16010
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.5200610160827637,
      "learning_rate": 4.154447979681188e-05,
      "loss": 1.7921,
      "step": 16020
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.8937708139419556,
      "learning_rate": 4.149092390613541e-05,
      "loss": 1.7122,
      "step": 16030
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.6517654657363892,
      "learning_rate": 4.1437378067150824e-05,
      "loss": 1.7424,
      "step": 16040
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.9769150018692017,
      "learning_rate": 4.138384234311131e-05,
      "loss": 1.8824,
      "step": 16050
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.5800868272781372,
      "learning_rate": 4.1330316797258144e-05,
      "loss": 1.7248,
      "step": 16060
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.4852451086044312,
      "learning_rate": 4.127680149282054e-05,
      "loss": 1.7923,
      "step": 16070
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.5246202945709229,
      "learning_rate": 4.12232964930156e-05,
      "loss": 1.763,
      "step": 16080
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.7764426469802856,
      "learning_rate": 4.116980186104831e-05,
      "loss": 1.6423,
      "step": 16090
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.4783328771591187,
      "learning_rate": 4.111631766011136e-05,
      "loss": 1.7599,
      "step": 16100
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.690195918083191,
      "learning_rate": 4.106284395338515e-05,
      "loss": 1.7715,
      "step": 16110
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.5150066614151,
      "learning_rate": 4.100938080403767e-05,
      "loss": 1.8165,
      "step": 16120
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.690779685974121,
      "learning_rate": 4.0955928275224425e-05,
      "loss": 1.7657,
      "step": 16130
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.8155204057693481,
      "learning_rate": 4.090248643008837e-05,
      "loss": 1.7711,
      "step": 16140
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.6623420715332031,
      "learning_rate": 4.08490553317599e-05,
      "loss": 1.7453,
      "step": 16150
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.6312954425811768,
      "learning_rate": 4.079563504335665e-05,
      "loss": 1.8055,
      "step": 16160
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.618301272392273,
      "learning_rate": 4.0742225627983504e-05,
      "loss": 1.8081,
      "step": 16170
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.7084639072418213,
      "learning_rate": 4.068882714873248e-05,
      "loss": 1.7562,
      "step": 16180
    },
    {
      "epoch": 1.68,
      "grad_norm": 2.090695381164551,
      "learning_rate": 4.063543966868275e-05,
      "loss": 1.6162,
      "step": 16190
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.4612301588058472,
      "learning_rate": 4.0582063250900427e-05,
      "loss": 1.7852,
      "step": 16200
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.7365412712097168,
      "learning_rate": 4.052869795843853e-05,
      "loss": 1.8062,
      "step": 16210
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.862106204032898,
      "learning_rate": 4.047534385433705e-05,
      "loss": 1.7058,
      "step": 16220
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.695813775062561,
      "learning_rate": 4.042200100162265e-05,
      "loss": 1.7624,
      "step": 16230
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.523480772972107,
      "learning_rate": 4.036866946330875e-05,
      "loss": 1.7498,
      "step": 16240
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.5989012718200684,
      "learning_rate": 4.0315349302395374e-05,
      "loss": 1.7297,
      "step": 16250
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.5897198915481567,
      "learning_rate": 4.0262040581869166e-05,
      "loss": 1.7716,
      "step": 16260
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.6602789163589478,
      "learning_rate": 4.0208743364703206e-05,
      "loss": 1.7288,
      "step": 16270
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.9915693998336792,
      "learning_rate": 4.015545771385697e-05,
      "loss": 1.792,
      "step": 16280
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.6969940662384033,
      "learning_rate": 4.010218369227634e-05,
      "loss": 1.6862,
      "step": 16290
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.9395716190338135,
      "learning_rate": 4.004892136289341e-05,
      "loss": 1.6917,
      "step": 16300
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.8970733880996704,
      "learning_rate": 3.999567078862644e-05,
      "loss": 1.725,
      "step": 16310
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.9652094841003418,
      "learning_rate": 3.994243203237986e-05,
      "loss": 1.8782,
      "step": 16320
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.67715585231781,
      "learning_rate": 3.988920515704412e-05,
      "loss": 1.7114,
      "step": 16330
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.7144254446029663,
      "learning_rate": 3.983599022549561e-05,
      "loss": 1.7511,
      "step": 16340
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.2575738430023193,
      "learning_rate": 3.978278730059664e-05,
      "loss": 1.82,
      "step": 16350
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.8243961334228516,
      "learning_rate": 3.972959644519533e-05,
      "loss": 1.7821,
      "step": 16360
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.8537522554397583,
      "learning_rate": 3.967641772212552e-05,
      "loss": 1.7257,
      "step": 16370
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.6676013469696045,
      "learning_rate": 3.962325119420676e-05,
      "loss": 1.8542,
      "step": 16380
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.5208179950714111,
      "learning_rate": 3.957009692424418e-05,
      "loss": 1.7475,
      "step": 16390
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.7091295719146729,
      "learning_rate": 3.951695497502837e-05,
      "loss": 1.6651,
      "step": 16400
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.0214180946350098,
      "learning_rate": 3.946382540933548e-05,
      "loss": 1.6908,
      "step": 16410
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.7578003406524658,
      "learning_rate": 3.941070828992694e-05,
      "loss": 1.7727,
      "step": 16420
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.4645142555236816,
      "learning_rate": 3.935760367954948e-05,
      "loss": 1.6917,
      "step": 16430
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.790533423423767,
      "learning_rate": 3.9304511640935126e-05,
      "loss": 1.7335,
      "step": 16440
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.940284252166748,
      "learning_rate": 3.925143223680099e-05,
      "loss": 1.7336,
      "step": 16450
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.8004248142242432,
      "learning_rate": 3.919836552984924e-05,
      "loss": 1.6357,
      "step": 16460
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.9702742099761963,
      "learning_rate": 3.9145311582767134e-05,
      "loss": 1.7547,
      "step": 16470
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.814719557762146,
      "learning_rate": 3.909227045822678e-05,
      "loss": 1.7193,
      "step": 16480
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.6696105003356934,
      "learning_rate": 3.903924221888516e-05,
      "loss": 1.9167,
      "step": 16490
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.6652041673660278,
      "learning_rate": 3.898622692738401e-05,
      "loss": 1.8053,
      "step": 16500
    },
    {
      "epoch": 1.71,
      "eval_loss": 1.8131147623062134,
      "eval_runtime": 366.1632,
      "eval_samples_per_second": 23.394,
      "eval_steps_per_second": 23.394,
      "step": 16500
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.6447895765304565,
      "learning_rate": 3.893322464634985e-05,
      "loss": 1.7812,
      "step": 16510
    },
    {
      "epoch": 1.71,
      "grad_norm": 2.0118160247802734,
      "learning_rate": 3.888553376911675e-05,
      "loss": 1.7808,
      "step": 16520
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.139307975769043,
      "learning_rate": 3.8832556380450626e-05,
      "loss": 1.8111,
      "step": 16530
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.3411478996276855,
      "learning_rate": 3.877959218378102e-05,
      "loss": 1.7589,
      "step": 16540
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.901596784591675,
      "learning_rate": 3.872664124167409e-05,
      "loss": 1.6904,
      "step": 16550
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.8696776628494263,
      "learning_rate": 3.867370361668026e-05,
      "loss": 1.785,
      "step": 16560
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.6531987190246582,
      "learning_rate": 3.8620779371334254e-05,
      "loss": 1.7678,
      "step": 16570
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.9474565982818604,
      "learning_rate": 3.8567868568154966e-05,
      "loss": 1.7951,
      "step": 16580
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.707370400428772,
      "learning_rate": 3.851497126964547e-05,
      "loss": 1.6892,
      "step": 16590
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.7385759353637695,
      "learning_rate": 3.8462087538292836e-05,
      "loss": 1.6271,
      "step": 16600
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.8290884494781494,
      "learning_rate": 3.8409217436568084e-05,
      "loss": 1.6951,
      "step": 16610
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.1620302200317383,
      "learning_rate": 3.835636102692623e-05,
      "loss": 1.7133,
      "step": 16620
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.5228387117385864,
      "learning_rate": 3.8303518371806026e-05,
      "loss": 1.698,
      "step": 16630
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.771654725074768,
      "learning_rate": 3.8250689533629984e-05,
      "loss": 1.6781,
      "step": 16640
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.8725544214248657,
      "learning_rate": 3.819787457480436e-05,
      "loss": 1.702,
      "step": 16650
    },
    {
      "epoch": 1.73,
      "grad_norm": 2.0243735313415527,
      "learning_rate": 3.814507355771895e-05,
      "loss": 1.7657,
      "step": 16660
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.6758614778518677,
      "learning_rate": 3.8092286544747105e-05,
      "loss": 1.7608,
      "step": 16670
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.9484138488769531,
      "learning_rate": 3.8039513598245604e-05,
      "loss": 1.6698,
      "step": 16680
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.8450829982757568,
      "learning_rate": 3.798675478055466e-05,
      "loss": 1.8651,
      "step": 16690
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.2992510795593262,
      "learning_rate": 3.7934010153997766e-05,
      "loss": 1.7181,
      "step": 16700
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.6591682434082031,
      "learning_rate": 3.788127978088165e-05,
      "loss": 1.8075,
      "step": 16710
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.6866164207458496,
      "learning_rate": 3.782856372349621e-05,
      "loss": 1.7961,
      "step": 16720
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.5966310501098633,
      "learning_rate": 3.777586204411443e-05,
      "loss": 1.7893,
      "step": 16730
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.458567500114441,
      "learning_rate": 3.772317480499232e-05,
      "loss": 1.7688,
      "step": 16740
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.0315213203430176,
      "learning_rate": 3.767050206836881e-05,
      "loss": 1.8345,
      "step": 16750
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.7572064399719238,
      "learning_rate": 3.7617843896465724e-05,
      "loss": 1.8577,
      "step": 16760
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.6101263761520386,
      "learning_rate": 3.756520035148765e-05,
      "loss": 1.7385,
      "step": 16770
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.9019205570220947,
      "learning_rate": 3.7512571495621906e-05,
      "loss": 1.7179,
      "step": 16780
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.7323453426361084,
      "learning_rate": 3.7459957391038506e-05,
      "loss": 1.7707,
      "step": 16790
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.5666652917861938,
      "learning_rate": 3.740735809988997e-05,
      "loss": 1.7356,
      "step": 16800
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.2675983905792236,
      "learning_rate": 3.735477368431133e-05,
      "loss": 1.8787,
      "step": 16810
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.9557133913040161,
      "learning_rate": 3.730220420642011e-05,
      "loss": 1.6703,
      "step": 16820
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.70807945728302,
      "learning_rate": 3.724964972831613e-05,
      "loss": 1.6938,
      "step": 16830
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.7812288999557495,
      "learning_rate": 3.7197110312081474e-05,
      "loss": 1.8048,
      "step": 16840
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.725895643234253,
      "learning_rate": 3.714458601978047e-05,
      "loss": 1.7092,
      "step": 16850
    },
    {
      "epoch": 1.75,
      "grad_norm": 2.3943638801574707,
      "learning_rate": 3.709207691345959e-05,
      "loss": 1.7321,
      "step": 16860
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.741224765777588,
      "learning_rate": 3.703958305514736e-05,
      "loss": 1.7048,
      "step": 16870
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.79343843460083,
      "learning_rate": 3.698710450685423e-05,
      "loss": 1.7006,
      "step": 16880
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.6665444374084473,
      "learning_rate": 3.693464133057268e-05,
      "loss": 1.7974,
      "step": 16890
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.6512389183044434,
      "learning_rate": 3.688219358827694e-05,
      "loss": 1.7778,
      "step": 16900
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.5609385967254639,
      "learning_rate": 3.682976134192302e-05,
      "loss": 1.5477,
      "step": 16910
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.7111905813217163,
      "learning_rate": 3.6777344653448675e-05,
      "loss": 1.772,
      "step": 16920
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.8164325952529907,
      "learning_rate": 3.672494358477323e-05,
      "loss": 1.8268,
      "step": 16930
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.7588251829147339,
      "learning_rate": 3.667255819779758e-05,
      "loss": 1.7621,
      "step": 16940
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.893604040145874,
      "learning_rate": 3.662018855440408e-05,
      "loss": 1.7054,
      "step": 16950
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.418157935142517,
      "learning_rate": 3.6567834716456515e-05,
      "loss": 1.7621,
      "step": 16960
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.8384097814559937,
      "learning_rate": 3.651549674579998e-05,
      "loss": 1.7783,
      "step": 16970
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.7064743041992188,
      "learning_rate": 3.646317470426083e-05,
      "loss": 1.6447,
      "step": 16980
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.8679600954055786,
      "learning_rate": 3.6410868653646604e-05,
      "loss": 1.7496,
      "step": 16990
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.550388813018799,
      "learning_rate": 3.6358578655745946e-05,
      "loss": 1.8089,
      "step": 17000
    },
    {
      "epoch": 1.76,
      "eval_loss": 1.810364007949829,
      "eval_runtime": 366.5964,
      "eval_samples_per_second": 23.366,
      "eval_steps_per_second": 23.366,
      "step": 17000
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.8952275514602661,
      "learning_rate": 3.6306304772328517e-05,
      "loss": 1.6599,
      "step": 17010
    },
    {
      "epoch": 1.77,
      "grad_norm": 2.0297632217407227,
      "learning_rate": 3.625404706514502e-05,
      "loss": 1.8822,
      "step": 17020
    },
    {
      "epoch": 1.77,
      "grad_norm": 2.3968589305877686,
      "learning_rate": 3.620180559592694e-05,
      "loss": 1.7839,
      "step": 17030
    },
    {
      "epoch": 1.77,
      "grad_norm": 2.292614459991455,
      "learning_rate": 3.6149580426386684e-05,
      "loss": 1.712,
      "step": 17040
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.7056363821029663,
      "learning_rate": 3.60973716182173e-05,
      "loss": 1.6402,
      "step": 17050
    },
    {
      "epoch": 1.77,
      "grad_norm": 2.0945303440093994,
      "learning_rate": 3.604517923309262e-05,
      "loss": 1.8871,
      "step": 17060
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.6721423864364624,
      "learning_rate": 3.5993003332667e-05,
      "loss": 1.8926,
      "step": 17070
    },
    {
      "epoch": 1.77,
      "grad_norm": 2.091209650039673,
      "learning_rate": 3.5940843978575305e-05,
      "loss": 1.715,
      "step": 17080
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.6055601835250854,
      "learning_rate": 3.588870123243295e-05,
      "loss": 1.7843,
      "step": 17090
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.8324495553970337,
      "learning_rate": 3.583657515583565e-05,
      "loss": 1.7362,
      "step": 17100
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.7596360445022583,
      "learning_rate": 3.578446581035944e-05,
      "loss": 1.6636,
      "step": 17110
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.8543744087219238,
      "learning_rate": 3.573237325756059e-05,
      "loss": 1.8242,
      "step": 17120
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.7222527265548706,
      "learning_rate": 3.568029755897559e-05,
      "loss": 1.6033,
      "step": 17130
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.656465768814087,
      "learning_rate": 3.562823877612095e-05,
      "loss": 1.7174,
      "step": 17140
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.9685415029525757,
      "learning_rate": 3.557619697049319e-05,
      "loss": 1.7203,
      "step": 17150
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.9066506624221802,
      "learning_rate": 3.552417220356886e-05,
      "loss": 1.7295,
      "step": 17160
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.3893072605133057,
      "learning_rate": 3.547216453680432e-05,
      "loss": 1.6331,
      "step": 17170
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.6233577728271484,
      "learning_rate": 3.54201740316357e-05,
      "loss": 1.7045,
      "step": 17180
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.5836642980575562,
      "learning_rate": 3.536820074947895e-05,
      "loss": 1.7416,
      "step": 17190
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.8998454809188843,
      "learning_rate": 3.531624475172959e-05,
      "loss": 1.7816,
      "step": 17200
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.630961298942566,
      "learning_rate": 3.5264306099762765e-05,
      "loss": 1.7982,
      "step": 17210
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.6460169553756714,
      "learning_rate": 3.52123848549331e-05,
      "loss": 1.6612,
      "step": 17220
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.7981737852096558,
      "learning_rate": 3.5160481078574684e-05,
      "loss": 1.7121,
      "step": 17230
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.9298129081726074,
      "learning_rate": 3.510859483200098e-05,
      "loss": 1.6733,
      "step": 17240
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.6994004249572754,
      "learning_rate": 3.50567261765047e-05,
      "loss": 1.7597,
      "step": 17250
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.7868874073028564,
      "learning_rate": 3.500487517335782e-05,
      "loss": 1.5893,
      "step": 17260
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.8275715112686157,
      "learning_rate": 3.4953041883811444e-05,
      "loss": 1.8136,
      "step": 17270
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.8649731874465942,
      "learning_rate": 3.490122636909572e-05,
      "loss": 1.8955,
      "step": 17280
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.678614616394043,
      "learning_rate": 3.4849428690419864e-05,
      "loss": 1.8774,
      "step": 17290
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.889732837677002,
      "learning_rate": 3.479764890897199e-05,
      "loss": 1.8594,
      "step": 17300
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.8273239135742188,
      "learning_rate": 3.474588708591905e-05,
      "loss": 1.7841,
      "step": 17310
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.9322259426116943,
      "learning_rate": 3.469414328240679e-05,
      "loss": 1.821,
      "step": 17320
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.8947875499725342,
      "learning_rate": 3.464241755955972e-05,
      "loss": 1.8635,
      "step": 17330
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.042100191116333,
      "learning_rate": 3.4590709978480926e-05,
      "loss": 1.6957,
      "step": 17340
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.042280435562134,
      "learning_rate": 3.4539020600252084e-05,
      "loss": 1.721,
      "step": 17350
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.865235447883606,
      "learning_rate": 3.448734948593339e-05,
      "loss": 1.7497,
      "step": 17360
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.545750617980957,
      "learning_rate": 3.4435696696563435e-05,
      "loss": 1.6796,
      "step": 17370
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.7007219791412354,
      "learning_rate": 3.438406229315919e-05,
      "loss": 1.7058,
      "step": 17380
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.3080086708068848,
      "learning_rate": 3.4332446336715853e-05,
      "loss": 1.7156,
      "step": 17390
    },
    {
      "epoch": 1.81,
      "grad_norm": 2.491379499435425,
      "learning_rate": 3.428084888820693e-05,
      "loss": 1.6804,
      "step": 17400
    },
    {
      "epoch": 1.81,
      "grad_norm": 2.0051095485687256,
      "learning_rate": 3.422927000858396e-05,
      "loss": 1.7538,
      "step": 17410
    },
    {
      "epoch": 1.81,
      "grad_norm": 2.5200939178466797,
      "learning_rate": 3.417770975877659e-05,
      "loss": 1.786,
      "step": 17420
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.7758052349090576,
      "learning_rate": 3.412616819969248e-05,
      "loss": 1.7525,
      "step": 17430
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.7880972623825073,
      "learning_rate": 3.4074645392217194e-05,
      "loss": 1.775,
      "step": 17440
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.8269505500793457,
      "learning_rate": 3.402314139721411e-05,
      "loss": 1.6956,
      "step": 17450
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.739578127861023,
      "learning_rate": 3.397165627552445e-05,
      "loss": 1.7282,
      "step": 17460
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.7035177946090698,
      "learning_rate": 3.3920190087967096e-05,
      "loss": 1.78,
      "step": 17470
    },
    {
      "epoch": 1.81,
      "grad_norm": 2.08879017829895,
      "learning_rate": 3.386874289533857e-05,
      "loss": 1.7911,
      "step": 17480
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.7736703157424927,
      "learning_rate": 3.381731475841294e-05,
      "loss": 1.7073,
      "step": 17490
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.6288375854492188,
      "learning_rate": 3.376590573794181e-05,
      "loss": 1.8332,
      "step": 17500
    },
    {
      "epoch": 1.82,
      "eval_loss": 1.8091784715652466,
      "eval_runtime": 366.5885,
      "eval_samples_per_second": 23.367,
      "eval_steps_per_second": 23.367,
      "step": 17500
    },
    {
      "epoch": 1.82,
      "grad_norm": 3.2170181274414062,
      "learning_rate": 3.3719654014279365e-05,
      "loss": 1.6991,
      "step": 17510
    },
    {
      "epoch": 1.82,
      "grad_norm": 2.016216516494751,
      "learning_rate": 3.366828148236143e-05,
      "loss": 1.8545,
      "step": 17520
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.703290343284607,
      "learning_rate": 3.361692824294958e-05,
      "loss": 1.8037,
      "step": 17530
    },
    {
      "epoch": 1.82,
      "grad_norm": 2.549917459487915,
      "learning_rate": 3.356559435670695e-05,
      "loss": 1.7316,
      "step": 17540
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.6355971097946167,
      "learning_rate": 3.351427988427376e-05,
      "loss": 1.7809,
      "step": 17550
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.7272109985351562,
      "learning_rate": 3.346298488626732e-05,
      "loss": 1.6443,
      "step": 17560
    },
    {
      "epoch": 1.82,
      "grad_norm": 2.0610132217407227,
      "learning_rate": 3.3411709423281915e-05,
      "loss": 1.8138,
      "step": 17570
    },
    {
      "epoch": 1.82,
      "grad_norm": 2.0022215843200684,
      "learning_rate": 3.33604535558888e-05,
      "loss": 1.6821,
      "step": 17580
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.5714285373687744,
      "learning_rate": 3.330921734463603e-05,
      "loss": 1.8099,
      "step": 17590
    },
    {
      "epoch": 1.83,
      "grad_norm": 2.002368927001953,
      "learning_rate": 3.325800085004845e-05,
      "loss": 1.7152,
      "step": 17600
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.5882145166397095,
      "learning_rate": 3.3206804132627666e-05,
      "loss": 1.6498,
      "step": 17610
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.8166639804840088,
      "learning_rate": 3.315562725285185e-05,
      "loss": 1.8967,
      "step": 17620
    },
    {
      "epoch": 1.83,
      "grad_norm": 2.019402265548706,
      "learning_rate": 3.310447027117577e-05,
      "loss": 1.6959,
      "step": 17630
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.9664647579193115,
      "learning_rate": 3.305333324803069e-05,
      "loss": 1.6903,
      "step": 17640
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.7699487209320068,
      "learning_rate": 3.300221624382431e-05,
      "loss": 1.7574,
      "step": 17650
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.7727411985397339,
      "learning_rate": 3.2951119318940663e-05,
      "loss": 1.7156,
      "step": 17660
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.680986762046814,
      "learning_rate": 3.290004253374006e-05,
      "loss": 1.7926,
      "step": 17670
    },
    {
      "epoch": 1.83,
      "grad_norm": 2.1643805503845215,
      "learning_rate": 3.2848985948559044e-05,
      "loss": 1.6863,
      "step": 17680
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.8409324884414673,
      "learning_rate": 3.279794962371025e-05,
      "loss": 1.679,
      "step": 17690
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.6713087558746338,
      "learning_rate": 3.274693361948243e-05,
      "loss": 1.7528,
      "step": 17700
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.7310408353805542,
      "learning_rate": 3.269593799614034e-05,
      "loss": 1.7479,
      "step": 17710
    },
    {
      "epoch": 1.84,
      "grad_norm": 2.0187299251556396,
      "learning_rate": 3.26449628139246e-05,
      "loss": 1.7227,
      "step": 17720
    },
    {
      "epoch": 1.84,
      "grad_norm": 2.051468849182129,
      "learning_rate": 3.259400813305169e-05,
      "loss": 1.7506,
      "step": 17730
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.8794364929199219,
      "learning_rate": 3.254307401371395e-05,
      "loss": 1.6428,
      "step": 17740
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.6061750650405884,
      "learning_rate": 3.2492160516079364e-05,
      "loss": 1.6634,
      "step": 17750
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.4267109632492065,
      "learning_rate": 3.244126770029156e-05,
      "loss": 1.8209,
      "step": 17760
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.8083572387695312,
      "learning_rate": 3.239039562646972e-05,
      "loss": 1.6624,
      "step": 17770
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.7594400644302368,
      "learning_rate": 3.2339544354708604e-05,
      "loss": 1.8047,
      "step": 17780
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.912962555885315,
      "learning_rate": 3.228871394507831e-05,
      "loss": 1.9024,
      "step": 17790
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.8814188241958618,
      "learning_rate": 3.2237904457624304e-05,
      "loss": 1.7518,
      "step": 17800
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.569097876548767,
      "learning_rate": 3.21871159523674e-05,
      "loss": 1.6533,
      "step": 17810
    },
    {
      "epoch": 1.85,
      "grad_norm": 2.006096124649048,
      "learning_rate": 3.213634848930357e-05,
      "loss": 1.6912,
      "step": 17820
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.9717057943344116,
      "learning_rate": 3.2085602128403936e-05,
      "loss": 1.738,
      "step": 17830
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.725995659828186,
      "learning_rate": 3.2034876929614684e-05,
      "loss": 1.6671,
      "step": 17840
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.9890108108520508,
      "learning_rate": 3.198417295285705e-05,
      "loss": 1.7277,
      "step": 17850
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.9124387502670288,
      "learning_rate": 3.1933490258027155e-05,
      "loss": 1.8301,
      "step": 17860
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.7915762662887573,
      "learning_rate": 3.1882828904995956e-05,
      "loss": 1.7342,
      "step": 17870
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.9236319065093994,
      "learning_rate": 3.183218895360929e-05,
      "loss": 1.6961,
      "step": 17880
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.753072738647461,
      "learning_rate": 3.178157046368764e-05,
      "loss": 1.7839,
      "step": 17890
    },
    {
      "epoch": 1.86,
      "grad_norm": 2.130641460418701,
      "learning_rate": 3.173097349502613e-05,
      "loss": 1.6956,
      "step": 17900
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.6754326820373535,
      "learning_rate": 3.16803981073945e-05,
      "loss": 1.7571,
      "step": 17910
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.820601463317871,
      "learning_rate": 3.162984436053699e-05,
      "loss": 1.7154,
      "step": 17920
    },
    {
      "epoch": 1.86,
      "grad_norm": 2.2036285400390625,
      "learning_rate": 3.157931231417227e-05,
      "loss": 1.8026,
      "step": 17930
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.9379831552505493,
      "learning_rate": 3.152880202799334e-05,
      "loss": 1.7663,
      "step": 17940
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.9647111892700195,
      "learning_rate": 3.1478313561667576e-05,
      "loss": 1.7176,
      "step": 17950
    },
    {
      "epoch": 1.86,
      "grad_norm": 1.9282907247543335,
      "learning_rate": 3.1427846974836494e-05,
      "loss": 1.7447,
      "step": 17960
    },
    {
      "epoch": 1.86,
      "grad_norm": 2.0008018016815186,
      "learning_rate": 3.1377402327115804e-05,
      "loss": 1.6438,
      "step": 17970
    },
    {
      "epoch": 1.87,
      "grad_norm": 2.5005314350128174,
      "learning_rate": 3.1326979678095325e-05,
      "loss": 1.5362,
      "step": 17980
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.8928492069244385,
      "learning_rate": 3.127657908733883e-05,
      "loss": 1.6728,
      "step": 17990
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.557977557182312,
      "learning_rate": 3.122620061438406e-05,
      "loss": 1.8147,
      "step": 18000
    },
    {
      "epoch": 1.87,
      "eval_loss": 1.8085676431655884,
      "eval_runtime": 366.3697,
      "eval_samples_per_second": 23.381,
      "eval_steps_per_second": 23.381,
      "step": 18000
    },
    {
      "epoch": 1.87,
      "grad_norm": 2.0099904537200928,
      "learning_rate": 3.1175844318742666e-05,
      "loss": 1.8353,
      "step": 18010
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.8257983922958374,
      "learning_rate": 3.1125510259900045e-05,
      "loss": 1.7547,
      "step": 18020
    },
    {
      "epoch": 1.87,
      "grad_norm": 2.0840489864349365,
      "learning_rate": 3.1075198497315356e-05,
      "loss": 1.6653,
      "step": 18030
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.809262990951538,
      "learning_rate": 3.102490909042139e-05,
      "loss": 1.7105,
      "step": 18040
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.8285115957260132,
      "learning_rate": 3.0974642098624594e-05,
      "loss": 1.7361,
      "step": 18050
    },
    {
      "epoch": 1.87,
      "grad_norm": 1.8732426166534424,
      "learning_rate": 3.092439758130488e-05,
      "loss": 1.7656,
      "step": 18060
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.8801864385604858,
      "learning_rate": 3.087417559781558e-05,
      "loss": 1.7789,
      "step": 18070
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.6444830894470215,
      "learning_rate": 3.082397620748353e-05,
      "loss": 1.6892,
      "step": 18080
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.0586278438568115,
      "learning_rate": 3.077379946960876e-05,
      "loss": 1.6953,
      "step": 18090
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.8815083503723145,
      "learning_rate": 3.072364544346457e-05,
      "loss": 1.7586,
      "step": 18100
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.7808665037155151,
      "learning_rate": 3.067351418829744e-05,
      "loss": 1.6018,
      "step": 18110
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.065462112426758,
      "learning_rate": 3.0623405763326986e-05,
      "loss": 1.7221,
      "step": 18120
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.4484606981277466,
      "learning_rate": 3.0573320227745796e-05,
      "loss": 1.687,
      "step": 18130
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.9386175870895386,
      "learning_rate": 3.0523257640719433e-05,
      "loss": 1.7737,
      "step": 18140
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.4342511892318726,
      "learning_rate": 3.0473218061386393e-05,
      "loss": 1.6976,
      "step": 18150
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.162414789199829,
      "learning_rate": 3.042320154885795e-05,
      "loss": 1.7261,
      "step": 18160
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.5526257753372192,
      "learning_rate": 3.0373208162218127e-05,
      "loss": 1.6808,
      "step": 18170
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.9735454320907593,
      "learning_rate": 3.0323237960523655e-05,
      "loss": 1.8015,
      "step": 18180
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.8184747695922852,
      "learning_rate": 3.027329100280387e-05,
      "loss": 1.7153,
      "step": 18190
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.6774282455444336,
      "learning_rate": 3.022336734806065e-05,
      "loss": 1.7769,
      "step": 18200
    },
    {
      "epoch": 1.89,
      "grad_norm": 2.179699659347534,
      "learning_rate": 3.017346705526832e-05,
      "loss": 1.7473,
      "step": 18210
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.8403363227844238,
      "learning_rate": 3.012359018337364e-05,
      "loss": 1.7126,
      "step": 18220
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.7726383209228516,
      "learning_rate": 3.0073736791295694e-05,
      "loss": 1.7863,
      "step": 18230
    },
    {
      "epoch": 1.89,
      "grad_norm": 1.9273831844329834,
      "learning_rate": 3.0023906937925812e-05,
      "loss": 1.804,
      "step": 18240
    },
    {
      "epoch": 1.89,
      "grad_norm": 2.6159489154815674,
      "learning_rate": 2.997410068212756e-05,
      "loss": 1.7372,
      "step": 18250
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.9451448917388916,
      "learning_rate": 2.992431808273658e-05,
      "loss": 1.7611,
      "step": 18260
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.724989891052246,
      "learning_rate": 2.9874559198560587e-05,
      "loss": 1.7989,
      "step": 18270
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.7271372079849243,
      "learning_rate": 2.982482408837931e-05,
      "loss": 1.7205,
      "step": 18280
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.7554939985275269,
      "learning_rate": 2.977511281094435e-05,
      "loss": 1.7021,
      "step": 18290
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.7376060485839844,
      "learning_rate": 2.972542542497918e-05,
      "loss": 1.7808,
      "step": 18300
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.7933621406555176,
      "learning_rate": 2.9675761989179023e-05,
      "loss": 1.7346,
      "step": 18310
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.860364556312561,
      "learning_rate": 2.9626122562210866e-05,
      "loss": 1.8113,
      "step": 18320
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.2412869930267334,
      "learning_rate": 2.9576507202713276e-05,
      "loss": 1.6778,
      "step": 18330
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.7132409811019897,
      "learning_rate": 2.9526915969296405e-05,
      "loss": 1.6662,
      "step": 18340
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.2390575408935547,
      "learning_rate": 2.947734892054194e-05,
      "loss": 1.7289,
      "step": 18350
    },
    {
      "epoch": 1.91,
      "grad_norm": 2.3222172260284424,
      "learning_rate": 2.942780611500296e-05,
      "loss": 1.7442,
      "step": 18360
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.6846845149993896,
      "learning_rate": 2.9378287611203915e-05,
      "loss": 1.7343,
      "step": 18370
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.703598141670227,
      "learning_rate": 2.932879346764052e-05,
      "loss": 1.6132,
      "step": 18380
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.5728578567504883,
      "learning_rate": 2.9279323742779796e-05,
      "loss": 1.7145,
      "step": 18390
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.8759535551071167,
      "learning_rate": 2.9229878495059837e-05,
      "loss": 1.8797,
      "step": 18400
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.7827666997909546,
      "learning_rate": 2.9180457782889848e-05,
      "loss": 1.8484,
      "step": 18410
    },
    {
      "epoch": 1.91,
      "grad_norm": 2.071101665496826,
      "learning_rate": 2.9131061664650074e-05,
      "loss": 1.7163,
      "step": 18420
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.747307300567627,
      "learning_rate": 2.908169019869167e-05,
      "loss": 1.7803,
      "step": 18430
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.6045536994934082,
      "learning_rate": 2.9032343443336663e-05,
      "loss": 1.7156,
      "step": 18440
    },
    {
      "epoch": 1.91,
      "grad_norm": 1.9888962507247925,
      "learning_rate": 2.898302145687797e-05,
      "loss": 1.8473,
      "step": 18450
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.7840121984481812,
      "learning_rate": 2.8933724297579147e-05,
      "loss": 1.7061,
      "step": 18460
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.6583466529846191,
      "learning_rate": 2.888445202367449e-05,
      "loss": 1.8342,
      "step": 18470
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.9441323280334473,
      "learning_rate": 2.8835204693368844e-05,
      "loss": 1.8098,
      "step": 18480
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.764539122581482,
      "learning_rate": 2.878598236483766e-05,
      "loss": 1.7205,
      "step": 18490
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.822211503982544,
      "learning_rate": 2.8736785096226793e-05,
      "loss": 1.6932,
      "step": 18500
    },
    {
      "epoch": 1.92,
      "eval_loss": 1.806001901626587,
      "eval_runtime": 366.8617,
      "eval_samples_per_second": 23.349,
      "eval_steps_per_second": 23.349,
      "step": 18500
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.8137294054031372,
      "learning_rate": 2.8687612945652488e-05,
      "loss": 1.6822,
      "step": 18510
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.7310364246368408,
      "learning_rate": 2.86384659712014e-05,
      "loss": 1.6062,
      "step": 18520
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.7414333820343018,
      "learning_rate": 2.858934423093037e-05,
      "loss": 1.6423,
      "step": 18530
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.6736496686935425,
      "learning_rate": 2.8540247782866414e-05,
      "loss": 1.7937,
      "step": 18540
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.8820717334747314,
      "learning_rate": 2.849117668500676e-05,
      "loss": 1.6602,
      "step": 18550
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.890698790550232,
      "learning_rate": 2.8442130995318606e-05,
      "loss": 1.6383,
      "step": 18560
    },
    {
      "epoch": 1.93,
      "grad_norm": 2.1151981353759766,
      "learning_rate": 2.8393110771739174e-05,
      "loss": 1.9823,
      "step": 18570
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.9290966987609863,
      "learning_rate": 2.8344116072175575e-05,
      "loss": 1.7358,
      "step": 18580
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.925236701965332,
      "learning_rate": 2.8295146954504825e-05,
      "loss": 1.6775,
      "step": 18590
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.949389934539795,
      "learning_rate": 2.8246203476573664e-05,
      "loss": 1.7499,
      "step": 18600
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.7480649948120117,
      "learning_rate": 2.819728569619854e-05,
      "loss": 1.7244,
      "step": 18610
    },
    {
      "epoch": 1.93,
      "grad_norm": 2.0399680137634277,
      "learning_rate": 2.8148393671165618e-05,
      "loss": 1.8461,
      "step": 18620
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.7800081968307495,
      "learning_rate": 2.809952745923057e-05,
      "loss": 1.6547,
      "step": 18630
    },
    {
      "epoch": 1.93,
      "grad_norm": 1.6882325410842896,
      "learning_rate": 2.805068711811858e-05,
      "loss": 1.7701,
      "step": 18640
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.9382128715515137,
      "learning_rate": 2.800187270552428e-05,
      "loss": 1.7197,
      "step": 18650
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.7147198915481567,
      "learning_rate": 2.7953084279111706e-05,
      "loss": 1.8867,
      "step": 18660
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.6305973529815674,
      "learning_rate": 2.790432189651417e-05,
      "loss": 1.5909,
      "step": 18670
    },
    {
      "epoch": 1.94,
      "grad_norm": 2.275273561477661,
      "learning_rate": 2.7855585615334173e-05,
      "loss": 1.7936,
      "step": 18680
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.8258399963378906,
      "learning_rate": 2.780687549314348e-05,
      "loss": 1.6764,
      "step": 18690
    },
    {
      "epoch": 1.94,
      "grad_norm": 2.0471200942993164,
      "learning_rate": 2.7758191587482886e-05,
      "loss": 1.753,
      "step": 18700
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.8357669115066528,
      "learning_rate": 2.77095339558622e-05,
      "loss": 1.6853,
      "step": 18710
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.7419970035552979,
      "learning_rate": 2.766090265576028e-05,
      "loss": 1.7447,
      "step": 18720
    },
    {
      "epoch": 1.94,
      "grad_norm": 1.7705554962158203,
      "learning_rate": 2.7612297744624792e-05,
      "loss": 1.7553,
      "step": 18730
    },
    {
      "epoch": 1.94,
      "grad_norm": 2.2815189361572266,
      "learning_rate": 2.756371927987227e-05,
      "loss": 1.7837,
      "step": 18740
    },
    {
      "epoch": 1.95,
      "grad_norm": 1.4806005954742432,
      "learning_rate": 2.751516731888798e-05,
      "loss": 1.7273,
      "step": 18750
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.2902464866638184,
      "learning_rate": 2.746664191902594e-05,
      "loss": 1.7614,
      "step": 18760
    },
    {
      "epoch": 1.95,
      "grad_norm": 1.746330738067627,
      "learning_rate": 2.7418143137608727e-05,
      "loss": 1.7003,
      "step": 18770
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.2818551063537598,
      "learning_rate": 2.736967103192748e-05,
      "loss": 1.8225,
      "step": 18780
    },
    {
      "epoch": 1.95,
      "grad_norm": 1.624215841293335,
      "learning_rate": 2.7321225659241877e-05,
      "loss": 1.8248,
      "step": 18790
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.0776751041412354,
      "learning_rate": 2.7272807076779966e-05,
      "loss": 1.7854,
      "step": 18800
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.22050404548645,
      "learning_rate": 2.7224415341738147e-05,
      "loss": 1.7685,
      "step": 18810
    },
    {
      "epoch": 1.95,
      "grad_norm": 1.9911136627197266,
      "learning_rate": 2.7176050511281158e-05,
      "loss": 1.6329,
      "step": 18820
    },
    {
      "epoch": 1.95,
      "grad_norm": 1.6398905515670776,
      "learning_rate": 2.7127712642541915e-05,
      "loss": 1.7974,
      "step": 18830
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.9791041612625122,
      "learning_rate": 2.707940179262147e-05,
      "loss": 1.6566,
      "step": 18840
    },
    {
      "epoch": 1.96,
      "grad_norm": 2.0418734550476074,
      "learning_rate": 2.703111801858899e-05,
      "loss": 1.6746,
      "step": 18850
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.8670969009399414,
      "learning_rate": 2.6982861377481628e-05,
      "loss": 1.8026,
      "step": 18860
    },
    {
      "epoch": 1.96,
      "grad_norm": 2.01448130607605,
      "learning_rate": 2.693463192630452e-05,
      "loss": 1.7193,
      "step": 18870
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.7147866487503052,
      "learning_rate": 2.688642972203067e-05,
      "loss": 1.6777,
      "step": 18880
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.5420420169830322,
      "learning_rate": 2.6838254821600882e-05,
      "loss": 1.67,
      "step": 18890
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.9821171760559082,
      "learning_rate": 2.6790107281923714e-05,
      "loss": 1.7284,
      "step": 18900
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.9348418712615967,
      "learning_rate": 2.6741987159875382e-05,
      "loss": 1.7153,
      "step": 18910
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.7650444507598877,
      "learning_rate": 2.6693894512299776e-05,
      "loss": 1.7511,
      "step": 18920
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.760262131690979,
      "learning_rate": 2.664582939600827e-05,
      "loss": 1.6817,
      "step": 18930
    },
    {
      "epoch": 1.97,
      "grad_norm": 1.8471641540527344,
      "learning_rate": 2.6597791867779735e-05,
      "loss": 1.6367,
      "step": 18940
    },
    {
      "epoch": 1.97,
      "grad_norm": 2.573063850402832,
      "learning_rate": 2.6549781984360433e-05,
      "loss": 1.7429,
      "step": 18950
    },
    {
      "epoch": 1.97,
      "grad_norm": 2.2860395908355713,
      "learning_rate": 2.6501799802464033e-05,
      "loss": 1.6165,
      "step": 18960
    },
    {
      "epoch": 1.97,
      "grad_norm": 1.915836215019226,
      "learning_rate": 2.645384537877142e-05,
      "loss": 1.7564,
      "step": 18970
    },
    {
      "epoch": 1.97,
      "grad_norm": 2.0206258296966553,
      "learning_rate": 2.6405918769930675e-05,
      "loss": 1.7013,
      "step": 18980
    },
    {
      "epoch": 1.97,
      "grad_norm": 1.5002844333648682,
      "learning_rate": 2.6358020032557103e-05,
      "loss": 1.7656,
      "step": 18990
    },
    {
      "epoch": 1.97,
      "grad_norm": 1.868947982788086,
      "learning_rate": 2.6310149223233004e-05,
      "loss": 1.7515,
      "step": 19000
    },
    {
      "epoch": 1.97,
      "eval_loss": 1.8047224283218384,
      "eval_runtime": 366.541,
      "eval_samples_per_second": 23.37,
      "eval_steps_per_second": 23.37,
      "step": 19000
    },
    {
      "epoch": 1.97,
      "grad_norm": 1.7149559259414673,
      "learning_rate": 2.6262306398507718e-05,
      "loss": 1.8302,
      "step": 19010
    },
    {
      "epoch": 1.97,
      "grad_norm": 1.7412879467010498,
      "learning_rate": 2.6214491614897513e-05,
      "loss": 1.8973,
      "step": 19020
    },
    {
      "epoch": 1.97,
      "grad_norm": 1.9105485677719116,
      "learning_rate": 2.616670492888558e-05,
      "loss": 1.7057,
      "step": 19030
    },
    {
      "epoch": 1.98,
      "grad_norm": 1.8352853059768677,
      "learning_rate": 2.6118946396921862e-05,
      "loss": 1.7337,
      "step": 19040
    },
    {
      "epoch": 1.98,
      "grad_norm": 2.388744831085205,
      "learning_rate": 2.6071216075423055e-05,
      "loss": 1.75,
      "step": 19050
    },
    {
      "epoch": 1.98,
      "grad_norm": 1.7323306798934937,
      "learning_rate": 2.6023514020772566e-05,
      "loss": 1.7491,
      "step": 19060
    },
    {
      "epoch": 1.98,
      "grad_norm": 1.8521158695220947,
      "learning_rate": 2.5975840289320375e-05,
      "loss": 1.7616,
      "step": 19070
    },
    {
      "epoch": 1.98,
      "grad_norm": 2.07688570022583,
      "learning_rate": 2.5928194937382988e-05,
      "loss": 1.7216,
      "step": 19080
    },
    {
      "epoch": 1.98,
      "grad_norm": 1.7818019390106201,
      "learning_rate": 2.588057802124346e-05,
      "loss": 1.6415,
      "step": 19090
    },
    {
      "epoch": 1.98,
      "grad_norm": 1.842801809310913,
      "learning_rate": 2.5832989597151192e-05,
      "loss": 1.8134,
      "step": 19100
    },
    {
      "epoch": 1.98,
      "grad_norm": 1.7558883428573608,
      "learning_rate": 2.578542972132193e-05,
      "loss": 1.764,
      "step": 19110
    },
    {
      "epoch": 1.98,
      "grad_norm": 1.6903125047683716,
      "learning_rate": 2.57378984499377e-05,
      "loss": 1.6634,
      "step": 19120
    },
    {
      "epoch": 1.99,
      "grad_norm": 1.958221197128296,
      "learning_rate": 2.5690395839146776e-05,
      "loss": 1.7664,
      "step": 19130
    },
    {
      "epoch": 1.99,
      "grad_norm": 1.8786563873291016,
      "learning_rate": 2.564292194506355e-05,
      "loss": 1.7072,
      "step": 19140
    },
    {
      "epoch": 1.99,
      "grad_norm": 1.7025660276412964,
      "learning_rate": 2.559547682376844e-05,
      "loss": 1.6006,
      "step": 19150
    },
    {
      "epoch": 1.99,
      "grad_norm": 2.1662471294403076,
      "learning_rate": 2.5548060531307983e-05,
      "loss": 1.819,
      "step": 19160
    },
    {
      "epoch": 1.99,
      "grad_norm": 1.7931374311447144,
      "learning_rate": 2.5500673123694573e-05,
      "loss": 1.7845,
      "step": 19170
    },
    {
      "epoch": 1.99,
      "grad_norm": 2.193859100341797,
      "learning_rate": 2.5453314656906513e-05,
      "loss": 1.7965,
      "step": 19180
    },
    {
      "epoch": 1.99,
      "grad_norm": 1.4845237731933594,
      "learning_rate": 2.5405985186887892e-05,
      "loss": 1.7395,
      "step": 19190
    },
    {
      "epoch": 1.99,
      "grad_norm": 1.58220636844635,
      "learning_rate": 2.5358684769548624e-05,
      "loss": 1.803,
      "step": 19200
    },
    {
      "epoch": 1.99,
      "grad_norm": 1.6577153205871582,
      "learning_rate": 2.531141346076421e-05,
      "loss": 1.8119,
      "step": 19210
    },
    {
      "epoch": 1.99,
      "grad_norm": 2.2458736896514893,
      "learning_rate": 2.5264171316375796e-05,
      "loss": 1.7384,
      "step": 19220
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.9155051708221436,
      "learning_rate": 2.521695839219012e-05,
      "loss": 1.7333,
      "step": 19230
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.7835115194320679,
      "learning_rate": 2.516977474397935e-05,
      "loss": 1.7538,
      "step": 19240
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.156045436859131,
      "learning_rate": 2.512262042748107e-05,
      "loss": 1.8024,
      "step": 19250
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.8321380615234375,
      "learning_rate": 2.507549549839826e-05,
      "loss": 1.851,
      "step": 19260
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.8785403966903687,
      "learning_rate": 2.5028400012399155e-05,
      "loss": 1.7005,
      "step": 19270
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.970658302307129,
      "learning_rate": 2.4981334025117197e-05,
      "loss": 1.8377,
      "step": 19280
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.5068873167037964,
      "learning_rate": 2.4934297592150984e-05,
      "loss": 1.616,
      "step": 19290
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.014336347579956,
      "learning_rate": 2.4887290769064253e-05,
      "loss": 1.6582,
      "step": 19300
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.9528636932373047,
      "learning_rate": 2.4840313611385697e-05,
      "loss": 1.6262,
      "step": 19310
    },
    {
      "epoch": 2.01,
      "grad_norm": 1.768573522567749,
      "learning_rate": 2.4793366174608977e-05,
      "loss": 1.632,
      "step": 19320
    },
    {
      "epoch": 2.01,
      "grad_norm": 1.8454593420028687,
      "learning_rate": 2.4746448514192705e-05,
      "loss": 1.6866,
      "step": 19330
    },
    {
      "epoch": 2.01,
      "grad_norm": 1.7279329299926758,
      "learning_rate": 2.4699560685560248e-05,
      "loss": 1.6847,
      "step": 19340
    },
    {
      "epoch": 2.01,
      "grad_norm": 1.7248197793960571,
      "learning_rate": 2.4652702744099753e-05,
      "loss": 1.7066,
      "step": 19350
    },
    {
      "epoch": 2.01,
      "grad_norm": 1.8681834936141968,
      "learning_rate": 2.460587474516406e-05,
      "loss": 1.7047,
      "step": 19360
    },
    {
      "epoch": 2.01,
      "grad_norm": 1.7248592376708984,
      "learning_rate": 2.455907674407068e-05,
      "loss": 1.7703,
      "step": 19370
    },
    {
      "epoch": 2.01,
      "grad_norm": 1.71730637550354,
      "learning_rate": 2.4512308796101636e-05,
      "loss": 1.6338,
      "step": 19380
    },
    {
      "epoch": 2.01,
      "grad_norm": 1.9519063234329224,
      "learning_rate": 2.4465570956503458e-05,
      "loss": 1.6643,
      "step": 19390
    },
    {
      "epoch": 2.01,
      "grad_norm": 1.8911361694335938,
      "learning_rate": 2.4418863280487103e-05,
      "loss": 1.7184,
      "step": 19400
    },
    {
      "epoch": 2.01,
      "grad_norm": 2.015251636505127,
      "learning_rate": 2.4372185823227956e-05,
      "loss": 1.675,
      "step": 19410
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.1657280921936035,
      "learning_rate": 2.4325538639865636e-05,
      "loss": 1.5652,
      "step": 19420
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.0896048545837402,
      "learning_rate": 2.4278921785504026e-05,
      "loss": 1.5607,
      "step": 19430
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.8811099529266357,
      "learning_rate": 2.4232335315211176e-05,
      "loss": 1.6988,
      "step": 19440
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.97074294090271,
      "learning_rate": 2.4185779284019228e-05,
      "loss": 1.5421,
      "step": 19450
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.807339072227478,
      "learning_rate": 2.4139253746924423e-05,
      "loss": 1.599,
      "step": 19460
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.539976954460144,
      "learning_rate": 2.409275875888693e-05,
      "loss": 1.7247,
      "step": 19470
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.9486891031265259,
      "learning_rate": 2.404629437483083e-05,
      "loss": 1.7297,
      "step": 19480
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.0328590869903564,
      "learning_rate": 2.3999860649644063e-05,
      "loss": 1.7451,
      "step": 19490
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.242173433303833,
      "learning_rate": 2.395345763817838e-05,
      "loss": 1.5257,
      "step": 19500
    },
    {
      "epoch": 2.02,
      "eval_loss": 1.8105273246765137,
      "eval_runtime": 366.6802,
      "eval_samples_per_second": 23.361,
      "eval_steps_per_second": 23.361,
      "step": 19500
    },
    {
      "epoch": 2.02,
      "grad_norm": 1.6732360124588013,
      "learning_rate": 2.39070853952492e-05,
      "loss": 1.627,
      "step": 19510
    },
    {
      "epoch": 2.03,
      "grad_norm": 2.090728998184204,
      "learning_rate": 2.3860743975635613e-05,
      "loss": 1.6369,
      "step": 19520
    },
    {
      "epoch": 2.03,
      "grad_norm": 2.558203935623169,
      "learning_rate": 2.3814433434080337e-05,
      "loss": 1.7122,
      "step": 19530
    },
    {
      "epoch": 2.03,
      "grad_norm": 1.844069242477417,
      "learning_rate": 2.3768153825289556e-05,
      "loss": 1.6759,
      "step": 19540
    },
    {
      "epoch": 2.03,
      "grad_norm": 1.7304199934005737,
      "learning_rate": 2.3721905203932948e-05,
      "loss": 1.7044,
      "step": 19550
    },
    {
      "epoch": 2.03,
      "grad_norm": 1.9567567110061646,
      "learning_rate": 2.367568762464355e-05,
      "loss": 1.7476,
      "step": 19560
    },
    {
      "epoch": 2.03,
      "grad_norm": 2.193357229232788,
      "learning_rate": 2.3629501142017797e-05,
      "loss": 1.6669,
      "step": 19570
    },
    {
      "epoch": 2.03,
      "grad_norm": 2.033057928085327,
      "learning_rate": 2.3583345810615326e-05,
      "loss": 1.6227,
      "step": 19580
    },
    {
      "epoch": 2.03,
      "grad_norm": 1.8360373973846436,
      "learning_rate": 2.3537221684958983e-05,
      "loss": 1.7158,
      "step": 19590
    },
    {
      "epoch": 2.03,
      "grad_norm": 1.9333242177963257,
      "learning_rate": 2.34911288195348e-05,
      "loss": 1.5566,
      "step": 19600
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.077035427093506,
      "learning_rate": 2.344506726879183e-05,
      "loss": 1.6367,
      "step": 19610
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.248004674911499,
      "learning_rate": 2.3399037087142155e-05,
      "loss": 1.7616,
      "step": 19620
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.8292838335037231,
      "learning_rate": 2.3353038328960775e-05,
      "loss": 1.5334,
      "step": 19630
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.9103387594223022,
      "learning_rate": 2.330707104858562e-05,
      "loss": 1.5745,
      "step": 19640
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.9758840799331665,
      "learning_rate": 2.326113530031741e-05,
      "loss": 1.6937,
      "step": 19650
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.006786584854126,
      "learning_rate": 2.321523113841958e-05,
      "loss": 1.5718,
      "step": 19660
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.1312596797943115,
      "learning_rate": 2.3169358617118326e-05,
      "loss": 1.7912,
      "step": 19670
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.081690788269043,
      "learning_rate": 2.3123517790602413e-05,
      "loss": 1.6331,
      "step": 19680
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.8242489099502563,
      "learning_rate": 2.3077708713023156e-05,
      "loss": 1.6703,
      "step": 19690
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.8079164028167725,
      "learning_rate": 2.3031931438494432e-05,
      "loss": 1.5957,
      "step": 19700
    },
    {
      "epoch": 2.05,
      "grad_norm": 2.3097798824310303,
      "learning_rate": 2.298618602109248e-05,
      "loss": 1.6862,
      "step": 19710
    },
    {
      "epoch": 2.05,
      "grad_norm": 1.850260853767395,
      "learning_rate": 2.2940472514855945e-05,
      "loss": 1.5805,
      "step": 19720
    },
    {
      "epoch": 2.05,
      "grad_norm": 1.8241453170776367,
      "learning_rate": 2.2894790973785735e-05,
      "loss": 1.7747,
      "step": 19730
    },
    {
      "epoch": 2.05,
      "grad_norm": 1.8168420791625977,
      "learning_rate": 2.2849141451845067e-05,
      "loss": 1.57,
      "step": 19740
    },
    {
      "epoch": 2.05,
      "grad_norm": 2.0413031578063965,
      "learning_rate": 2.280352400295928e-05,
      "loss": 1.6412,
      "step": 19750
    },
    {
      "epoch": 2.05,
      "grad_norm": 2.115856409072876,
      "learning_rate": 2.2757938681015813e-05,
      "loss": 1.6883,
      "step": 19760
    },
    {
      "epoch": 2.05,
      "grad_norm": 1.9571243524551392,
      "learning_rate": 2.271693940430981e-05,
      "loss": 1.6068,
      "step": 19770
    },
    {
      "epoch": 2.05,
      "grad_norm": 2.184216022491455,
      "learning_rate": 2.2671415271880807e-05,
      "loss": 1.7034,
      "step": 19780
    },
    {
      "epoch": 2.05,
      "grad_norm": 2.357062339782715,
      "learning_rate": 2.262592342245295e-05,
      "loss": 1.5908,
      "step": 19790
    },
    {
      "epoch": 2.05,
      "grad_norm": 2.0332603454589844,
      "learning_rate": 2.2580463909765336e-05,
      "loss": 1.551,
      "step": 19800
    },
    {
      "epoch": 2.06,
      "grad_norm": 2.0267109870910645,
      "learning_rate": 2.2535036787518842e-05,
      "loss": 1.6742,
      "step": 19810
    },
    {
      "epoch": 2.06,
      "grad_norm": 1.6684991121292114,
      "learning_rate": 2.2489642109376142e-05,
      "loss": 1.6436,
      "step": 19820
    },
    {
      "epoch": 2.06,
      "grad_norm": 2.3741259574890137,
      "learning_rate": 2.2444279928961525e-05,
      "loss": 1.4973,
      "step": 19830
    },
    {
      "epoch": 2.06,
      "grad_norm": 2.005915641784668,
      "learning_rate": 2.239895029986091e-05,
      "loss": 1.6494,
      "step": 19840
    },
    {
      "epoch": 2.06,
      "grad_norm": 1.7193447351455688,
      "learning_rate": 2.235365327562176e-05,
      "loss": 1.7806,
      "step": 19850
    },
    {
      "epoch": 2.06,
      "grad_norm": 2.18947434425354,
      "learning_rate": 2.2308388909753008e-05,
      "loss": 1.722,
      "step": 19860
    },
    {
      "epoch": 2.06,
      "grad_norm": 1.6454615592956543,
      "learning_rate": 2.226315725572507e-05,
      "loss": 1.7221,
      "step": 19870
    },
    {
      "epoch": 2.06,
      "grad_norm": 1.8491965532302856,
      "learning_rate": 2.2217958366969643e-05,
      "loss": 1.6967,
      "step": 19880
    },
    {
      "epoch": 2.06,
      "grad_norm": 2.12011456489563,
      "learning_rate": 2.2172792296879763e-05,
      "loss": 1.7128,
      "step": 19890
    },
    {
      "epoch": 2.07,
      "grad_norm": 2.1298727989196777,
      "learning_rate": 2.2127659098809683e-05,
      "loss": 1.7376,
      "step": 19900
    },
    {
      "epoch": 2.07,
      "grad_norm": 1.9788424968719482,
      "learning_rate": 2.20825588260748e-05,
      "loss": 1.6129,
      "step": 19910
    },
    {
      "epoch": 2.07,
      "grad_norm": 1.6180686950683594,
      "learning_rate": 2.2037491531951693e-05,
      "loss": 1.7023,
      "step": 19920
    },
    {
      "epoch": 2.07,
      "grad_norm": 1.9137476682662964,
      "learning_rate": 2.1992457269677908e-05,
      "loss": 1.6529,
      "step": 19930
    },
    {
      "epoch": 2.07,
      "grad_norm": 1.712229609489441,
      "learning_rate": 2.194745609245198e-05,
      "loss": 1.5235,
      "step": 19940
    },
    {
      "epoch": 2.07,
      "grad_norm": 2.143667697906494,
      "learning_rate": 2.1902488053433413e-05,
      "loss": 1.7033,
      "step": 19950
    },
    {
      "epoch": 2.07,
      "grad_norm": 2.0184526443481445,
      "learning_rate": 2.185755320574252e-05,
      "loss": 1.6323,
      "step": 19960
    },
    {
      "epoch": 2.07,
      "grad_norm": 2.319875717163086,
      "learning_rate": 2.1812651602460388e-05,
      "loss": 1.702,
      "step": 19970
    },
    {
      "epoch": 2.07,
      "grad_norm": 2.1223666667938232,
      "learning_rate": 2.17677832966289e-05,
      "loss": 1.737,
      "step": 19980
    },
    {
      "epoch": 2.07,
      "grad_norm": 1.750496506690979,
      "learning_rate": 2.1722948341250553e-05,
      "loss": 1.59,
      "step": 19990
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.1144497394561768,
      "learning_rate": 2.1678146789288456e-05,
      "loss": 1.6507,
      "step": 20000
    },
    {
      "epoch": 2.08,
      "eval_loss": 1.811077356338501,
      "eval_runtime": 366.3519,
      "eval_samples_per_second": 23.382,
      "eval_steps_per_second": 23.382,
      "step": 20000
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.8118879795074463,
      "learning_rate": 2.163337869366624e-05,
      "loss": 1.6173,
      "step": 20010
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.1112821102142334,
      "learning_rate": 2.1588644107268075e-05,
      "loss": 1.6147,
      "step": 20020
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.776253581047058,
      "learning_rate": 2.1543943082938495e-05,
      "loss": 1.6652,
      "step": 20030
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.6985000371932983,
      "learning_rate": 2.149927567348238e-05,
      "loss": 1.6824,
      "step": 20040
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.1755285263061523,
      "learning_rate": 2.145464193166496e-05,
      "loss": 1.7228,
      "step": 20050
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.613474130630493,
      "learning_rate": 2.1410041910211633e-05,
      "loss": 1.6075,
      "step": 20060
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.0566585063934326,
      "learning_rate": 2.1365475661807993e-05,
      "loss": 1.5661,
      "step": 20070
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.0327749252319336,
      "learning_rate": 2.132094323909971e-05,
      "loss": 1.6082,
      "step": 20080
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.6664066314697266,
      "learning_rate": 2.127644469469256e-05,
      "loss": 1.7283,
      "step": 20090
    },
    {
      "epoch": 2.09,
      "grad_norm": 2.504863739013672,
      "learning_rate": 2.1231980081152232e-05,
      "loss": 1.5922,
      "step": 20100
    },
    {
      "epoch": 2.09,
      "grad_norm": 1.8795042037963867,
      "learning_rate": 2.118754945100434e-05,
      "loss": 1.5855,
      "step": 20110
    },
    {
      "epoch": 2.09,
      "grad_norm": 1.8659496307373047,
      "learning_rate": 2.1143152856734412e-05,
      "loss": 1.6187,
      "step": 20120
    },
    {
      "epoch": 2.09,
      "grad_norm": 1.9295670986175537,
      "learning_rate": 2.1098790350787705e-05,
      "loss": 1.685,
      "step": 20130
    },
    {
      "epoch": 2.09,
      "grad_norm": 2.2614126205444336,
      "learning_rate": 2.1054461985569217e-05,
      "loss": 1.5841,
      "step": 20140
    },
    {
      "epoch": 2.09,
      "grad_norm": 2.005124568939209,
      "learning_rate": 2.101016781344367e-05,
      "loss": 1.7033,
      "step": 20150
    },
    {
      "epoch": 2.09,
      "grad_norm": 2.418886184692383,
      "learning_rate": 2.0965907886735324e-05,
      "loss": 1.7263,
      "step": 20160
    },
    {
      "epoch": 2.09,
      "grad_norm": 2.037978172302246,
      "learning_rate": 2.092168225772803e-05,
      "loss": 1.7437,
      "step": 20170
    },
    {
      "epoch": 2.09,
      "grad_norm": 1.76096773147583,
      "learning_rate": 2.0877490978665087e-05,
      "loss": 1.7383,
      "step": 20180
    },
    {
      "epoch": 2.1,
      "grad_norm": 1.5886571407318115,
      "learning_rate": 2.0833334101749276e-05,
      "loss": 1.66,
      "step": 20190
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.030587911605835,
      "learning_rate": 2.0789211679142673e-05,
      "loss": 1.6183,
      "step": 20200
    },
    {
      "epoch": 2.1,
      "grad_norm": 1.9004921913146973,
      "learning_rate": 2.0745123762966677e-05,
      "loss": 1.6572,
      "step": 20210
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.3780858516693115,
      "learning_rate": 2.070107040530197e-05,
      "loss": 1.8075,
      "step": 20220
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.052269697189331,
      "learning_rate": 2.0657051658188336e-05,
      "loss": 1.6353,
      "step": 20230
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.4635205268859863,
      "learning_rate": 2.0613067573624705e-05,
      "loss": 1.6941,
      "step": 20240
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.0553042888641357,
      "learning_rate": 2.0569118203569094e-05,
      "loss": 1.7308,
      "step": 20250
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.202385187149048,
      "learning_rate": 2.0525203599938464e-05,
      "loss": 1.6382,
      "step": 20260
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.2694222927093506,
      "learning_rate": 2.048132381460873e-05,
      "loss": 1.6882,
      "step": 20270
    },
    {
      "epoch": 2.1,
      "grad_norm": 1.6923493146896362,
      "learning_rate": 2.0437478899414646e-05,
      "loss": 1.6922,
      "step": 20280
    },
    {
      "epoch": 2.11,
      "grad_norm": 2.1539840698242188,
      "learning_rate": 2.0393668906149836e-05,
      "loss": 1.5657,
      "step": 20290
    },
    {
      "epoch": 2.11,
      "grad_norm": 1.905916690826416,
      "learning_rate": 2.034989388656663e-05,
      "loss": 1.704,
      "step": 20300
    },
    {
      "epoch": 2.11,
      "grad_norm": 1.9561771154403687,
      "learning_rate": 2.030615389237601e-05,
      "loss": 1.6382,
      "step": 20310
    },
    {
      "epoch": 2.11,
      "grad_norm": 2.047546625137329,
      "learning_rate": 2.0262448975247676e-05,
      "loss": 1.6814,
      "step": 20320
    },
    {
      "epoch": 2.11,
      "grad_norm": 1.9533098936080933,
      "learning_rate": 2.021877918680981e-05,
      "loss": 1.6079,
      "step": 20330
    },
    {
      "epoch": 2.11,
      "grad_norm": 2.096038341522217,
      "learning_rate": 2.0175144578649124e-05,
      "loss": 1.6608,
      "step": 20340
    },
    {
      "epoch": 2.11,
      "grad_norm": 2.0283029079437256,
      "learning_rate": 2.013154520231075e-05,
      "loss": 1.6138,
      "step": 20350
    },
    {
      "epoch": 2.11,
      "grad_norm": 1.7313048839569092,
      "learning_rate": 2.008798110929827e-05,
      "loss": 1.727,
      "step": 20360
    },
    {
      "epoch": 2.11,
      "grad_norm": 2.146653890609741,
      "learning_rate": 2.0044452351073516e-05,
      "loss": 1.7514,
      "step": 20370
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.0785858631134033,
      "learning_rate": 2.00009589790566e-05,
      "loss": 1.5855,
      "step": 20380
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.492521047592163,
      "learning_rate": 1.9957501044625832e-05,
      "loss": 1.6561,
      "step": 20390
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.6336958408355713,
      "learning_rate": 1.991407859911765e-05,
      "loss": 1.7075,
      "step": 20400
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.816489815711975,
      "learning_rate": 1.987069169382662e-05,
      "loss": 1.5901,
      "step": 20410
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.96657395362854,
      "learning_rate": 1.9827340380005267e-05,
      "loss": 1.7548,
      "step": 20420
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.1604936122894287,
      "learning_rate": 1.978402470886409e-05,
      "loss": 1.8394,
      "step": 20430
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.778445839881897,
      "learning_rate": 1.9740744731571487e-05,
      "loss": 1.7333,
      "step": 20440
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.7017021179199219,
      "learning_rate": 1.969750049925367e-05,
      "loss": 1.6383,
      "step": 20450
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.0116055011749268,
      "learning_rate": 1.9654292062994685e-05,
      "loss": 1.5931,
      "step": 20460
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.0277669429779053,
      "learning_rate": 1.9611119473836232e-05,
      "loss": 1.787,
      "step": 20470
    },
    {
      "epoch": 2.13,
      "grad_norm": 1.902348518371582,
      "learning_rate": 1.9567982782777665e-05,
      "loss": 1.6443,
      "step": 20480
    },
    {
      "epoch": 2.13,
      "grad_norm": 1.9777095317840576,
      "learning_rate": 1.9524882040775997e-05,
      "loss": 1.7759,
      "step": 20490
    },
    {
      "epoch": 2.13,
      "grad_norm": 2.5860331058502197,
      "learning_rate": 1.948181729874571e-05,
      "loss": 1.6245,
      "step": 20500
    },
    {
      "epoch": 2.13,
      "eval_loss": 1.8105648756027222,
      "eval_runtime": 366.4189,
      "eval_samples_per_second": 23.378,
      "eval_steps_per_second": 23.378,
      "step": 20500
    },
    {
      "epoch": 2.13,
      "grad_norm": 2.164203643798828,
      "learning_rate": 1.943878860755876e-05,
      "loss": 1.6246,
      "step": 20510
    },
    {
      "epoch": 2.13,
      "grad_norm": 1.8115270137786865,
      "learning_rate": 1.9395796018044577e-05,
      "loss": 1.6955,
      "step": 20520
    },
    {
      "epoch": 2.13,
      "grad_norm": 2.1300711631774902,
      "learning_rate": 1.935283958098988e-05,
      "loss": 1.8047,
      "step": 20530
    },
    {
      "epoch": 2.13,
      "grad_norm": 2.433471202850342,
      "learning_rate": 1.930991934713871e-05,
      "loss": 1.6865,
      "step": 20540
    },
    {
      "epoch": 2.13,
      "grad_norm": 2.1313796043395996,
      "learning_rate": 1.9267035367192316e-05,
      "loss": 1.6311,
      "step": 20550
    },
    {
      "epoch": 2.13,
      "grad_norm": 2.019437313079834,
      "learning_rate": 1.922418769180918e-05,
      "loss": 1.5556,
      "step": 20560
    },
    {
      "epoch": 2.13,
      "grad_norm": 2.85005521774292,
      "learning_rate": 1.9181376371604847e-05,
      "loss": 1.613,
      "step": 20570
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.2933595180511475,
      "learning_rate": 1.9138601457151904e-05,
      "loss": 1.6039,
      "step": 20580
    },
    {
      "epoch": 2.14,
      "grad_norm": 1.771889090538025,
      "learning_rate": 1.909586299897999e-05,
      "loss": 1.6849,
      "step": 20590
    },
    {
      "epoch": 2.14,
      "grad_norm": 1.9063196182250977,
      "learning_rate": 1.9053161047575634e-05,
      "loss": 1.666,
      "step": 20600
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.1241512298583984,
      "learning_rate": 1.901049565338225e-05,
      "loss": 1.4853,
      "step": 20610
    },
    {
      "epoch": 2.14,
      "grad_norm": 1.981818675994873,
      "learning_rate": 1.896786686680005e-05,
      "loss": 1.5368,
      "step": 20620
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.1496670246124268,
      "learning_rate": 1.892527473818605e-05,
      "loss": 1.5978,
      "step": 20630
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.205709457397461,
      "learning_rate": 1.8882719317853925e-05,
      "loss": 1.7125,
      "step": 20640
    },
    {
      "epoch": 2.14,
      "grad_norm": 1.9403969049453735,
      "learning_rate": 1.884020065607397e-05,
      "loss": 1.7124,
      "step": 20650
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.3654983043670654,
      "learning_rate": 1.8797718803073117e-05,
      "loss": 1.6689,
      "step": 20660
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.8515896797180176,
      "learning_rate": 1.8755273809034767e-05,
      "loss": 1.6509,
      "step": 20670
    },
    {
      "epoch": 2.15,
      "grad_norm": 3.8761720657348633,
      "learning_rate": 1.8712865724098776e-05,
      "loss": 1.6902,
      "step": 20680
    },
    {
      "epoch": 2.15,
      "grad_norm": 2.1335904598236084,
      "learning_rate": 1.867049459836145e-05,
      "loss": 1.723,
      "step": 20690
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.803117036819458,
      "learning_rate": 1.8628160481875383e-05,
      "loss": 1.5752,
      "step": 20700
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.963526964187622,
      "learning_rate": 1.8585863424649475e-05,
      "loss": 1.6759,
      "step": 20710
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.8939738273620605,
      "learning_rate": 1.854360347664883e-05,
      "loss": 1.6327,
      "step": 20720
    },
    {
      "epoch": 2.15,
      "grad_norm": 2.0643999576568604,
      "learning_rate": 1.8501380687794752e-05,
      "loss": 1.706,
      "step": 20730
    },
    {
      "epoch": 2.15,
      "grad_norm": 2.0005550384521484,
      "learning_rate": 1.8459195107964616e-05,
      "loss": 1.6606,
      "step": 20740
    },
    {
      "epoch": 2.15,
      "grad_norm": 2.2216315269470215,
      "learning_rate": 1.8417046786991836e-05,
      "loss": 1.6229,
      "step": 20750
    },
    {
      "epoch": 2.15,
      "grad_norm": 2.2069668769836426,
      "learning_rate": 1.8374935774665862e-05,
      "loss": 1.6375,
      "step": 20760
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.1581103801727295,
      "learning_rate": 1.833286212073202e-05,
      "loss": 1.6423,
      "step": 20770
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.962293267250061,
      "learning_rate": 1.8290825874891505e-05,
      "loss": 1.593,
      "step": 20780
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.0574047565460205,
      "learning_rate": 1.824882708680138e-05,
      "loss": 1.6097,
      "step": 20790
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.8172603845596313,
      "learning_rate": 1.8206865806074396e-05,
      "loss": 1.7238,
      "step": 20800
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.1258835792541504,
      "learning_rate": 1.8164942082279023e-05,
      "loss": 1.8054,
      "step": 20810
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.130808115005493,
      "learning_rate": 1.812305596493935e-05,
      "loss": 1.5892,
      "step": 20820
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.4811623096466064,
      "learning_rate": 1.8081207503535085e-05,
      "loss": 1.6382,
      "step": 20830
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.0326476097106934,
      "learning_rate": 1.8039396747501407e-05,
      "loss": 1.6846,
      "step": 20840
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.0371601581573486,
      "learning_rate": 1.7997623746228954e-05,
      "loss": 1.85,
      "step": 20850
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.8273868560791016,
      "learning_rate": 1.7955888549063815e-05,
      "loss": 1.5751,
      "step": 20860
    },
    {
      "epoch": 2.17,
      "grad_norm": 1.9725466966629028,
      "learning_rate": 1.7914191205307374e-05,
      "loss": 1.6952,
      "step": 20870
    },
    {
      "epoch": 2.17,
      "grad_norm": 1.8331764936447144,
      "learning_rate": 1.7872531764216303e-05,
      "loss": 1.6171,
      "step": 20880
    },
    {
      "epoch": 2.17,
      "grad_norm": 1.8374881744384766,
      "learning_rate": 1.7830910275002504e-05,
      "loss": 1.5778,
      "step": 20890
    },
    {
      "epoch": 2.17,
      "grad_norm": 2.2908289432525635,
      "learning_rate": 1.7789326786833076e-05,
      "loss": 1.6358,
      "step": 20900
    },
    {
      "epoch": 2.17,
      "grad_norm": 1.9256044626235962,
      "learning_rate": 1.7747781348830202e-05,
      "loss": 1.74,
      "step": 20910
    },
    {
      "epoch": 2.17,
      "grad_norm": 2.4058921337127686,
      "learning_rate": 1.77062740100711e-05,
      "loss": 1.546,
      "step": 20920
    },
    {
      "epoch": 2.17,
      "grad_norm": 2.4037487506866455,
      "learning_rate": 1.7664804819588014e-05,
      "loss": 1.6088,
      "step": 20930
    },
    {
      "epoch": 2.17,
      "grad_norm": 2.5033981800079346,
      "learning_rate": 1.762337382636809e-05,
      "loss": 1.6523,
      "step": 20940
    },
    {
      "epoch": 2.17,
      "grad_norm": 2.5477356910705566,
      "learning_rate": 1.7581981079353397e-05,
      "loss": 1.7759,
      "step": 20950
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.8834174871444702,
      "learning_rate": 1.7540626627440798e-05,
      "loss": 1.5955,
      "step": 20960
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.9881092309951782,
      "learning_rate": 1.749931051948191e-05,
      "loss": 1.5462,
      "step": 20970
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.2023017406463623,
      "learning_rate": 1.7458032804283064e-05,
      "loss": 1.6887,
      "step": 20980
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.8178751468658447,
      "learning_rate": 1.7416793530605223e-05,
      "loss": 1.7015,
      "step": 20990
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.019819736480713,
      "learning_rate": 1.7375592747163993e-05,
      "loss": 1.6069,
      "step": 21000
    },
    {
      "epoch": 2.18,
      "eval_loss": 1.810892939567566,
      "eval_runtime": 366.8984,
      "eval_samples_per_second": 23.347,
      "eval_steps_per_second": 23.347,
      "step": 21000
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.5480799674987793,
      "learning_rate": 1.733443050262945e-05,
      "loss": 1.6696,
      "step": 21010
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.50299072265625,
      "learning_rate": 1.7293306845626157e-05,
      "loss": 1.7032,
      "step": 21020
    },
    {
      "epoch": 2.18,
      "grad_norm": 1.792701244354248,
      "learning_rate": 1.7252221824733133e-05,
      "loss": 1.7496,
      "step": 21030
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.1296536922454834,
      "learning_rate": 1.7211175488483715e-05,
      "loss": 1.5617,
      "step": 21040
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.211948871612549,
      "learning_rate": 1.7170167885365535e-05,
      "loss": 1.7236,
      "step": 21050
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.0043225288391113,
      "learning_rate": 1.7129199063820527e-05,
      "loss": 1.6516,
      "step": 21060
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.4067461490631104,
      "learning_rate": 1.708826907224476e-05,
      "loss": 1.6243,
      "step": 21070
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.2569186687469482,
      "learning_rate": 1.7047377958988452e-05,
      "loss": 1.6654,
      "step": 21080
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.0740249156951904,
      "learning_rate": 1.700652577235587e-05,
      "loss": 1.8157,
      "step": 21090
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.028871536254883,
      "learning_rate": 1.696571256060535e-05,
      "loss": 1.6911,
      "step": 21100
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.111984968185425,
      "learning_rate": 1.692493837194915e-05,
      "loss": 1.7281,
      "step": 21110
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.085453748703003,
      "learning_rate": 1.6884203254553416e-05,
      "loss": 1.6246,
      "step": 21120
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.1685590744018555,
      "learning_rate": 1.6843507256538187e-05,
      "loss": 1.6514,
      "step": 21130
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.581775426864624,
      "learning_rate": 1.6802850425977258e-05,
      "loss": 1.6531,
      "step": 21140
    },
    {
      "epoch": 2.19,
      "grad_norm": 1.765169620513916,
      "learning_rate": 1.676223281089816e-05,
      "loss": 1.6531,
      "step": 21150
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.214644432067871,
      "learning_rate": 1.6721654459282078e-05,
      "loss": 1.6554,
      "step": 21160
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.02850604057312,
      "learning_rate": 1.6681115419063875e-05,
      "loss": 1.616,
      "step": 21170
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.5604909658432007,
      "learning_rate": 1.6640615738131933e-05,
      "loss": 1.6434,
      "step": 21180
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.3961880207061768,
      "learning_rate": 1.660015546432811e-05,
      "loss": 1.5383,
      "step": 21190
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.293530225753784,
      "learning_rate": 1.6559734645447793e-05,
      "loss": 1.7105,
      "step": 21200
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.045866012573242,
      "learning_rate": 1.6519353329239705e-05,
      "loss": 1.73,
      "step": 21210
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.360307216644287,
      "learning_rate": 1.6479011563405895e-05,
      "loss": 1.709,
      "step": 21220
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.8806208372116089,
      "learning_rate": 1.643870939560174e-05,
      "loss": 1.6937,
      "step": 21230
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.6277527809143066,
      "learning_rate": 1.6398446873435802e-05,
      "loss": 1.8284,
      "step": 21240
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.7662577629089355,
      "learning_rate": 1.6358224044469827e-05,
      "loss": 1.668,
      "step": 21250
    },
    {
      "epoch": 2.21,
      "grad_norm": 1.7903400659561157,
      "learning_rate": 1.631804095621864e-05,
      "loss": 1.5417,
      "step": 21260
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.3887574672698975,
      "learning_rate": 1.627789765615018e-05,
      "loss": 1.6399,
      "step": 21270
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.2535059452056885,
      "learning_rate": 1.6237794191685347e-05,
      "loss": 1.6567,
      "step": 21280
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.2993462085723877,
      "learning_rate": 1.6197730610197952e-05,
      "loss": 1.6288,
      "step": 21290
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.2640390396118164,
      "learning_rate": 1.6157706959014785e-05,
      "loss": 1.6507,
      "step": 21300
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.0007011890411377,
      "learning_rate": 1.611772328541537e-05,
      "loss": 1.6739,
      "step": 21310
    },
    {
      "epoch": 2.21,
      "grad_norm": 1.7314629554748535,
      "learning_rate": 1.607777963663205e-05,
      "loss": 1.6503,
      "step": 21320
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.0366673469543457,
      "learning_rate": 1.60378760598499e-05,
      "loss": 1.6256,
      "step": 21330
    },
    {
      "epoch": 2.21,
      "grad_norm": 1.8097586631774902,
      "learning_rate": 1.5998012602206637e-05,
      "loss": 1.6128,
      "step": 21340
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.2937819957733154,
      "learning_rate": 1.5958189310792583e-05,
      "loss": 1.4979,
      "step": 21350
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.420308828353882,
      "learning_rate": 1.5918406232650602e-05,
      "loss": 1.6242,
      "step": 21360
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.3087563514709473,
      "learning_rate": 1.5878663414776113e-05,
      "loss": 1.6866,
      "step": 21370
    },
    {
      "epoch": 2.22,
      "grad_norm": 1.978890061378479,
      "learning_rate": 1.5838960904116906e-05,
      "loss": 1.5951,
      "step": 21380
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.510997772216797,
      "learning_rate": 1.5799298747573177e-05,
      "loss": 1.7027,
      "step": 21390
    },
    {
      "epoch": 2.22,
      "grad_norm": 1.6033395528793335,
      "learning_rate": 1.575967699199749e-05,
      "loss": 1.7557,
      "step": 21400
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.835613965988159,
      "learning_rate": 1.5720095684194643e-05,
      "loss": 1.7252,
      "step": 21410
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.316861867904663,
      "learning_rate": 1.568055487092165e-05,
      "loss": 1.644,
      "step": 21420
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.1675024032592773,
      "learning_rate": 1.56410545988877e-05,
      "loss": 1.6558,
      "step": 21430
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.4011054039001465,
      "learning_rate": 1.5601594914754126e-05,
      "loss": 1.6628,
      "step": 21440
    },
    {
      "epoch": 2.23,
      "grad_norm": 1.835410475730896,
      "learning_rate": 1.556217586513426e-05,
      "loss": 1.6498,
      "step": 21450
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.137761354446411,
      "learning_rate": 1.552279749659346e-05,
      "loss": 1.5887,
      "step": 21460
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.0121333599090576,
      "learning_rate": 1.548345985564903e-05,
      "loss": 1.7024,
      "step": 21470
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.261686086654663,
      "learning_rate": 1.5444162988770128e-05,
      "loss": 1.6347,
      "step": 21480
    },
    {
      "epoch": 2.23,
      "grad_norm": 1.8045576810836792,
      "learning_rate": 1.5404906942377817e-05,
      "loss": 1.6596,
      "step": 21490
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.2564189434051514,
      "learning_rate": 1.5365691762844875e-05,
      "loss": 1.6378,
      "step": 21500
    },
    {
      "epoch": 2.23,
      "eval_loss": 1.8106926679611206,
      "eval_runtime": 366.2586,
      "eval_samples_per_second": 23.388,
      "eval_steps_per_second": 23.388,
      "step": 21500
    },
    {
      "epoch": 2.23,
      "grad_norm": 1.6994878053665161,
      "learning_rate": 1.532651749649583e-05,
      "loss": 1.7012,
      "step": 21510
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.225602865219116,
      "learning_rate": 1.5287384189606873e-05,
      "loss": 1.6345,
      "step": 21520
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.565049648284912,
      "learning_rate": 1.5248291888405797e-05,
      "loss": 1.6881,
      "step": 21530
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.9957932233810425,
      "learning_rate": 1.520924063907201e-05,
      "loss": 1.8049,
      "step": 21540
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.9978973865509033,
      "learning_rate": 1.5170230487736358e-05,
      "loss": 1.5942,
      "step": 21550
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.3014450073242188,
      "learning_rate": 1.5131261480481162e-05,
      "loss": 1.6471,
      "step": 21560
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.9899615049362183,
      "learning_rate": 1.5092333663340175e-05,
      "loss": 1.7314,
      "step": 21570
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.311161994934082,
      "learning_rate": 1.5053447082298444e-05,
      "loss": 1.6689,
      "step": 21580
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.6832374334335327,
      "learning_rate": 1.5014601783292315e-05,
      "loss": 1.6059,
      "step": 21590
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.309607982635498,
      "learning_rate": 1.4975797812209397e-05,
      "loss": 1.7079,
      "step": 21600
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.02691650390625,
      "learning_rate": 1.4937035214888446e-05,
      "loss": 1.7312,
      "step": 21610
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.7398306131362915,
      "learning_rate": 1.4898314037119355e-05,
      "loss": 1.5206,
      "step": 21620
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.993775725364685,
      "learning_rate": 1.4859634324643074e-05,
      "loss": 1.7489,
      "step": 21630
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.718377113342285,
      "learning_rate": 1.4820996123151614e-05,
      "loss": 1.7561,
      "step": 21640
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.9832720756530762,
      "learning_rate": 1.4782399478287906e-05,
      "loss": 1.7336,
      "step": 21650
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.215174913406372,
      "learning_rate": 1.4743844435645792e-05,
      "loss": 1.6293,
      "step": 21660
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.8854987621307373,
      "learning_rate": 1.470533104077001e-05,
      "loss": 1.6305,
      "step": 21670
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.776933193206787,
      "learning_rate": 1.4666859339156064e-05,
      "loss": 1.6263,
      "step": 21680
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.1315011978149414,
      "learning_rate": 1.4628429376250202e-05,
      "loss": 1.6951,
      "step": 21690
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.0791430473327637,
      "learning_rate": 1.4590041197449378e-05,
      "loss": 1.7167,
      "step": 21700
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.6854817867279053,
      "learning_rate": 1.4551694848101205e-05,
      "loss": 1.7319,
      "step": 21710
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.385225772857666,
      "learning_rate": 1.4513390373503866e-05,
      "loss": 1.6939,
      "step": 21720
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.0631344318389893,
      "learning_rate": 1.4475127818906048e-05,
      "loss": 1.6858,
      "step": 21730
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.0157713890075684,
      "learning_rate": 1.443690722950699e-05,
      "loss": 1.6199,
      "step": 21740
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.9856317043304443,
      "learning_rate": 1.4398728650456295e-05,
      "loss": 1.63,
      "step": 21750
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.2782320976257324,
      "learning_rate": 1.4360592126853944e-05,
      "loss": 1.5927,
      "step": 21760
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.9000308513641357,
      "learning_rate": 1.4322497703750298e-05,
      "loss": 1.639,
      "step": 21770
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.1684727668762207,
      "learning_rate": 1.428444542614591e-05,
      "loss": 1.6215,
      "step": 21780
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.4843478202819824,
      "learning_rate": 1.4246435338991586e-05,
      "loss": 1.5877,
      "step": 21790
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.958471417427063,
      "learning_rate": 1.4208467487188277e-05,
      "loss": 1.5452,
      "step": 21800
    },
    {
      "epoch": 2.26,
      "grad_norm": 3.044224262237549,
      "learning_rate": 1.417054191558707e-05,
      "loss": 1.6165,
      "step": 21810
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.9734842777252197,
      "learning_rate": 1.4132658668989084e-05,
      "loss": 1.6513,
      "step": 21820
    },
    {
      "epoch": 2.27,
      "grad_norm": 2.2108495235443115,
      "learning_rate": 1.409481779214542e-05,
      "loss": 1.5958,
      "step": 21830
    },
    {
      "epoch": 2.27,
      "grad_norm": 2.2479212284088135,
      "learning_rate": 1.4057019329757182e-05,
      "loss": 1.6623,
      "step": 21840
    },
    {
      "epoch": 2.27,
      "grad_norm": 2.193195343017578,
      "learning_rate": 1.401926332647533e-05,
      "loss": 1.6597,
      "step": 21850
    },
    {
      "epoch": 2.27,
      "grad_norm": 1.9345952272415161,
      "learning_rate": 1.3981549826900654e-05,
      "loss": 1.7008,
      "step": 21860
    },
    {
      "epoch": 2.27,
      "grad_norm": 2.655914306640625,
      "learning_rate": 1.3943878875583794e-05,
      "loss": 1.765,
      "step": 21870
    },
    {
      "epoch": 2.27,
      "grad_norm": 2.704345226287842,
      "learning_rate": 1.3906250517025071e-05,
      "loss": 1.5759,
      "step": 21880
    },
    {
      "epoch": 2.27,
      "grad_norm": 2.1082229614257812,
      "learning_rate": 1.3868664795674519e-05,
      "loss": 1.7737,
      "step": 21890
    },
    {
      "epoch": 2.27,
      "grad_norm": 2.255974292755127,
      "learning_rate": 1.383112175593178e-05,
      "loss": 1.6869,
      "step": 21900
    },
    {
      "epoch": 2.27,
      "grad_norm": 1.935892105102539,
      "learning_rate": 1.3793621442146132e-05,
      "loss": 1.602,
      "step": 21910
    },
    {
      "epoch": 2.27,
      "grad_norm": 2.252326726913452,
      "learning_rate": 1.375616389861632e-05,
      "loss": 1.6599,
      "step": 21920
    },
    {
      "epoch": 2.28,
      "grad_norm": 2.402860641479492,
      "learning_rate": 1.3718749169590572e-05,
      "loss": 1.7116,
      "step": 21930
    },
    {
      "epoch": 2.28,
      "grad_norm": 1.6313769817352295,
      "learning_rate": 1.3681377299266601e-05,
      "loss": 1.6806,
      "step": 21940
    },
    {
      "epoch": 2.28,
      "grad_norm": 2.2680346965789795,
      "learning_rate": 1.364404833179142e-05,
      "loss": 1.6822,
      "step": 21950
    },
    {
      "epoch": 2.28,
      "grad_norm": 2.1708943843841553,
      "learning_rate": 1.3606762311261395e-05,
      "loss": 1.6325,
      "step": 21960
    },
    {
      "epoch": 2.28,
      "grad_norm": 2.026413679122925,
      "learning_rate": 1.3569519281722148e-05,
      "loss": 1.6799,
      "step": 21970
    },
    {
      "epoch": 2.28,
      "grad_norm": 2.0695810317993164,
      "learning_rate": 1.353231928716851e-05,
      "loss": 1.6583,
      "step": 21980
    },
    {
      "epoch": 2.28,
      "grad_norm": 1.719884991645813,
      "learning_rate": 1.3495162371544513e-05,
      "loss": 1.5851,
      "step": 21990
    },
    {
      "epoch": 2.28,
      "grad_norm": 2.2338125705718994,
      "learning_rate": 1.3458048578743259e-05,
      "loss": 1.6624,
      "step": 22000
    },
    {
      "epoch": 2.28,
      "eval_loss": 1.8100756406784058,
      "eval_runtime": 366.2987,
      "eval_samples_per_second": 23.385,
      "eval_steps_per_second": 23.385,
      "step": 22000
    },
    {
      "epoch": 2.28,
      "grad_norm": 1.9378795623779297,
      "learning_rate": 1.3420977952606928e-05,
      "loss": 1.7396,
      "step": 22010
    },
    {
      "epoch": 2.29,
      "grad_norm": 1.9252735376358032,
      "learning_rate": 1.3383950536926681e-05,
      "loss": 1.609,
      "step": 22020
    },
    {
      "epoch": 2.29,
      "grad_norm": Infinity,
      "learning_rate": 1.3350662843906737e-05,
      "loss": 1.6905,
      "step": 22030
    },
    {
      "epoch": 2.29,
      "grad_norm": 3.349489688873291,
      "learning_rate": 1.3313717648554941e-05,
      "loss": 1.7813,
      "step": 22040
    },
    {
      "epoch": 2.29,
      "grad_norm": 2.1088995933532715,
      "learning_rate": 1.3276815790364855e-05,
      "loss": 1.6437,
      "step": 22050
    },
    {
      "epoch": 2.29,
      "grad_norm": 2.3395206928253174,
      "learning_rate": 1.3239957312928287e-05,
      "loss": 1.8001,
      "step": 22060
    },
    {
      "epoch": 2.29,
      "grad_norm": 2.2846102714538574,
      "learning_rate": 1.3203142259785805e-05,
      "loss": 1.7035,
      "step": 22070
    },
    {
      "epoch": 2.29,
      "grad_norm": 2.0812740325927734,
      "learning_rate": 1.3166370674426682e-05,
      "loss": 1.7612,
      "step": 22080
    },
    {
      "epoch": 2.29,
      "grad_norm": 2.153064012527466,
      "learning_rate": 1.312964260028886e-05,
      "loss": 1.6001,
      "step": 22090
    },
    {
      "epoch": 2.29,
      "grad_norm": 1.991883397102356,
      "learning_rate": 1.309295808075887e-05,
      "loss": 1.5945,
      "step": 22100
    },
    {
      "epoch": 2.29,
      "grad_norm": 2.0276575088500977,
      "learning_rate": 1.3056317159171765e-05,
      "loss": 1.6774,
      "step": 22110
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.9097543954849243,
      "learning_rate": 1.3019719878811166e-05,
      "loss": 1.7446,
      "step": 22120
    },
    {
      "epoch": 2.3,
      "grad_norm": 2.2757132053375244,
      "learning_rate": 1.2983166282909065e-05,
      "loss": 1.652,
      "step": 22130
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.8896809816360474,
      "learning_rate": 1.2946656414645896e-05,
      "loss": 1.726,
      "step": 22140
    },
    {
      "epoch": 2.3,
      "grad_norm": 2.0430893898010254,
      "learning_rate": 1.2910190317150406e-05,
      "loss": 1.717,
      "step": 22150
    },
    {
      "epoch": 2.3,
      "grad_norm": 2.0143308639526367,
      "learning_rate": 1.2873768033499683e-05,
      "loss": 1.6957,
      "step": 22160
    },
    {
      "epoch": 2.3,
      "grad_norm": 2.4307126998901367,
      "learning_rate": 1.2837389606719014e-05,
      "loss": 1.6556,
      "step": 22170
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.7926594018936157,
      "learning_rate": 1.2801055079781876e-05,
      "loss": 1.704,
      "step": 22180
    },
    {
      "epoch": 2.3,
      "grad_norm": 2.2056024074554443,
      "learning_rate": 1.2764764495609943e-05,
      "loss": 1.6305,
      "step": 22190
    },
    {
      "epoch": 2.3,
      "grad_norm": 2.01977801322937,
      "learning_rate": 1.2728517897072923e-05,
      "loss": 1.7071,
      "step": 22200
    },
    {
      "epoch": 2.3,
      "grad_norm": 2.073422431945801,
      "learning_rate": 1.2692315326988568e-05,
      "loss": 1.6733,
      "step": 22210
    },
    {
      "epoch": 2.31,
      "grad_norm": 2.787848711013794,
      "learning_rate": 1.2656156828122661e-05,
      "loss": 1.5898,
      "step": 22220
    },
    {
      "epoch": 2.31,
      "grad_norm": 1.806898593902588,
      "learning_rate": 1.2620042443188894e-05,
      "loss": 1.4876,
      "step": 22230
    },
    {
      "epoch": 2.31,
      "grad_norm": 2.2487497329711914,
      "learning_rate": 1.2583972214848838e-05,
      "loss": 1.5547,
      "step": 22240
    },
    {
      "epoch": 2.31,
      "grad_norm": 2.313263177871704,
      "learning_rate": 1.2547946185711912e-05,
      "loss": 1.7034,
      "step": 22250
    },
    {
      "epoch": 2.31,
      "grad_norm": 2.384561538696289,
      "learning_rate": 1.2511964398335353e-05,
      "loss": 1.749,
      "step": 22260
    },
    {
      "epoch": 2.31,
      "grad_norm": 1.9780634641647339,
      "learning_rate": 1.247602689522409e-05,
      "loss": 1.7291,
      "step": 22270
    },
    {
      "epoch": 2.31,
      "grad_norm": 2.0536580085754395,
      "learning_rate": 1.2440133718830755e-05,
      "loss": 1.731,
      "step": 22280
    },
    {
      "epoch": 2.31,
      "grad_norm": 2.0390632152557373,
      "learning_rate": 1.2404284911555637e-05,
      "loss": 1.6779,
      "step": 22290
    },
    {
      "epoch": 2.31,
      "grad_norm": 2.1376826763153076,
      "learning_rate": 1.2368480515746588e-05,
      "loss": 1.5601,
      "step": 22300
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.1888363361358643,
      "learning_rate": 1.2332720573698998e-05,
      "loss": 1.6641,
      "step": 22310
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.8983417749404907,
      "learning_rate": 1.2297005127655764e-05,
      "loss": 1.6354,
      "step": 22320
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.23266863822937,
      "learning_rate": 1.2261334219807208e-05,
      "loss": 1.8762,
      "step": 22330
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.9419821500778198,
      "learning_rate": 1.2225707892291034e-05,
      "loss": 1.5662,
      "step": 22340
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.087331771850586,
      "learning_rate": 1.2190126187192274e-05,
      "loss": 1.6213,
      "step": 22350
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.56945538520813,
      "learning_rate": 1.2154589146543294e-05,
      "loss": 1.5596,
      "step": 22360
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.505795955657959,
      "learning_rate": 1.211909681232365e-05,
      "loss": 1.6466,
      "step": 22370
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.1562793254852295,
      "learning_rate": 1.2083649226460103e-05,
      "loss": 1.6049,
      "step": 22380
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.9464999437332153,
      "learning_rate": 1.2048246430826543e-05,
      "loss": 1.5672,
      "step": 22390
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.0526771545410156,
      "learning_rate": 1.2012888467243987e-05,
      "loss": 1.6112,
      "step": 22400
    },
    {
      "epoch": 2.33,
      "grad_norm": 2.423037052154541,
      "learning_rate": 1.197757537748046e-05,
      "loss": 1.688,
      "step": 22410
    },
    {
      "epoch": 2.33,
      "grad_norm": 2.2421927452087402,
      "learning_rate": 1.1942307203250968e-05,
      "loss": 1.5428,
      "step": 22420
    },
    {
      "epoch": 2.33,
      "grad_norm": 2.274214267730713,
      "learning_rate": 1.1907083986217476e-05,
      "loss": 1.7224,
      "step": 22430
    },
    {
      "epoch": 2.33,
      "grad_norm": 2.2111003398895264,
      "learning_rate": 1.1871905767988862e-05,
      "loss": 1.6989,
      "step": 22440
    },
    {
      "epoch": 2.33,
      "grad_norm": 2.104255437850952,
      "learning_rate": 1.1836772590120815e-05,
      "loss": 1.7252,
      "step": 22450
    },
    {
      "epoch": 2.33,
      "grad_norm": 2.144078016281128,
      "learning_rate": 1.1801684494115821e-05,
      "loss": 1.6685,
      "step": 22460
    },
    {
      "epoch": 2.33,
      "grad_norm": 1.904774785041809,
      "learning_rate": 1.1766641521423127e-05,
      "loss": 1.6771,
      "step": 22470
    },
    {
      "epoch": 2.33,
      "grad_norm": 2.1819891929626465,
      "learning_rate": 1.1731643713438656e-05,
      "loss": 1.5825,
      "step": 22480
    },
    {
      "epoch": 2.33,
      "grad_norm": 2.393366575241089,
      "learning_rate": 1.169669111150501e-05,
      "loss": 1.6754,
      "step": 22490
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.2675530910491943,
      "learning_rate": 1.166178375691136e-05,
      "loss": 1.6366,
      "step": 22500
    },
    {
      "epoch": 2.34,
      "eval_loss": 1.8092089891433716,
      "eval_runtime": 366.5757,
      "eval_samples_per_second": 23.368,
      "eval_steps_per_second": 23.368,
      "step": 22500
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.140343189239502,
      "learning_rate": 1.162692169089344e-05,
      "loss": 1.6895,
      "step": 22510
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.011730909347534,
      "learning_rate": 1.1592104954633465e-05,
      "loss": 1.7273,
      "step": 22520
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.896247148513794,
      "learning_rate": 1.1557333589260144e-05,
      "loss": 1.6648,
      "step": 22530
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.293984889984131,
      "learning_rate": 1.1522607635848565e-05,
      "loss": 1.6828,
      "step": 22540
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.065916061401367,
      "learning_rate": 1.148792713542014e-05,
      "loss": 1.6347,
      "step": 22550
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.0788140296936035,
      "learning_rate": 1.1453292128942656e-05,
      "loss": 1.547,
      "step": 22560
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.148500680923462,
      "learning_rate": 1.141870265733011e-05,
      "loss": 1.6013,
      "step": 22570
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.274247884750366,
      "learning_rate": 1.1384158761442704e-05,
      "loss": 1.7741,
      "step": 22580
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.0580668449401855,
      "learning_rate": 1.1349660482086843e-05,
      "loss": 1.7024,
      "step": 22590
    },
    {
      "epoch": 2.35,
      "grad_norm": 2.15765380859375,
      "learning_rate": 1.1315207860015015e-05,
      "loss": 1.6604,
      "step": 22600
    },
    {
      "epoch": 2.35,
      "grad_norm": 2.464986801147461,
      "learning_rate": 1.1280800935925772e-05,
      "loss": 1.7812,
      "step": 22610
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.9510339498519897,
      "learning_rate": 1.1246439750463683e-05,
      "loss": 1.7325,
      "step": 22620
    },
    {
      "epoch": 2.35,
      "grad_norm": 2.0466928482055664,
      "learning_rate": 1.1212124344219315e-05,
      "loss": 1.6617,
      "step": 22630
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.987909197807312,
      "learning_rate": 1.1177854757729133e-05,
      "loss": 1.5946,
      "step": 22640
    },
    {
      "epoch": 2.35,
      "grad_norm": 2.050917863845825,
      "learning_rate": 1.114363103147546e-05,
      "loss": 1.6364,
      "step": 22650
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.8225693702697754,
      "learning_rate": 1.1109453205886483e-05,
      "loss": 1.682,
      "step": 22660
    },
    {
      "epoch": 2.35,
      "grad_norm": 2.746814012527466,
      "learning_rate": 1.1075321321336141e-05,
      "loss": 1.6782,
      "step": 22670
    },
    {
      "epoch": 2.35,
      "grad_norm": 2.1968166828155518,
      "learning_rate": 1.1041235418144114e-05,
      "loss": 1.6242,
      "step": 22680
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.7946821451187134,
      "learning_rate": 1.1007195536575738e-05,
      "loss": 1.5517,
      "step": 22690
    },
    {
      "epoch": 2.36,
      "grad_norm": 2.1551361083984375,
      "learning_rate": 1.0973201716842035e-05,
      "loss": 1.672,
      "step": 22700
    },
    {
      "epoch": 2.36,
      "grad_norm": 2.5206375122070312,
      "learning_rate": 1.0939253999099575e-05,
      "loss": 1.4844,
      "step": 22710
    },
    {
      "epoch": 2.36,
      "grad_norm": 2.310344934463501,
      "learning_rate": 1.090535242345046e-05,
      "loss": 1.7055,
      "step": 22720
    },
    {
      "epoch": 2.36,
      "grad_norm": 1.907455325126648,
      "learning_rate": 1.087149702994234e-05,
      "loss": 1.6509,
      "step": 22730
    },
    {
      "epoch": 2.36,
      "grad_norm": 1.8148751258850098,
      "learning_rate": 1.0837687858568258e-05,
      "loss": 1.6085,
      "step": 22740
    },
    {
      "epoch": 2.36,
      "grad_norm": 2.160767078399658,
      "learning_rate": 1.0803924949266647e-05,
      "loss": 1.5141,
      "step": 22750
    },
    {
      "epoch": 2.36,
      "grad_norm": 2.025810718536377,
      "learning_rate": 1.0770208341921357e-05,
      "loss": 1.7071,
      "step": 22760
    },
    {
      "epoch": 2.36,
      "grad_norm": 2.022355556488037,
      "learning_rate": 1.0736538076361479e-05,
      "loss": 1.6967,
      "step": 22770
    },
    {
      "epoch": 2.36,
      "grad_norm": 2.1520445346832275,
      "learning_rate": 1.0702914192361391e-05,
      "loss": 1.5397,
      "step": 22780
    },
    {
      "epoch": 2.37,
      "grad_norm": 1.9464645385742188,
      "learning_rate": 1.0669336729640645e-05,
      "loss": 1.5681,
      "step": 22790
    },
    {
      "epoch": 2.37,
      "grad_norm": 2.035560369491577,
      "learning_rate": 1.0635805727864019e-05,
      "loss": 1.7285,
      "step": 22800
    },
    {
      "epoch": 2.37,
      "grad_norm": 2.0322890281677246,
      "learning_rate": 1.0602321226641354e-05,
      "loss": 1.7217,
      "step": 22810
    },
    {
      "epoch": 2.37,
      "grad_norm": 2.144758462905884,
      "learning_rate": 1.0568883265527568e-05,
      "loss": 1.5968,
      "step": 22820
    },
    {
      "epoch": 2.37,
      "grad_norm": 1.9253326654434204,
      "learning_rate": 1.0535491884022635e-05,
      "loss": 1.605,
      "step": 22830
    },
    {
      "epoch": 2.37,
      "grad_norm": 2.168569326400757,
      "learning_rate": 1.050214712157147e-05,
      "loss": 1.7332,
      "step": 22840
    },
    {
      "epoch": 2.37,
      "grad_norm": 2.238739252090454,
      "learning_rate": 1.0468849017563914e-05,
      "loss": 1.6952,
      "step": 22850
    },
    {
      "epoch": 2.37,
      "grad_norm": 2.402153253555298,
      "learning_rate": 1.0435597611334736e-05,
      "loss": 1.6868,
      "step": 22860
    },
    {
      "epoch": 2.37,
      "grad_norm": 2.4529545307159424,
      "learning_rate": 1.040239294216349e-05,
      "loss": 1.75,
      "step": 22870
    },
    {
      "epoch": 2.37,
      "grad_norm": 2.354480743408203,
      "learning_rate": 1.0369235049274546e-05,
      "loss": 1.6435,
      "step": 22880
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.5528817176818848,
      "learning_rate": 1.0336123971836998e-05,
      "loss": 1.7805,
      "step": 22890
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.691324234008789,
      "learning_rate": 1.0303059748964671e-05,
      "loss": 1.6213,
      "step": 22900
    },
    {
      "epoch": 2.38,
      "grad_norm": 1.9373353719711304,
      "learning_rate": 1.0270042419716025e-05,
      "loss": 1.6004,
      "step": 22910
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.3942084312438965,
      "learning_rate": 1.0237072023094107e-05,
      "loss": 1.7457,
      "step": 22920
    },
    {
      "epoch": 2.38,
      "grad_norm": 1.8791247606277466,
      "learning_rate": 1.0204148598046526e-05,
      "loss": 1.5986,
      "step": 22930
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.0256567001342773,
      "learning_rate": 1.0171272183465453e-05,
      "loss": 1.6936,
      "step": 22940
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.0812971591949463,
      "learning_rate": 1.013844281818746e-05,
      "loss": 1.5745,
      "step": 22950
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.365061044692993,
      "learning_rate": 1.0105660540993578e-05,
      "loss": 1.6951,
      "step": 22960
    },
    {
      "epoch": 2.38,
      "grad_norm": 1.8646081686019897,
      "learning_rate": 1.0072925390609206e-05,
      "loss": 1.6192,
      "step": 22970
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.3649721145629883,
      "learning_rate": 1.004023740570405e-05,
      "loss": 1.5361,
      "step": 22980
    },
    {
      "epoch": 2.39,
      "grad_norm": 1.9846277236938477,
      "learning_rate": 1.0007596624892151e-05,
      "loss": 1.7855,
      "step": 22990
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.0751001834869385,
      "learning_rate": 9.975003086731749e-06,
      "loss": 1.5974,
      "step": 23000
    },
    {
      "epoch": 2.39,
      "eval_loss": 1.8095136880874634,
      "eval_runtime": 366.6685,
      "eval_samples_per_second": 23.362,
      "eval_steps_per_second": 23.362,
      "step": 23000
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.139411211013794,
      "learning_rate": 9.942456829725272e-06,
      "loss": 1.643,
      "step": 23010
    },
    {
      "epoch": 2.39,
      "grad_norm": 1.904515266418457,
      "learning_rate": 9.90995789231931e-06,
      "loss": 1.5246,
      "step": 23020
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.0609426498413086,
      "learning_rate": 9.877506312904572e-06,
      "loss": 1.6488,
      "step": 23030
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.246943712234497,
      "learning_rate": 9.845102129815787e-06,
      "loss": 1.7597,
      "step": 23040
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.1012485027313232,
      "learning_rate": 9.812745381331722e-06,
      "loss": 1.6471,
      "step": 23050
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.332838773727417,
      "learning_rate": 9.780436105675089e-06,
      "loss": 1.6107,
      "step": 23060
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.2103922367095947,
      "learning_rate": 9.74817434101255e-06,
      "loss": 1.7487,
      "step": 23070
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.1183316707611084,
      "learning_rate": 9.715960125454621e-06,
      "loss": 1.5648,
      "step": 23080
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.1342875957489014,
      "learning_rate": 9.683793497055631e-06,
      "loss": 1.7782,
      "step": 23090
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.1140620708465576,
      "learning_rate": 9.65167449381375e-06,
      "loss": 1.683,
      "step": 23100
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.1704511642456055,
      "learning_rate": 9.619603153670842e-06,
      "loss": 1.6672,
      "step": 23110
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.8891563415527344,
      "learning_rate": 9.587579514512463e-06,
      "loss": 1.6764,
      "step": 23120
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.3974151611328125,
      "learning_rate": 9.555603614167868e-06,
      "loss": 1.5923,
      "step": 23130
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.9512426853179932,
      "learning_rate": 9.523675490409872e-06,
      "loss": 1.7119,
      "step": 23140
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.3068156242370605,
      "learning_rate": 9.491795180954871e-06,
      "loss": 1.6369,
      "step": 23150
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.5483007431030273,
      "learning_rate": 9.459962723462767e-06,
      "loss": 1.6199,
      "step": 23160
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.0341153144836426,
      "learning_rate": 9.428178155536966e-06,
      "loss": 1.6251,
      "step": 23170
    },
    {
      "epoch": 2.41,
      "grad_norm": 2.542752742767334,
      "learning_rate": 9.396441514724264e-06,
      "loss": 1.6962,
      "step": 23180
    },
    {
      "epoch": 2.41,
      "grad_norm": 1.9875249862670898,
      "learning_rate": 9.364752838514851e-06,
      "loss": 1.7093,
      "step": 23190
    },
    {
      "epoch": 2.41,
      "grad_norm": 2.2083816528320312,
      "learning_rate": 9.333112164342284e-06,
      "loss": 1.7736,
      "step": 23200
    },
    {
      "epoch": 2.41,
      "grad_norm": 2.367635726928711,
      "learning_rate": 9.30151952958338e-06,
      "loss": 1.5411,
      "step": 23210
    },
    {
      "epoch": 2.41,
      "grad_norm": 2.0017919540405273,
      "learning_rate": 9.269974971558232e-06,
      "loss": 1.6865,
      "step": 23220
    },
    {
      "epoch": 2.41,
      "grad_norm": 2.5804622173309326,
      "learning_rate": 9.238478527530115e-06,
      "loss": 1.6319,
      "step": 23230
    },
    {
      "epoch": 2.41,
      "grad_norm": 2.117703914642334,
      "learning_rate": 9.2070302347055e-06,
      "loss": 1.6471,
      "step": 23240
    },
    {
      "epoch": 2.41,
      "grad_norm": 2.4781734943389893,
      "learning_rate": 9.17563013023396e-06,
      "loss": 1.6763,
      "step": 23250
    },
    {
      "epoch": 2.41,
      "grad_norm": 2.132943868637085,
      "learning_rate": 9.144278251208122e-06,
      "loss": 1.7724,
      "step": 23260
    },
    {
      "epoch": 2.41,
      "grad_norm": 1.9925588369369507,
      "learning_rate": 9.112974634663696e-06,
      "loss": 1.567,
      "step": 23270
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.228208303451538,
      "learning_rate": 9.081719317579345e-06,
      "loss": 1.613,
      "step": 23280
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.0098953247070312,
      "learning_rate": 9.05051233687666e-06,
      "loss": 1.731,
      "step": 23290
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.2264482975006104,
      "learning_rate": 9.019353729420183e-06,
      "loss": 1.6726,
      "step": 23300
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.225882053375244,
      "learning_rate": 8.988243532017272e-06,
      "loss": 1.6943,
      "step": 23310
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.2505786418914795,
      "learning_rate": 8.957181781418117e-06,
      "loss": 1.7216,
      "step": 23320
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.37277889251709,
      "learning_rate": 8.926168514315653e-06,
      "loss": 1.596,
      "step": 23330
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.4443247318267822,
      "learning_rate": 8.89520376734559e-06,
      "loss": 1.7035,
      "step": 23340
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.2665810585021973,
      "learning_rate": 8.864287577086283e-06,
      "loss": 1.6732,
      "step": 23350
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.125474452972412,
      "learning_rate": 8.83341998005872e-06,
      "loss": 1.7215,
      "step": 23360
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.2370047569274902,
      "learning_rate": 8.802601012726542e-06,
      "loss": 1.7541,
      "step": 23370
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.4935803413391113,
      "learning_rate": 8.771830711495882e-06,
      "loss": 1.619,
      "step": 23380
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.019491672515869,
      "learning_rate": 8.741109112715396e-06,
      "loss": 1.5953,
      "step": 23390
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.222581624984741,
      "learning_rate": 8.710436252676251e-06,
      "loss": 1.5829,
      "step": 23400
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.033332586288452,
      "learning_rate": 8.679812167611995e-06,
      "loss": 1.6942,
      "step": 23410
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.1542210578918457,
      "learning_rate": 8.649236893698571e-06,
      "loss": 1.7923,
      "step": 23420
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.180952787399292,
      "learning_rate": 8.618710467054253e-06,
      "loss": 1.7219,
      "step": 23430
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.35410737991333,
      "learning_rate": 8.588232923739647e-06,
      "loss": 1.7447,
      "step": 23440
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.215064287185669,
      "learning_rate": 8.557804299757583e-06,
      "loss": 1.6624,
      "step": 23450
    },
    {
      "epoch": 2.43,
      "grad_norm": 2.0739474296569824,
      "learning_rate": 8.5274246310531e-06,
      "loss": 1.5831,
      "step": 23460
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.443742513656616,
      "learning_rate": 8.497093953513408e-06,
      "loss": 1.7913,
      "step": 23470
    },
    {
      "epoch": 2.44,
      "grad_norm": 1.7847580909729004,
      "learning_rate": 8.466812302967874e-06,
      "loss": 1.6696,
      "step": 23480
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.1710681915283203,
      "learning_rate": 8.436579715187926e-06,
      "loss": 1.7167,
      "step": 23490
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.617619514465332,
      "learning_rate": 8.40639622588702e-06,
      "loss": 1.6343,
      "step": 23500
    },
    {
      "epoch": 2.44,
      "eval_loss": 1.8081032037734985,
      "eval_runtime": 366.4424,
      "eval_samples_per_second": 23.376,
      "eval_steps_per_second": 23.376,
      "step": 23500
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.79015851020813,
      "learning_rate": 8.376261870720647e-06,
      "loss": 1.5403,
      "step": 23510
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.08353853225708,
      "learning_rate": 8.346176685286211e-06,
      "loss": 1.7195,
      "step": 23520
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.3451263904571533,
      "learning_rate": 8.316140705123093e-06,
      "loss": 1.6529,
      "step": 23530
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.2634856700897217,
      "learning_rate": 8.286153965712506e-06,
      "loss": 1.7555,
      "step": 23540
    },
    {
      "epoch": 2.44,
      "grad_norm": 1.869768738746643,
      "learning_rate": 8.256216502477493e-06,
      "loss": 1.5544,
      "step": 23550
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.4004099369049072,
      "learning_rate": 8.226328350782897e-06,
      "loss": 1.6259,
      "step": 23560
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.0007331371307373,
      "learning_rate": 8.196489545935327e-06,
      "loss": 1.5301,
      "step": 23570
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.0010182857513428,
      "learning_rate": 8.16670012318308e-06,
      "loss": 1.663,
      "step": 23580
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.213376998901367,
      "learning_rate": 8.136960117716113e-06,
      "loss": 1.7007,
      "step": 23590
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.3966095447540283,
      "learning_rate": 8.107269564666015e-06,
      "loss": 1.6332,
      "step": 23600
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.3722105026245117,
      "learning_rate": 8.077628499105977e-06,
      "loss": 1.711,
      "step": 23610
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.582570791244507,
      "learning_rate": 8.048036956050697e-06,
      "loss": 1.7954,
      "step": 23620
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.3168203830718994,
      "learning_rate": 8.018494970456374e-06,
      "loss": 1.6535,
      "step": 23630
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.3083863258361816,
      "learning_rate": 7.989002577220717e-06,
      "loss": 1.7051,
      "step": 23640
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.390695571899414,
      "learning_rate": 7.959559811182781e-06,
      "loss": 1.6984,
      "step": 23650
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.277005195617676,
      "learning_rate": 7.930166707123038e-06,
      "loss": 1.7101,
      "step": 23660
    },
    {
      "epoch": 2.46,
      "grad_norm": 1.8407412767410278,
      "learning_rate": 7.900823299763293e-06,
      "loss": 1.6519,
      "step": 23670
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.9232637882232666,
      "learning_rate": 7.871529623766643e-06,
      "loss": 1.6827,
      "step": 23680
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.3254663944244385,
      "learning_rate": 7.842285713737419e-06,
      "loss": 1.6991,
      "step": 23690
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.540093183517456,
      "learning_rate": 7.813091604221173e-06,
      "loss": 1.5288,
      "step": 23700
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.265110969543457,
      "learning_rate": 7.783947329704655e-06,
      "loss": 1.5721,
      "step": 23710
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.0118792057037354,
      "learning_rate": 7.754852924615708e-06,
      "loss": 1.7106,
      "step": 23720
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.2288055419921875,
      "learning_rate": 7.725808423323277e-06,
      "loss": 1.6225,
      "step": 23730
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.6116342544555664,
      "learning_rate": 7.696813860137375e-06,
      "loss": 1.5079,
      "step": 23740
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.3405773639678955,
      "learning_rate": 7.667869269309003e-06,
      "loss": 1.6295,
      "step": 23750
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.07440185546875,
      "learning_rate": 7.638974685030132e-06,
      "loss": 1.7175,
      "step": 23760
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.761955976486206,
      "learning_rate": 7.610130141433647e-06,
      "loss": 1.6809,
      "step": 23770
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.3351995944976807,
      "learning_rate": 7.581335672593371e-06,
      "loss": 1.6229,
      "step": 23780
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.3266923427581787,
      "learning_rate": 7.5525913125239154e-06,
      "loss": 1.6069,
      "step": 23790
    },
    {
      "epoch": 2.47,
      "grad_norm": 1.7029705047607422,
      "learning_rate": 7.523897095180721e-06,
      "loss": 1.6892,
      "step": 23800
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.4788591861724854,
      "learning_rate": 7.495253054460022e-06,
      "loss": 1.6391,
      "step": 23810
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.258401393890381,
      "learning_rate": 7.466659224198741e-06,
      "loss": 1.5658,
      "step": 23820
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.1933774948120117,
      "learning_rate": 7.438115638174492e-06,
      "loss": 1.7256,
      "step": 23830
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.419090986251831,
      "learning_rate": 7.4096223301055645e-06,
      "loss": 1.6172,
      "step": 23840
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.3875033855438232,
      "learning_rate": 7.381179333650828e-06,
      "loss": 1.7528,
      "step": 23850
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.2390494346618652,
      "learning_rate": 7.352786682409723e-06,
      "loss": 1.625,
      "step": 23860
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.119025707244873,
      "learning_rate": 7.324444409922221e-06,
      "loss": 1.689,
      "step": 23870
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.207566022872925,
      "learning_rate": 7.2961525496688e-06,
      "loss": 1.6239,
      "step": 23880
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.2501370906829834,
      "learning_rate": 7.26791113507036e-06,
      "loss": 1.5862,
      "step": 23890
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.2198519706726074,
      "learning_rate": 7.239720199488204e-06,
      "loss": 1.7284,
      "step": 23900
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.8444048166275024,
      "learning_rate": 7.211579776224042e-06,
      "loss": 1.618,
      "step": 23910
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.9931601285934448,
      "learning_rate": 7.1834898985198905e-06,
      "loss": 1.6354,
      "step": 23920
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.032456874847412,
      "learning_rate": 7.155450599558039e-06,
      "loss": 1.672,
      "step": 23930
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.1787571907043457,
      "learning_rate": 7.1274619124610695e-06,
      "loss": 1.6856,
      "step": 23940
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.091167449951172,
      "learning_rate": 7.099523870291758e-06,
      "loss": 1.5584,
      "step": 23950
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.2856948375701904,
      "learning_rate": 7.071636506053036e-06,
      "loss": 1.6688,
      "step": 23960
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.045889139175415,
      "learning_rate": 7.043799852687982e-06,
      "loss": 1.6243,
      "step": 23970
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.466381788253784,
      "learning_rate": 7.016013943079797e-06,
      "loss": 1.664,
      "step": 23980
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.273704767227173,
      "learning_rate": 6.988278810051702e-06,
      "loss": 1.92,
      "step": 23990
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.362574338912964,
      "learning_rate": 6.960594486366956e-06,
      "loss": 1.6166,
      "step": 24000
    },
    {
      "epoch": 2.49,
      "eval_loss": 1.8084111213684082,
      "eval_runtime": 366.5006,
      "eval_samples_per_second": 23.372,
      "eval_steps_per_second": 23.372,
      "step": 24000
    },
    {
      "epoch": 2.49,
      "grad_norm": 1.9173510074615479,
      "learning_rate": 6.932961004728772e-06,
      "loss": 1.5779,
      "step": 24010
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.060224771499634,
      "learning_rate": 6.905378397780349e-06,
      "loss": 1.6895,
      "step": 24020
    },
    {
      "epoch": 2.49,
      "grad_norm": 1.9594894647598267,
      "learning_rate": 6.877846698104745e-06,
      "loss": 1.7376,
      "step": 24030
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.166302442550659,
      "learning_rate": 6.850365938224912e-06,
      "loss": 1.6872,
      "step": 24040
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.000756025314331,
      "learning_rate": 6.822936150603604e-06,
      "loss": 1.6484,
      "step": 24050
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.439765453338623,
      "learning_rate": 6.795557367643363e-06,
      "loss": 1.6857,
      "step": 24060
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.1090502738952637,
      "learning_rate": 6.770960098696544e-06,
      "loss": 1.6833,
      "step": 24070
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.3296210765838623,
      "learning_rate": 6.743678313645558e-06,
      "loss": 1.6294,
      "step": 24080
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.9586832523345947,
      "learning_rate": 6.7164476268822055e-06,
      "loss": 1.6873,
      "step": 24090
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.312877655029297,
      "learning_rate": 6.6892680705738285e-06,
      "loss": 1.6938,
      "step": 24100
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.0829153060913086,
      "learning_rate": 6.662139676827372e-06,
      "loss": 1.7739,
      "step": 24110
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.059680223464966,
      "learning_rate": 6.635062477689369e-06,
      "loss": 1.6167,
      "step": 24120
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.8220824003219604,
      "learning_rate": 6.608036505145859e-06,
      "loss": 1.6882,
      "step": 24130
    },
    {
      "epoch": 2.51,
      "grad_norm": 1.9815696477890015,
      "learning_rate": 6.581061791122362e-06,
      "loss": 1.63,
      "step": 24140
    },
    {
      "epoch": 2.51,
      "grad_norm": 2.044353723526001,
      "learning_rate": 6.554138367483853e-06,
      "loss": 1.5585,
      "step": 24150
    },
    {
      "epoch": 2.51,
      "grad_norm": 2.558394193649292,
      "learning_rate": 6.527266266034731e-06,
      "loss": 1.6923,
      "step": 24160
    },
    {
      "epoch": 2.51,
      "grad_norm": 2.2753281593322754,
      "learning_rate": 6.500445518518755e-06,
      "loss": 1.6368,
      "step": 24170
    },
    {
      "epoch": 2.51,
      "grad_norm": 2.223710298538208,
      "learning_rate": 6.473676156619013e-06,
      "loss": 1.7251,
      "step": 24180
    },
    {
      "epoch": 2.51,
      "grad_norm": 2.101153612136841,
      "learning_rate": 6.446958211957921e-06,
      "loss": 1.6222,
      "step": 24190
    },
    {
      "epoch": 2.51,
      "grad_norm": 2.045614719390869,
      "learning_rate": 6.420291716097121e-06,
      "loss": 1.5556,
      "step": 24200
    },
    {
      "epoch": 2.51,
      "grad_norm": 2.0965781211853027,
      "learning_rate": 6.393676700537498e-06,
      "loss": 1.7057,
      "step": 24210
    },
    {
      "epoch": 2.51,
      "grad_norm": 1.9219740629196167,
      "learning_rate": 6.367113196719115e-06,
      "loss": 1.6577,
      "step": 24220
    },
    {
      "epoch": 2.51,
      "grad_norm": 1.810388207435608,
      "learning_rate": 6.340601236021204e-06,
      "loss": 1.599,
      "step": 24230
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.1188740730285645,
      "learning_rate": 6.3141408497620905e-06,
      "loss": 1.6542,
      "step": 24240
    },
    {
      "epoch": 2.52,
      "grad_norm": 1.9470288753509521,
      "learning_rate": 6.287732069199165e-06,
      "loss": 1.7819,
      "step": 24250
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.2860171794891357,
      "learning_rate": 6.261374925528901e-06,
      "loss": 1.7243,
      "step": 24260
    },
    {
      "epoch": 2.52,
      "grad_norm": 1.9698411226272583,
      "learning_rate": 6.235069449886727e-06,
      "loss": 1.6632,
      "step": 24270
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.539912462234497,
      "learning_rate": 6.208815673347052e-06,
      "loss": 1.6994,
      "step": 24280
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.082479953765869,
      "learning_rate": 6.182613626923229e-06,
      "loss": 1.7177,
      "step": 24290
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.1582045555114746,
      "learning_rate": 6.156463341567487e-06,
      "loss": 1.6608,
      "step": 24300
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.036170721054077,
      "learning_rate": 6.130364848170911e-06,
      "loss": 1.5768,
      "step": 24310
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.2667946815490723,
      "learning_rate": 6.104318177563395e-06,
      "loss": 1.5989,
      "step": 24320
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.0986833572387695,
      "learning_rate": 6.078323360513649e-06,
      "loss": 1.7084,
      "step": 24330
    },
    {
      "epoch": 2.53,
      "grad_norm": 2.052166223526001,
      "learning_rate": 6.052380427729093e-06,
      "loss": 1.5947,
      "step": 24340
    },
    {
      "epoch": 2.53,
      "grad_norm": 2.4175827503204346,
      "learning_rate": 6.026489409855867e-06,
      "loss": 1.7186,
      "step": 24350
    },
    {
      "epoch": 2.53,
      "grad_norm": 2.2597897052764893,
      "learning_rate": 6.000650337478803e-06,
      "loss": 1.6196,
      "step": 24360
    },
    {
      "epoch": 2.53,
      "grad_norm": 1.7499979734420776,
      "learning_rate": 5.974863241121348e-06,
      "loss": 1.6755,
      "step": 24370
    },
    {
      "epoch": 2.53,
      "grad_norm": 2.238988161087036,
      "learning_rate": 5.949128151245542e-06,
      "loss": 1.5659,
      "step": 24380
    },
    {
      "epoch": 2.53,
      "grad_norm": 1.8110312223434448,
      "learning_rate": 5.9234450982520285e-06,
      "loss": 1.6987,
      "step": 24390
    },
    {
      "epoch": 2.53,
      "grad_norm": 1.9272148609161377,
      "learning_rate": 5.897814112479954e-06,
      "loss": 1.6744,
      "step": 24400
    },
    {
      "epoch": 2.53,
      "grad_norm": 2.294955253601074,
      "learning_rate": 5.8722352242069515e-06,
      "loss": 1.5518,
      "step": 24410
    },
    {
      "epoch": 2.53,
      "grad_norm": 3.8249709606170654,
      "learning_rate": 5.84670846364912e-06,
      "loss": 1.5488,
      "step": 24420
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.348909854888916,
      "learning_rate": 5.821233860961e-06,
      "loss": 1.7039,
      "step": 24430
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.049985885620117,
      "learning_rate": 5.7958114462354886e-06,
      "loss": 1.7437,
      "step": 24440
    },
    {
      "epoch": 2.54,
      "grad_norm": 1.7600862979888916,
      "learning_rate": 5.77044124950385e-06,
      "loss": 1.7499,
      "step": 24450
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.1101295948028564,
      "learning_rate": 5.745123300735655e-06,
      "loss": 1.6987,
      "step": 24460
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.434105396270752,
      "learning_rate": 5.7198576298387545e-06,
      "loss": 1.6843,
      "step": 24470
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.2089571952819824,
      "learning_rate": 5.694644266659266e-06,
      "loss": 1.6763,
      "step": 24480
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.0115396976470947,
      "learning_rate": 5.669483240981493e-06,
      "loss": 1.7232,
      "step": 24490
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.0566680431365967,
      "learning_rate": 5.644374582527912e-06,
      "loss": 1.7609,
      "step": 24500
    },
    {
      "epoch": 2.54,
      "eval_loss": 1.8080946207046509,
      "eval_runtime": 366.7761,
      "eval_samples_per_second": 23.355,
      "eval_steps_per_second": 23.355,
      "step": 24500
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.2404942512512207,
      "learning_rate": 5.619318320959155e-06,
      "loss": 1.7029,
      "step": 24510
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.4610164165496826,
      "learning_rate": 5.59431448587393e-06,
      "loss": 1.5854,
      "step": 24520
    },
    {
      "epoch": 2.55,
      "grad_norm": 2.2357473373413086,
      "learning_rate": 5.5693631068090615e-06,
      "loss": 1.6809,
      "step": 24530
    },
    {
      "epoch": 2.55,
      "grad_norm": 2.5194218158721924,
      "learning_rate": 5.5444642132393644e-06,
      "loss": 1.7569,
      "step": 24540
    },
    {
      "epoch": 2.55,
      "grad_norm": 2.3939223289489746,
      "learning_rate": 5.519617834577662e-06,
      "loss": 1.6579,
      "step": 24550
    },
    {
      "epoch": 2.55,
      "grad_norm": 2.40265154838562,
      "learning_rate": 5.494824000174764e-06,
      "loss": 1.5864,
      "step": 24560
    },
    {
      "epoch": 2.55,
      "grad_norm": 2.11824107170105,
      "learning_rate": 5.470082739319388e-06,
      "loss": 1.7714,
      "step": 24570
    },
    {
      "epoch": 2.55,
      "grad_norm": 2.2996251583099365,
      "learning_rate": 5.445394081238153e-06,
      "loss": 1.7126,
      "step": 24580
    },
    {
      "epoch": 2.55,
      "grad_norm": 2.5817244052886963,
      "learning_rate": 5.420758055095532e-06,
      "loss": 1.7753,
      "step": 24590
    },
    {
      "epoch": 2.55,
      "grad_norm": 1.9671807289123535,
      "learning_rate": 5.396174689993849e-06,
      "loss": 1.6339,
      "step": 24600
    },
    {
      "epoch": 2.55,
      "grad_norm": 2.0654733180999756,
      "learning_rate": 5.371644014973193e-06,
      "loss": 1.6509,
      "step": 24610
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.1205062866210938,
      "learning_rate": 5.34716605901141e-06,
      "loss": 1.563,
      "step": 24620
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.2735555171966553,
      "learning_rate": 5.3227408510241e-06,
      "loss": 1.6318,
      "step": 24630
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.8393709659576416,
      "learning_rate": 5.29836841986453e-06,
      "loss": 1.6204,
      "step": 24640
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.2943859100341797,
      "learning_rate": 5.27404879432361e-06,
      "loss": 1.6508,
      "step": 24650
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.423921823501587,
      "learning_rate": 5.2497820031298935e-06,
      "loss": 1.6413,
      "step": 24660
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.0429563522338867,
      "learning_rate": 5.225568074949516e-06,
      "loss": 1.6377,
      "step": 24670
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.8979543447494507,
      "learning_rate": 5.201407038386169e-06,
      "loss": 1.6888,
      "step": 24680
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.9097506999969482,
      "learning_rate": 5.177298921981039e-06,
      "loss": 1.6036,
      "step": 24690
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.2665696144104004,
      "learning_rate": 5.153243754212838e-06,
      "loss": 1.6586,
      "step": 24700
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.2470240592956543,
      "learning_rate": 5.129241563497711e-06,
      "loss": 1.7032,
      "step": 24710
    },
    {
      "epoch": 2.57,
      "grad_norm": 2.4343063831329346,
      "learning_rate": 5.105292378189197e-06,
      "loss": 1.6233,
      "step": 24720
    },
    {
      "epoch": 2.57,
      "grad_norm": 1.9156427383422852,
      "learning_rate": 5.081396226578273e-06,
      "loss": 1.6973,
      "step": 24730
    },
    {
      "epoch": 2.57,
      "grad_norm": 2.4441378116607666,
      "learning_rate": 5.057553136893228e-06,
      "loss": 1.5873,
      "step": 24740
    },
    {
      "epoch": 2.57,
      "grad_norm": 2.5506484508514404,
      "learning_rate": 5.03376313729968e-06,
      "loss": 1.66,
      "step": 24750
    },
    {
      "epoch": 2.57,
      "grad_norm": 2.0552854537963867,
      "learning_rate": 5.010026255900518e-06,
      "loss": 1.6036,
      "step": 24760
    },
    {
      "epoch": 2.57,
      "grad_norm": 2.175600528717041,
      "learning_rate": 4.986342520735926e-06,
      "loss": 1.7352,
      "step": 24770
    },
    {
      "epoch": 2.57,
      "grad_norm": 1.9474823474884033,
      "learning_rate": 4.962711959783261e-06,
      "loss": 1.7682,
      "step": 24780
    },
    {
      "epoch": 2.57,
      "grad_norm": 2.030775308609009,
      "learning_rate": 4.9391346009570795e-06,
      "loss": 1.7556,
      "step": 24790
    },
    {
      "epoch": 2.57,
      "grad_norm": 1.6752042770385742,
      "learning_rate": 4.915610472109111e-06,
      "loss": 1.6302,
      "step": 24800
    },
    {
      "epoch": 2.57,
      "grad_norm": 1.8259567022323608,
      "learning_rate": 4.892139601028178e-06,
      "loss": 1.7425,
      "step": 24810
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.3606886863708496,
      "learning_rate": 4.868722015440192e-06,
      "loss": 1.6615,
      "step": 24820
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.0441269874572754,
      "learning_rate": 4.845357743008144e-06,
      "loss": 1.6211,
      "step": 24830
    },
    {
      "epoch": 2.58,
      "grad_norm": 1.9224873781204224,
      "learning_rate": 4.822046811332026e-06,
      "loss": 1.5967,
      "step": 24840
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.2468764781951904,
      "learning_rate": 4.798789247948826e-06,
      "loss": 1.6172,
      "step": 24850
    },
    {
      "epoch": 2.58,
      "grad_norm": 1.8771846294403076,
      "learning_rate": 4.775585080332462e-06,
      "loss": 1.5501,
      "step": 24860
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.191368579864502,
      "learning_rate": 4.752434335893835e-06,
      "loss": 1.7044,
      "step": 24870
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.503244400024414,
      "learning_rate": 4.72933704198068e-06,
      "loss": 1.4995,
      "step": 24880
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.0416769981384277,
      "learning_rate": 4.706293225877617e-06,
      "loss": 1.6448,
      "step": 24890
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.6988203525543213,
      "learning_rate": 4.683302914806098e-06,
      "loss": 1.7557,
      "step": 24900
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.2902016639709473,
      "learning_rate": 4.66036613592436e-06,
      "loss": 1.6146,
      "step": 24910
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.0429656505584717,
      "learning_rate": 4.6374829163274015e-06,
      "loss": 1.7086,
      "step": 24920
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.3118526935577393,
      "learning_rate": 4.6146532830469435e-06,
      "loss": 1.6424,
      "step": 24930
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.060727834701538,
      "learning_rate": 4.591877263051441e-06,
      "loss": 1.5246,
      "step": 24940
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.5514955520629883,
      "learning_rate": 4.569154883245985e-06,
      "loss": 1.6899,
      "step": 24950
    },
    {
      "epoch": 2.59,
      "grad_norm": 1.9259172677993774,
      "learning_rate": 4.546486170472297e-06,
      "loss": 1.633,
      "step": 24960
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.4700891971588135,
      "learning_rate": 4.523871151508735e-06,
      "loss": 1.5862,
      "step": 24970
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.2039785385131836,
      "learning_rate": 4.501309853070196e-06,
      "loss": 1.5898,
      "step": 24980
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.0073516368865967,
      "learning_rate": 4.478802301808138e-06,
      "loss": 1.6644,
      "step": 24990
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.0332748889923096,
      "learning_rate": 4.456348524310517e-06,
      "loss": 1.5347,
      "step": 25000
    },
    {
      "epoch": 2.59,
      "eval_loss": 1.8075504302978516,
      "eval_runtime": 366.3602,
      "eval_samples_per_second": 23.381,
      "eval_steps_per_second": 23.381,
      "step": 25000
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.8717288970947266,
      "learning_rate": 4.4339485471017575e-06,
      "loss": 1.5481,
      "step": 25010
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.443085193634033,
      "learning_rate": 4.411602396642767e-06,
      "loss": 1.5923,
      "step": 25020
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.428905963897705,
      "learning_rate": 4.391536904919402e-06,
      "loss": 1.6755,
      "step": 25030
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.0302655696868896,
      "learning_rate": 4.3692930979569165e-06,
      "loss": 1.6881,
      "step": 25040
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.4318830966949463,
      "learning_rate": 4.347103194121077e-06,
      "loss": 1.7191,
      "step": 25050
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.321272134780884,
      "learning_rate": 4.324967219624593e-06,
      "loss": 1.6974,
      "step": 25060
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.273607015609741,
      "learning_rate": 4.30288520061648e-06,
      "loss": 1.7029,
      "step": 25070
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.8631031513214111,
      "learning_rate": 4.280857163182034e-06,
      "loss": 1.7214,
      "step": 25080
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.355072021484375,
      "learning_rate": 4.258883133342767e-06,
      "loss": 1.7174,
      "step": 25090
    },
    {
      "epoch": 2.6,
      "grad_norm": 2.2804946899414062,
      "learning_rate": 4.236963137056388e-06,
      "loss": 1.5771,
      "step": 25100
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.123605966567993,
      "learning_rate": 4.2150972002167774e-06,
      "loss": 1.6171,
      "step": 25110
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.242096424102783,
      "learning_rate": 4.193285348653975e-06,
      "loss": 1.6406,
      "step": 25120
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.3184096813201904,
      "learning_rate": 4.171527608134112e-06,
      "loss": 1.7075,
      "step": 25130
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.372652769088745,
      "learning_rate": 4.1498240043593985e-06,
      "loss": 1.6545,
      "step": 25140
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.232440233230591,
      "learning_rate": 4.1281745629681065e-06,
      "loss": 1.6811,
      "step": 25150
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.3213722705841064,
      "learning_rate": 4.106579309534519e-06,
      "loss": 1.644,
      "step": 25160
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.6248996257781982,
      "learning_rate": 4.0850382695688915e-06,
      "loss": 1.6294,
      "step": 25170
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.152362585067749,
      "learning_rate": 4.063551468517474e-06,
      "loss": 1.6578,
      "step": 25180
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.3900234699249268,
      "learning_rate": 4.042118931762412e-06,
      "loss": 1.6655,
      "step": 25190
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.6472012996673584,
      "learning_rate": 4.0207406846217595e-06,
      "loss": 1.6536,
      "step": 25200
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.2818093299865723,
      "learning_rate": 3.999416752349433e-06,
      "loss": 1.6861,
      "step": 25210
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.2720158100128174,
      "learning_rate": 3.978147160135215e-06,
      "loss": 1.6216,
      "step": 25220
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.4665021896362305,
      "learning_rate": 3.9569319331046576e-06,
      "loss": 1.7059,
      "step": 25230
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.494602918624878,
      "learning_rate": 3.935771096319108e-06,
      "loss": 1.7024,
      "step": 25240
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.067516803741455,
      "learning_rate": 3.914664674775681e-06,
      "loss": 1.7003,
      "step": 25250
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.5072500705718994,
      "learning_rate": 3.893612693407184e-06,
      "loss": 1.7363,
      "step": 25260
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.2173755168914795,
      "learning_rate": 3.872615177082118e-06,
      "loss": 1.8125,
      "step": 25270
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.2104928493499756,
      "learning_rate": 3.851672150604668e-06,
      "loss": 1.5718,
      "step": 25280
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.1430015563964844,
      "learning_rate": 3.83078363871463e-06,
      "loss": 1.626,
      "step": 25290
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.3123369216918945,
      "learning_rate": 3.8099496660874033e-06,
      "loss": 1.6044,
      "step": 25300
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.0111615657806396,
      "learning_rate": 3.7891702573339572e-06,
      "loss": 1.6695,
      "step": 25310
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.5082876682281494,
      "learning_rate": 3.7684454370008337e-06,
      "loss": 1.6814,
      "step": 25320
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.308656692504883,
      "learning_rate": 3.747775229570055e-06,
      "loss": 1.7474,
      "step": 25330
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.098623752593994,
      "learning_rate": 3.7271596594591397e-06,
      "loss": 1.6478,
      "step": 25340
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.116004467010498,
      "learning_rate": 3.706598751021079e-06,
      "loss": 1.6561,
      "step": 25350
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.1356008052825928,
      "learning_rate": 3.6860925285442773e-06,
      "loss": 1.5744,
      "step": 25360
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.621279716491699,
      "learning_rate": 3.665641016252541e-06,
      "loss": 1.7076,
      "step": 25370
    },
    {
      "epoch": 2.63,
      "grad_norm": 1.872499942779541,
      "learning_rate": 3.6452442383050454e-06,
      "loss": 1.7218,
      "step": 25380
    },
    {
      "epoch": 2.63,
      "grad_norm": 2.5824832916259766,
      "learning_rate": 3.624902218796328e-06,
      "loss": 1.5726,
      "step": 25390
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.390072822570801,
      "learning_rate": 3.6046149817562105e-06,
      "loss": 1.6581,
      "step": 25400
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.1864142417907715,
      "learning_rate": 3.5843825511498285e-06,
      "loss": 1.6752,
      "step": 25410
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.1744353771209717,
      "learning_rate": 3.564204950877548e-06,
      "loss": 1.6977,
      "step": 25420
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.2262845039367676,
      "learning_rate": 3.54408220477499e-06,
      "loss": 1.7167,
      "step": 25430
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.1766083240509033,
      "learning_rate": 3.5240143366129685e-06,
      "loss": 1.6327,
      "step": 25440
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.1741278171539307,
      "learning_rate": 3.5040013700974595e-06,
      "loss": 1.7574,
      "step": 25450
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.041071653366089,
      "learning_rate": 3.4840433288696018e-06,
      "loss": 1.5755,
      "step": 25460
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.2424683570861816,
      "learning_rate": 3.464140236505625e-06,
      "loss": 1.658,
      "step": 25470
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.523369312286377,
      "learning_rate": 3.444292116516884e-06,
      "loss": 1.4945,
      "step": 25480
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.301635265350342,
      "learning_rate": 3.424498992349778e-06,
      "loss": 1.653,
      "step": 25490
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.789433717727661,
      "learning_rate": 3.4047608873857275e-06,
      "loss": 1.6027,
      "step": 25500
    },
    {
      "epoch": 2.65,
      "eval_loss": 1.8071681261062622,
      "eval_runtime": 366.5477,
      "eval_samples_per_second": 23.369,
      "eval_steps_per_second": 23.369,
      "step": 25500
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.0792737007141113,
      "learning_rate": 3.3850778249411684e-06,
      "loss": 1.7367,
      "step": 25510
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.343574285507202,
      "learning_rate": 3.365449828267536e-06,
      "loss": 1.7023,
      "step": 25520
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.0811409950256348,
      "learning_rate": 3.345876920551183e-06,
      "loss": 1.7026,
      "step": 25530
    },
    {
      "epoch": 2.65,
      "grad_norm": 3.2798686027526855,
      "learning_rate": 3.326359124913403e-06,
      "loss": 1.4349,
      "step": 25540
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.3154408931732178,
      "learning_rate": 3.306896464410397e-06,
      "loss": 1.7692,
      "step": 25550
    },
    {
      "epoch": 2.65,
      "grad_norm": 1.9824575185775757,
      "learning_rate": 3.2874889620332137e-06,
      "loss": 1.7666,
      "step": 25560
    },
    {
      "epoch": 2.65,
      "grad_norm": 1.841318130493164,
      "learning_rate": 3.2681366407077583e-06,
      "loss": 1.6397,
      "step": 25570
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.5977861881256104,
      "learning_rate": 3.2488395232947387e-06,
      "loss": 1.6767,
      "step": 25580
    },
    {
      "epoch": 2.66,
      "grad_norm": 1.9506735801696777,
      "learning_rate": 3.2295976325896703e-06,
      "loss": 1.6547,
      "step": 25590
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.0634188652038574,
      "learning_rate": 3.2104109913228097e-06,
      "loss": 1.6557,
      "step": 25600
    },
    {
      "epoch": 2.66,
      "grad_norm": 1.9435436725616455,
      "learning_rate": 3.1912796221591543e-06,
      "loss": 1.7079,
      "step": 25610
    },
    {
      "epoch": 2.66,
      "grad_norm": 1.9832992553710938,
      "learning_rate": 3.1722035476984267e-06,
      "loss": 1.6912,
      "step": 25620
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.024895429611206,
      "learning_rate": 3.153182790475001e-06,
      "loss": 1.7035,
      "step": 25630
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.3291525840759277,
      "learning_rate": 3.134217372957926e-06,
      "loss": 1.6022,
      "step": 25640
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.1884937286376953,
      "learning_rate": 3.1153073175508584e-06,
      "loss": 1.6661,
      "step": 25650
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.2704410552978516,
      "learning_rate": 3.0964526465920907e-06,
      "loss": 1.622,
      "step": 25660
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.5246849060058594,
      "learning_rate": 3.077653382354462e-06,
      "loss": 1.636,
      "step": 25670
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.524521827697754,
      "learning_rate": 3.0589095470453523e-06,
      "loss": 1.6643,
      "step": 25680
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.618893623352051,
      "learning_rate": 3.0402211628066947e-06,
      "loss": 1.5984,
      "step": 25690
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.1499176025390625,
      "learning_rate": 3.021588251714902e-06,
      "loss": 1.6696,
      "step": 25700
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.325561761856079,
      "learning_rate": 3.0030108357808453e-06,
      "loss": 1.6187,
      "step": 25710
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.0357987880706787,
      "learning_rate": 2.984488936949864e-06,
      "loss": 1.6629,
      "step": 25720
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.2287487983703613,
      "learning_rate": 2.9660225771017012e-06,
      "loss": 1.6332,
      "step": 25730
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.382711172103882,
      "learning_rate": 2.9476117780504964e-06,
      "loss": 1.724,
      "step": 25740
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.1440680027008057,
      "learning_rate": 2.929256561544741e-06,
      "loss": 1.6812,
      "step": 25750
    },
    {
      "epoch": 2.67,
      "grad_norm": 1.9825574159622192,
      "learning_rate": 2.9109569492673017e-06,
      "loss": 1.6443,
      "step": 25760
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.633505344390869,
      "learning_rate": 2.89271296283532e-06,
      "loss": 1.7181,
      "step": 25770
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.2807164192199707,
      "learning_rate": 2.874524623800251e-06,
      "loss": 1.6915,
      "step": 25780
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.350626230239868,
      "learning_rate": 2.8563919536478246e-06,
      "loss": 1.7209,
      "step": 25790
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.14866304397583,
      "learning_rate": 2.8383149737979732e-06,
      "loss": 1.5783,
      "step": 25800
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.286012887954712,
      "learning_rate": 2.8202937056048707e-06,
      "loss": 1.643,
      "step": 25810
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.095982789993286,
      "learning_rate": 2.802328170356877e-06,
      "loss": 1.6459,
      "step": 25820
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.2469048500061035,
      "learning_rate": 2.7844183892765106e-06,
      "loss": 1.5946,
      "step": 25830
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.0241141319274902,
      "learning_rate": 2.766564383520426e-06,
      "loss": 1.6202,
      "step": 25840
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.414094924926758,
      "learning_rate": 2.7487661741793793e-06,
      "loss": 1.7215,
      "step": 25850
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.4512791633605957,
      "learning_rate": 2.7310237822782523e-06,
      "loss": 1.7522,
      "step": 25860
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.064784526824951,
      "learning_rate": 2.7133372287759583e-06,
      "loss": 1.5397,
      "step": 25870
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.059925079345703,
      "learning_rate": 2.69570653456544e-06,
      "loss": 1.6617,
      "step": 25880
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.240561008453369,
      "learning_rate": 2.6781317204736978e-06,
      "loss": 1.7145,
      "step": 25890
    },
    {
      "epoch": 2.69,
      "grad_norm": 1.892883539199829,
      "learning_rate": 2.660612807261681e-06,
      "loss": 1.6766,
      "step": 25900
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.5751450061798096,
      "learning_rate": 2.643149815624324e-06,
      "loss": 1.6608,
      "step": 25910
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.5318281650543213,
      "learning_rate": 2.6257427661904753e-06,
      "loss": 1.7714,
      "step": 25920
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.411135673522949,
      "learning_rate": 2.608391679522948e-06,
      "loss": 1.6921,
      "step": 25930
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.3180909156799316,
      "learning_rate": 2.591096576118407e-06,
      "loss": 1.7142,
      "step": 25940
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.1679952144622803,
      "learning_rate": 2.5738574764073876e-06,
      "loss": 1.6107,
      "step": 25950
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.195821523666382,
      "learning_rate": 2.5566744007542777e-06,
      "loss": 1.6764,
      "step": 25960
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.0816123485565186,
      "learning_rate": 2.539547369457296e-06,
      "loss": 1.5881,
      "step": 25970
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.287708282470703,
      "learning_rate": 2.5224764027484414e-06,
      "loss": 1.6301,
      "step": 25980
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.2826101779937744,
      "learning_rate": 2.5054615207934786e-06,
      "loss": 1.5914,
      "step": 25990
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.3630077838897705,
      "learning_rate": 2.488502743691934e-06,
      "loss": 1.7376,
      "step": 26000
    },
    {
      "epoch": 2.7,
      "eval_loss": 1.8066359758377075,
      "eval_runtime": 366.3741,
      "eval_samples_per_second": 23.38,
      "eval_steps_per_second": 23.38,
      "step": 26000
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.397533416748047,
      "learning_rate": 2.4716000914770445e-06,
      "loss": 1.6055,
      "step": 26010
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.1121106147766113,
      "learning_rate": 2.4547535841157652e-06,
      "loss": 1.6532,
      "step": 26020
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.1200623512268066,
      "learning_rate": 2.4379632415087116e-06,
      "loss": 1.7108,
      "step": 26030
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.7257951498031616,
      "learning_rate": 2.4212290834901673e-06,
      "loss": 1.6332,
      "step": 26040
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.4444830417633057,
      "learning_rate": 2.4045511298280144e-06,
      "loss": 1.5788,
      "step": 26050
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.309835433959961,
      "learning_rate": 2.3879294002237873e-06,
      "loss": 1.725,
      "step": 26060
    },
    {
      "epoch": 2.71,
      "grad_norm": 2.6692404747009277,
      "learning_rate": 2.3713639143125687e-06,
      "loss": 1.6578,
      "step": 26070
    },
    {
      "epoch": 2.71,
      "grad_norm": 2.544325590133667,
      "learning_rate": 2.354854691663011e-06,
      "loss": 1.7452,
      "step": 26080
    },
    {
      "epoch": 2.71,
      "grad_norm": 2.446953296661377,
      "learning_rate": 2.338401751777308e-06,
      "loss": 1.714,
      "step": 26090
    },
    {
      "epoch": 2.71,
      "grad_norm": 2.6786575317382812,
      "learning_rate": 2.3220051140911637e-06,
      "loss": 1.7433,
      "step": 26100
    },
    {
      "epoch": 2.71,
      "grad_norm": 2.1722898483276367,
      "learning_rate": 2.3056647979737723e-06,
      "loss": 1.536,
      "step": 26110
    },
    {
      "epoch": 2.71,
      "grad_norm": 1.8602675199508667,
      "learning_rate": 2.2893808227277823e-06,
      "loss": 1.5999,
      "step": 26120
    },
    {
      "epoch": 2.71,
      "grad_norm": 2.028536796569824,
      "learning_rate": 2.273153207589329e-06,
      "loss": 1.7139,
      "step": 26130
    },
    {
      "epoch": 2.71,
      "grad_norm": 2.255565881729126,
      "learning_rate": 2.256981971727923e-06,
      "loss": 1.7084,
      "step": 26140
    },
    {
      "epoch": 2.71,
      "grad_norm": 2.1199538707733154,
      "learning_rate": 2.2408671342464883e-06,
      "loss": 1.6969,
      "step": 26150
    },
    {
      "epoch": 2.71,
      "grad_norm": 1.9264858961105347,
      "learning_rate": 2.224808714181348e-06,
      "loss": 1.5779,
      "step": 26160
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.4895949363708496,
      "learning_rate": 2.2088067305021554e-06,
      "loss": 1.7188,
      "step": 26170
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.0525805950164795,
      "learning_rate": 2.1928612021119065e-06,
      "loss": 1.5883,
      "step": 26180
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.38350510597229,
      "learning_rate": 2.1769721478468952e-06,
      "loss": 1.6125,
      "step": 26190
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.0014586448669434,
      "learning_rate": 2.1611395864767235e-06,
      "loss": 1.7048,
      "step": 26200
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.495518207550049,
      "learning_rate": 2.145363536704248e-06,
      "loss": 1.6758,
      "step": 26210
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.1405978202819824,
      "learning_rate": 2.1296440171655554e-06,
      "loss": 1.5621,
      "step": 26220
    },
    {
      "epoch": 2.72,
      "grad_norm": 1.9500532150268555,
      "learning_rate": 2.1139810464299858e-06,
      "loss": 1.7058,
      "step": 26230
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.23350191116333,
      "learning_rate": 2.0983746430000505e-06,
      "loss": 1.7337,
      "step": 26240
    },
    {
      "epoch": 2.72,
      "grad_norm": 2.182103157043457,
      "learning_rate": 2.0828248253114357e-06,
      "loss": 1.573,
      "step": 26250
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.0597028732299805,
      "learning_rate": 2.06733161173302e-06,
      "loss": 1.6832,
      "step": 26260
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.094364643096924,
      "learning_rate": 2.0518950205667742e-06,
      "loss": 1.6933,
      "step": 26270
    },
    {
      "epoch": 2.73,
      "grad_norm": 3.058856964111328,
      "learning_rate": 2.0365150700478008e-06,
      "loss": 1.6655,
      "step": 26280
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.1675288677215576,
      "learning_rate": 2.0211917783442946e-06,
      "loss": 1.6386,
      "step": 26290
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.2055506706237793,
      "learning_rate": 2.005925163557515e-06,
      "loss": 1.695,
      "step": 26300
    },
    {
      "epoch": 2.73,
      "grad_norm": 1.8643840551376343,
      "learning_rate": 1.9907152437217748e-06,
      "loss": 1.6536,
      "step": 26310
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.9666881561279297,
      "learning_rate": 1.9755620368044015e-06,
      "loss": 1.6702,
      "step": 26320
    },
    {
      "epoch": 2.73,
      "grad_norm": 1.968307614326477,
      "learning_rate": 1.9604655607057433e-06,
      "loss": 1.4769,
      "step": 26330
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.0606331825256348,
      "learning_rate": 1.945425833259129e-06,
      "loss": 1.6276,
      "step": 26340
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.0102226734161377,
      "learning_rate": 1.9304428722308367e-06,
      "loss": 1.6904,
      "step": 26350
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.021449089050293,
      "learning_rate": 1.9155166953201075e-06,
      "loss": 1.5628,
      "step": 26360
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.2657294273376465,
      "learning_rate": 1.9006473201590935e-06,
      "loss": 1.6539,
      "step": 26370
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.0428202152252197,
      "learning_rate": 1.8858347643128437e-06,
      "loss": 1.7185,
      "step": 26380
    },
    {
      "epoch": 2.74,
      "grad_norm": 1.9681273698806763,
      "learning_rate": 1.8710790452792893e-06,
      "loss": 1.651,
      "step": 26390
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.749660015106201,
      "learning_rate": 1.8563801804892312e-06,
      "loss": 1.834,
      "step": 26400
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.5164971351623535,
      "learning_rate": 1.8417381873063022e-06,
      "loss": 1.6493,
      "step": 26410
    },
    {
      "epoch": 2.74,
      "grad_norm": 1.9323326349258423,
      "learning_rate": 1.8271530830269335e-06,
      "loss": 1.7648,
      "step": 26420
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.0425472259521484,
      "learning_rate": 1.8126248848803983e-06,
      "loss": 1.6218,
      "step": 26430
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.128958225250244,
      "learning_rate": 1.7981536100287022e-06,
      "loss": 1.6364,
      "step": 26440
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.143988609313965,
      "learning_rate": 1.7837392755666371e-06,
      "loss": 1.5879,
      "step": 26450
    },
    {
      "epoch": 2.75,
      "grad_norm": 2.6633942127227783,
      "learning_rate": 1.7693818985217047e-06,
      "loss": 1.7184,
      "step": 26460
    },
    {
      "epoch": 2.75,
      "grad_norm": 1.831807017326355,
      "learning_rate": 1.7550814958541606e-06,
      "loss": 1.681,
      "step": 26470
    },
    {
      "epoch": 2.75,
      "grad_norm": 2.3306021690368652,
      "learning_rate": 1.7408380844569304e-06,
      "loss": 1.6232,
      "step": 26480
    },
    {
      "epoch": 2.75,
      "grad_norm": 2.3761816024780273,
      "learning_rate": 1.7266516811556166e-06,
      "loss": 1.6609,
      "step": 26490
    },
    {
      "epoch": 2.75,
      "grad_norm": 2.3714754581451416,
      "learning_rate": 1.7125223027084858e-06,
      "loss": 1.7109,
      "step": 26500
    },
    {
      "epoch": 2.75,
      "eval_loss": 1.8064804077148438,
      "eval_runtime": 366.5977,
      "eval_samples_per_second": 23.366,
      "eval_steps_per_second": 23.366,
      "step": 26500
    },
    {
      "epoch": 2.75,
      "grad_norm": 2.3402791023254395,
      "learning_rate": 1.6984499658064423e-06,
      "loss": 1.6452,
      "step": 26510
    },
    {
      "epoch": 2.75,
      "grad_norm": 1.8739113807678223,
      "learning_rate": 1.684434687073011e-06,
      "loss": 1.6683,
      "step": 26520
    },
    {
      "epoch": 2.75,
      "grad_norm": 2.090606451034546,
      "learning_rate": 1.6704764830642983e-06,
      "loss": 1.7161,
      "step": 26530
    },
    {
      "epoch": 2.75,
      "grad_norm": 3.9239823818206787,
      "learning_rate": 1.656575370269009e-06,
      "loss": 1.7506,
      "step": 26540
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.1380577087402344,
      "learning_rate": 1.642731365108391e-06,
      "loss": 1.7657,
      "step": 26550
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.082448959350586,
      "learning_rate": 1.6289444839362455e-06,
      "loss": 1.6811,
      "step": 26560
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.5577099323272705,
      "learning_rate": 1.6152147430388786e-06,
      "loss": 1.7774,
      "step": 26570
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.2009456157684326,
      "learning_rate": 1.6015421586351109e-06,
      "loss": 1.6272,
      "step": 26580
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.255693197250366,
      "learning_rate": 1.5879267468762337e-06,
      "loss": 1.6269,
      "step": 26590
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.0352518558502197,
      "learning_rate": 1.5743685238460038e-06,
      "loss": 1.6695,
      "step": 26600
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.2429628372192383,
      "learning_rate": 1.5608675055606313e-06,
      "loss": 1.8045,
      "step": 26610
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.285048007965088,
      "learning_rate": 1.5474237079687314e-06,
      "loss": 1.5709,
      "step": 26620
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.187016010284424,
      "learning_rate": 1.5340371469513505e-06,
      "loss": 1.583,
      "step": 26630
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.3498497009277344,
      "learning_rate": 1.5207078383218943e-06,
      "loss": 1.8029,
      "step": 26640
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.2267682552337646,
      "learning_rate": 1.5074357978261567e-06,
      "loss": 1.5816,
      "step": 26650
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.127513885498047,
      "learning_rate": 1.4942210411422685e-06,
      "loss": 1.6379,
      "step": 26660
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.2796316146850586,
      "learning_rate": 1.4810635838807097e-06,
      "loss": 1.7107,
      "step": 26670
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.2436325550079346,
      "learning_rate": 1.4679634415842524e-06,
      "loss": 1.6818,
      "step": 26680
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.176896572113037,
      "learning_rate": 1.4549206297279738e-06,
      "loss": 1.6097,
      "step": 26690
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.4082205295562744,
      "learning_rate": 1.4419351637192268e-06,
      "loss": 1.6159,
      "step": 26700
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.1671385765075684,
      "learning_rate": 1.4290070588976245e-06,
      "loss": 1.5999,
      "step": 26710
    },
    {
      "epoch": 2.77,
      "grad_norm": 1.8879659175872803,
      "learning_rate": 1.416136330535006e-06,
      "loss": 1.655,
      "step": 26720
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.182891845703125,
      "learning_rate": 1.403322993835443e-06,
      "loss": 1.6593,
      "step": 26730
    },
    {
      "epoch": 2.78,
      "grad_norm": 1.9096696376800537,
      "learning_rate": 1.390567063935222e-06,
      "loss": 1.7632,
      "step": 26740
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.320777416229248,
      "learning_rate": 1.3778685559027948e-06,
      "loss": 1.6371,
      "step": 26750
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.3039960861206055,
      "learning_rate": 1.3652274847387847e-06,
      "loss": 1.6489,
      "step": 26760
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.303565740585327,
      "learning_rate": 1.3526438653759854e-06,
      "loss": 1.7495,
      "step": 26770
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.1323602199554443,
      "learning_rate": 1.3401177126793007e-06,
      "loss": 1.5745,
      "step": 26780
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.6343204975128174,
      "learning_rate": 1.32764904144575e-06,
      "loss": 1.5956,
      "step": 26790
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.435429096221924,
      "learning_rate": 1.315237866404473e-06,
      "loss": 1.7779,
      "step": 26800
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.1746976375579834,
      "learning_rate": 1.3028842022166644e-06,
      "loss": 1.6188,
      "step": 26810
    },
    {
      "epoch": 2.78,
      "grad_norm": 1.8276281356811523,
      "learning_rate": 1.2905880634755952e-06,
      "loss": 1.6915,
      "step": 26820
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.4665770530700684,
      "learning_rate": 1.2783494647065686e-06,
      "loss": 1.6491,
      "step": 26830
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.4324841499328613,
      "learning_rate": 1.2661684203669421e-06,
      "loss": 1.7767,
      "step": 26840
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.173689365386963,
      "learning_rate": 1.2540449448460667e-06,
      "loss": 1.7556,
      "step": 26850
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.2863738536834717,
      "learning_rate": 1.2419790524652809e-06,
      "loss": 1.6657,
      "step": 26860
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.77966046333313,
      "learning_rate": 1.2299707574779218e-06,
      "loss": 1.5423,
      "step": 26870
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.2740495204925537,
      "learning_rate": 1.2180200740692704e-06,
      "loss": 1.6743,
      "step": 26880
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.2451119422912598,
      "learning_rate": 1.2061270163565508e-06,
      "loss": 1.5794,
      "step": 26890
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.212756633758545,
      "learning_rate": 1.1942915983889302e-06,
      "loss": 1.5576,
      "step": 26900
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.307974338531494,
      "learning_rate": 1.1825138341474751e-06,
      "loss": 1.7619,
      "step": 26910
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.4807841777801514,
      "learning_rate": 1.170793737545145e-06,
      "loss": 1.6699,
      "step": 26920
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.4162802696228027,
      "learning_rate": 1.159131322426782e-06,
      "loss": 1.7293,
      "step": 26930
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.187246799468994,
      "learning_rate": 1.147526602569088e-06,
      "loss": 1.6133,
      "step": 26940
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.8973768949508667,
      "learning_rate": 1.1359795916806138e-06,
      "loss": 1.7699,
      "step": 26950
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.95157790184021,
      "learning_rate": 1.1244903034017207e-06,
      "loss": 1.7027,
      "step": 26960
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.9102942943572998,
      "learning_rate": 1.1130587513046131e-06,
      "loss": 1.6705,
      "step": 26970
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.9958631992340088,
      "learning_rate": 1.1016849488932723e-06,
      "loss": 1.6167,
      "step": 26980
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.2748301029205322,
      "learning_rate": 1.0903689096034675e-06,
      "loss": 1.7118,
      "step": 26990
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.3941409587860107,
      "learning_rate": 1.0791106468027169e-06,
      "loss": 1.7087,
      "step": 27000
    },
    {
      "epoch": 2.8,
      "eval_loss": 1.806449294090271,
      "eval_runtime": 366.1759,
      "eval_samples_per_second": 23.393,
      "eval_steps_per_second": 23.393,
      "step": 27000
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.0505008697509766,
      "learning_rate": 1.0679101737903096e-06,
      "loss": 1.7042,
      "step": 27010
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.109651803970337,
      "learning_rate": 1.056767503797268e-06,
      "loss": 1.64,
      "step": 27020
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.870554208755493,
      "learning_rate": 1.045682649986307e-06,
      "loss": 1.6529,
      "step": 27030
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.4690799713134766,
      "learning_rate": 1.0346556254518746e-06,
      "loss": 1.708,
      "step": 27040
    },
    {
      "epoch": 2.81,
      "grad_norm": 1.8944483995437622,
      "learning_rate": 1.0236864432200787e-06,
      "loss": 1.7992,
      "step": 27050
    },
    {
      "epoch": 2.81,
      "grad_norm": 1.8543983697891235,
      "learning_rate": 1.0127751162487264e-06,
      "loss": 1.6345,
      "step": 27060
    },
    {
      "epoch": 2.81,
      "grad_norm": 1.9788914918899536,
      "learning_rate": 1.0019216574272517e-06,
      "loss": 1.6899,
      "step": 27070
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.220709800720215,
      "learning_rate": 9.91126079576754e-07,
      "loss": 1.6911,
      "step": 27080
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.1997783184051514,
      "learning_rate": 9.803883954499493e-07,
      "loss": 1.6677,
      "step": 27090
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.243908166885376,
      "learning_rate": 9.697086177311466e-07,
      "loss": 1.6892,
      "step": 27100
    },
    {
      "epoch": 2.81,
      "grad_norm": 1.8640730381011963,
      "learning_rate": 9.590867590362873e-07,
      "loss": 1.6054,
      "step": 27110
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.014134645462036,
      "learning_rate": 9.485228319128625e-07,
      "loss": 1.7029,
      "step": 27120
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.107769012451172,
      "learning_rate": 9.380168488399455e-07,
      "loss": 1.7296,
      "step": 27130
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.3341493606567383,
      "learning_rate": 9.275688222281531e-07,
      "loss": 1.7211,
      "step": 27140
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.43850040435791,
      "learning_rate": 9.171787644196406e-07,
      "loss": 1.7059,
      "step": 27150
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.1595866680145264,
      "learning_rate": 9.068466876880844e-07,
      "loss": 1.6181,
      "step": 27160
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.0913283824920654,
      "learning_rate": 8.965726042386768e-07,
      "loss": 1.788,
      "step": 27170
    },
    {
      "epoch": 2.82,
      "grad_norm": 1.7689595222473145,
      "learning_rate": 8.863565262080931e-07,
      "loss": 1.7211,
      "step": 27180
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.0731399059295654,
      "learning_rate": 8.761984656644906e-07,
      "loss": 1.5853,
      "step": 27190
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.330206871032715,
      "learning_rate": 8.660984346074874e-07,
      "loss": 1.5627,
      "step": 27200
    },
    {
      "epoch": 2.82,
      "grad_norm": 1.8820228576660156,
      "learning_rate": 8.560564449681562e-07,
      "loss": 1.6948,
      "step": 27210
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.1362686157226562,
      "learning_rate": 8.460725086090138e-07,
      "loss": 1.5672,
      "step": 27220
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.099161386489868,
      "learning_rate": 8.361466373239757e-07,
      "loss": 1.6124,
      "step": 27230
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.2988548278808594,
      "learning_rate": 8.262788428383961e-07,
      "loss": 1.7372,
      "step": 27240
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.1230146884918213,
      "learning_rate": 8.164691368090005e-07,
      "loss": 1.6902,
      "step": 27250
    },
    {
      "epoch": 2.83,
      "grad_norm": 1.9154047966003418,
      "learning_rate": 8.067175308239083e-07,
      "loss": 1.7001,
      "step": 27260
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.377018451690674,
      "learning_rate": 7.970240364025827e-07,
      "loss": 1.5516,
      "step": 27270
    },
    {
      "epoch": 2.83,
      "grad_norm": 1.8089832067489624,
      "learning_rate": 7.873886649958806e-07,
      "loss": 1.658,
      "step": 27280
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.0388567447662354,
      "learning_rate": 7.778114279859694e-07,
      "loss": 1.699,
      "step": 27290
    },
    {
      "epoch": 2.83,
      "grad_norm": 1.9652605056762695,
      "learning_rate": 7.682923366863382e-07,
      "loss": 1.7199,
      "step": 27300
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.044793128967285,
      "learning_rate": 7.588314023418086e-07,
      "loss": 1.7268,
      "step": 27310
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.9020936489105225,
      "learning_rate": 7.494286361284964e-07,
      "loss": 1.5867,
      "step": 27320
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.5759761333465576,
      "learning_rate": 7.400840491537997e-07,
      "loss": 1.7047,
      "step": 27330
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.076688051223755,
      "learning_rate": 7.307976524563887e-07,
      "loss": 1.6776,
      "step": 27340
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.0543160438537598,
      "learning_rate": 7.215694570061993e-07,
      "loss": 1.6815,
      "step": 27350
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.979160189628601,
      "learning_rate": 7.123994737044115e-07,
      "loss": 1.5938,
      "step": 27360
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.0421767234802246,
      "learning_rate": 7.032877133834382e-07,
      "loss": 1.6024,
      "step": 27370
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.923526406288147,
      "learning_rate": 6.942341868069191e-07,
      "loss": 1.5723,
      "step": 27380
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.3166816234588623,
      "learning_rate": 6.85238904669705e-07,
      "loss": 1.6694,
      "step": 27390
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.9315338134765625,
      "learning_rate": 6.763018775978291e-07,
      "loss": 1.5028,
      "step": 27400
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.3560543060302734,
      "learning_rate": 6.674231161485245e-07,
      "loss": 1.5985,
      "step": 27410
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.311643123626709,
      "learning_rate": 6.586026308101845e-07,
      "loss": 1.6188,
      "step": 27420
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.1482176780700684,
      "learning_rate": 6.498404320023688e-07,
      "loss": 1.5682,
      "step": 27430
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.4981625080108643,
      "learning_rate": 6.41136530075781e-07,
      "loss": 1.6711,
      "step": 27440
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.7921127080917358,
      "learning_rate": 6.324909353122577e-07,
      "loss": 1.5829,
      "step": 27450
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.7913905382156372,
      "learning_rate": 6.239036579247626e-07,
      "loss": 1.6264,
      "step": 27460
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.1270298957824707,
      "learning_rate": 6.153747080573536e-07,
      "loss": 1.6414,
      "step": 27470
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.1893322467803955,
      "learning_rate": 6.069040957852156e-07,
      "loss": 1.621,
      "step": 27480
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.189190626144409,
      "learning_rate": 5.984918311145949e-07,
      "loss": 1.718,
      "step": 27490
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.605478048324585,
      "learning_rate": 5.901379239828197e-07,
      "loss": 1.655,
      "step": 27500
    },
    {
      "epoch": 2.85,
      "eval_loss": 1.8063637018203735,
      "eval_runtime": 366.3459,
      "eval_samples_per_second": 23.382,
      "eval_steps_per_second": 23.382,
      "step": 27500
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.1767570972442627,
      "learning_rate": 5.818423842582909e-07,
      "loss": 1.6491,
      "step": 27510
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.543738603591919,
      "learning_rate": 5.73605221740442e-07,
      "loss": 1.5746,
      "step": 27520
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.1616220474243164,
      "learning_rate": 5.654264461597613e-07,
      "loss": 1.722,
      "step": 27530
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.07964825630188,
      "learning_rate": 5.573060671777541e-07,
      "loss": 1.6023,
      "step": 27540
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.4189367294311523,
      "learning_rate": 5.492440943869581e-07,
      "loss": 1.7364,
      "step": 27550
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.1068403720855713,
      "learning_rate": 5.412405373108997e-07,
      "loss": 1.7478,
      "step": 27560
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.3537585735321045,
      "learning_rate": 5.33295405404105e-07,
      "loss": 1.7372,
      "step": 27570
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.715970277786255,
      "learning_rate": 5.254087080520831e-07,
      "loss": 1.7102,
      "step": 27580
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.680645227432251,
      "learning_rate": 5.175804545713203e-07,
      "loss": 1.6259,
      "step": 27590
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.2143924236297607,
      "learning_rate": 5.098106542092584e-07,
      "loss": 1.676,
      "step": 27600
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.2148077487945557,
      "learning_rate": 5.020993161442833e-07,
      "loss": 1.8398,
      "step": 27610
    },
    {
      "epoch": 2.87,
      "grad_norm": 1.902659296989441,
      "learning_rate": 4.944464494857359e-07,
      "loss": 1.6767,
      "step": 27620
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.0702548027038574,
      "learning_rate": 4.868520632738738e-07,
      "loss": 1.7037,
      "step": 27630
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.064460277557373,
      "learning_rate": 4.793161664798651e-07,
      "loss": 1.7388,
      "step": 27640
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.3814806938171387,
      "learning_rate": 4.718387680058056e-07,
      "loss": 1.7465,
      "step": 27650
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.2114782333374023,
      "learning_rate": 4.644198766846686e-07,
      "loss": 1.5323,
      "step": 27660
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.4678611755371094,
      "learning_rate": 4.5705950128032135e-07,
      "loss": 1.7265,
      "step": 27670
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.431126356124878,
      "learning_rate": 4.497576504875145e-07,
      "loss": 1.6246,
      "step": 27680
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.3551032543182373,
      "learning_rate": 4.425143329318482e-07,
      "loss": 1.6725,
      "step": 27690
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.198199987411499,
      "learning_rate": 4.353295571697835e-07,
      "loss": 1.7226,
      "step": 27700
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.2715306282043457,
      "learning_rate": 4.2820333168863693e-07,
      "loss": 1.7035,
      "step": 27710
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.3533949851989746,
      "learning_rate": 4.2113566490654677e-07,
      "loss": 1.7224,
      "step": 27720
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.3234505653381348,
      "learning_rate": 4.141265651724846e-07,
      "loss": 1.689,
      "step": 27730
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.1822383403778076,
      "learning_rate": 4.071760407662273e-07,
      "loss": 1.6089,
      "step": 27740
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.2528626918792725,
      "learning_rate": 4.0028409989837365e-07,
      "loss": 1.6739,
      "step": 27750
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.120609760284424,
      "learning_rate": 3.934507507103058e-07,
      "loss": 1.7644,
      "step": 27760
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.914779782295227,
      "learning_rate": 3.866760012741888e-07,
      "loss": 1.6424,
      "step": 27770
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.237823009490967,
      "learning_rate": 3.799598595929765e-07,
      "loss": 1.6075,
      "step": 27780
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.242994785308838,
      "learning_rate": 3.733023336003894e-07,
      "loss": 1.6722,
      "step": 27790
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.7252392768859863,
      "learning_rate": 3.667034311608919e-07,
      "loss": 1.5419,
      "step": 27800
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.5060675144195557,
      "learning_rate": 3.601631600697042e-07,
      "loss": 1.667,
      "step": 27810
    },
    {
      "epoch": 2.89,
      "grad_norm": 1.938001036643982,
      "learning_rate": 3.5368152805279055e-07,
      "loss": 1.6488,
      "step": 27820
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.1734368801116943,
      "learning_rate": 3.472585427668484e-07,
      "loss": 1.643,
      "step": 27830
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.0946736335754395,
      "learning_rate": 3.4089421179928084e-07,
      "loss": 1.7035,
      "step": 27840
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.5372607707977295,
      "learning_rate": 3.3458854266821824e-07,
      "loss": 1.6301,
      "step": 27850
    },
    {
      "epoch": 2.89,
      "grad_norm": 1.9523016214370728,
      "learning_rate": 3.2834154282248564e-07,
      "loss": 1.6716,
      "step": 27860
    },
    {
      "epoch": 2.89,
      "grad_norm": 1.9914041757583618,
      "learning_rate": 3.221532196416022e-07,
      "loss": 1.5386,
      "step": 27870
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.2376868724823,
      "learning_rate": 3.1602358043578697e-07,
      "loss": 1.6315,
      "step": 27880
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.0711374282836914,
      "learning_rate": 3.099526324459145e-07,
      "loss": 1.6097,
      "step": 27890
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.0891404151916504,
      "learning_rate": 3.0394038284354276e-07,
      "loss": 1.5235,
      "step": 27900
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.0767629146575928,
      "learning_rate": 2.979868387308848e-07,
      "loss": 1.7159,
      "step": 27910
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.4998576641082764,
      "learning_rate": 2.920920071408151e-07,
      "loss": 1.6325,
      "step": 27920
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.0643787384033203,
      "learning_rate": 2.862558950368299e-07,
      "loss": 1.5688,
      "step": 27930
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.335446357727051,
      "learning_rate": 2.8047850931307574e-07,
      "loss": 1.6824,
      "step": 27940
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.2746496200561523,
      "learning_rate": 2.7475985679433216e-07,
      "loss": 1.6968,
      "step": 27950
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.302790880203247,
      "learning_rate": 2.690999442359843e-07,
      "loss": 1.5946,
      "step": 27960
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.902816891670227,
      "learning_rate": 2.6349877832403945e-07,
      "loss": 1.5866,
      "step": 27970
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.470014810562134,
      "learning_rate": 2.5795636567509385e-07,
      "loss": 1.6453,
      "step": 27980
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.6176974773406982,
      "learning_rate": 2.5247271283635464e-07,
      "loss": 1.6505,
      "step": 27990
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.1988446712493896,
      "learning_rate": 2.470478262856013e-07,
      "loss": 1.7042,
      "step": 28000
    },
    {
      "epoch": 2.91,
      "eval_loss": 1.8063308000564575,
      "eval_runtime": 366.1323,
      "eval_samples_per_second": 23.396,
      "eval_steps_per_second": 23.396,
      "step": 28000
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.4067835807800293,
      "learning_rate": 2.416817124312132e-07,
      "loss": 1.5412,
      "step": 28010
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.3758270740509033,
      "learning_rate": 2.3637437761211968e-07,
      "loss": 1.6948,
      "step": 28020
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.103649616241455,
      "learning_rate": 2.3112582809783346e-07,
      "loss": 1.5765,
      "step": 28030
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.430511713027954,
      "learning_rate": 2.2593607008841167e-07,
      "loss": 1.6286,
      "step": 28040
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.424691677093506,
      "learning_rate": 2.20805109714467e-07,
      "loss": 1.6866,
      "step": 28050
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.1277034282684326,
      "learning_rate": 2.1573295303716212e-07,
      "loss": 1.5913,
      "step": 28060
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.394803524017334,
      "learning_rate": 2.1071960604817643e-07,
      "loss": 1.7025,
      "step": 28070
    },
    {
      "epoch": 2.91,
      "grad_norm": 1.9984523057937622,
      "learning_rate": 2.0576507466973926e-07,
      "loss": 1.5868,
      "step": 28080
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.198403835296631,
      "learning_rate": 2.0086936475459118e-07,
      "loss": 1.7384,
      "step": 28090
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.8285800218582153,
      "learning_rate": 1.960324820859838e-07,
      "loss": 1.5729,
      "step": 28100
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.3380532264709473,
      "learning_rate": 1.9125443237768548e-07,
      "loss": 1.7538,
      "step": 28110
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.804263114929199,
      "learning_rate": 1.8653522127395907e-07,
      "loss": 1.617,
      "step": 28120
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.9003303050994873,
      "learning_rate": 1.8187485434956187e-07,
      "loss": 1.742,
      "step": 28130
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.7715858221054077,
      "learning_rate": 1.772733371097457e-07,
      "loss": 1.5752,
      "step": 28140
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.5157196521759033,
      "learning_rate": 1.727306749902402e-07,
      "loss": 1.6101,
      "step": 28150
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.398585557937622,
      "learning_rate": 1.6824687335725287e-07,
      "loss": 1.67,
      "step": 28160
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.0565457344055176,
      "learning_rate": 1.6382193750744678e-07,
      "loss": 1.7625,
      "step": 28170
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.871058464050293,
      "learning_rate": 1.594558726679629e-07,
      "loss": 1.7875,
      "step": 28180
    },
    {
      "epoch": 2.93,
      "grad_norm": 2.139232635498047,
      "learning_rate": 1.5514868399639228e-07,
      "loss": 1.6814,
      "step": 28190
    },
    {
      "epoch": 2.93,
      "grad_norm": 2.3376753330230713,
      "learning_rate": 1.5090037658077594e-07,
      "loss": 1.6555,
      "step": 28200
    },
    {
      "epoch": 2.93,
      "grad_norm": 2.8270230293273926,
      "learning_rate": 1.4671095543960511e-07,
      "loss": 1.6389,
      "step": 28210
    },
    {
      "epoch": 2.93,
      "grad_norm": 2.0027694702148438,
      "learning_rate": 1.425804255217933e-07,
      "loss": 1.646,
      "step": 28220
    },
    {
      "epoch": 2.93,
      "grad_norm": 2.1631276607513428,
      "learning_rate": 1.3850879170670407e-07,
      "loss": 1.6574,
      "step": 28230
    },
    {
      "epoch": 2.93,
      "grad_norm": 2.374727725982666,
      "learning_rate": 1.344960588041233e-07,
      "loss": 1.6311,
      "step": 28240
    },
    {
      "epoch": 2.93,
      "grad_norm": 2.2447919845581055,
      "learning_rate": 1.305422315542426e-07,
      "loss": 1.7104,
      "step": 28250
    },
    {
      "epoch": 2.93,
      "grad_norm": 2.1859006881713867,
      "learning_rate": 1.266473146276981e-07,
      "loss": 1.6952,
      "step": 28260
    },
    {
      "epoch": 2.93,
      "grad_norm": 1.975358247756958,
      "learning_rate": 1.228113126255037e-07,
      "loss": 1.684,
      "step": 28270
    },
    {
      "epoch": 2.93,
      "grad_norm": 2.35534405708313,
      "learning_rate": 1.1903423007909586e-07,
      "loss": 1.7145,
      "step": 28280
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.0945727825164795,
      "learning_rate": 1.1531607145031098e-07,
      "loss": 1.797,
      "step": 28290
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.374049425125122,
      "learning_rate": 1.1165684113137453e-07,
      "loss": 1.6824,
      "step": 28300
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.2851498126983643,
      "learning_rate": 1.0805654344489546e-07,
      "loss": 1.7444,
      "step": 28310
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.1030609607696533,
      "learning_rate": 1.0451518264388282e-07,
      "loss": 1.6595,
      "step": 28320
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.0384929180145264,
      "learning_rate": 1.0103276291170138e-07,
      "loss": 1.6687,
      "step": 28330
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.0456600189208984,
      "learning_rate": 9.760928836211047e-08,
      "loss": 1.6575,
      "step": 28340
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.1384291648864746,
      "learning_rate": 9.424476303921403e-08,
      "loss": 1.7174,
      "step": 28350
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.1434381008148193,
      "learning_rate": 9.093919091751058e-08,
      "loss": 1.6642,
      "step": 28360
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.3212802410125732,
      "learning_rate": 8.769257590183766e-08,
      "loss": 1.5461,
      "step": 28370
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.127185106277466,
      "learning_rate": 8.4504921827383e-08,
      "loss": 1.6541,
      "step": 28380
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.27286434173584,
      "learning_rate": 8.137623245970116e-08,
      "loss": 1.6715,
      "step": 28390
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.1659529209136963,
      "learning_rate": 7.830651149468016e-08,
      "loss": 1.6585,
      "step": 28400
    },
    {
      "epoch": 2.95,
      "grad_norm": 1.889021873474121,
      "learning_rate": 7.529576255854709e-08,
      "loss": 1.7409,
      "step": 28410
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.624755620956421,
      "learning_rate": 7.234398920788477e-08,
      "loss": 1.7275,
      "step": 28420
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.222306489944458,
      "learning_rate": 6.945119492958174e-08,
      "loss": 1.6655,
      "step": 28430
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.0554325580596924,
      "learning_rate": 6.661738314087673e-08,
      "loss": 1.6606,
      "step": 28440
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.5510776042938232,
      "learning_rate": 6.38425571893253e-08,
      "loss": 1.6654,
      "step": 28450
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.037814140319824,
      "learning_rate": 6.112672035279987e-08,
      "loss": 1.6387,
      "step": 28460
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.222862958908081,
      "learning_rate": 5.846987583949526e-08,
      "loss": 1.5657,
      "step": 28470
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.232246160507202,
      "learning_rate": 5.5872026787912033e-08,
      "loss": 1.5819,
      "step": 28480
    },
    {
      "epoch": 2.96,
      "grad_norm": 3.2337634563446045,
      "learning_rate": 5.333317626687318e-08,
      "loss": 1.6536,
      "step": 28490
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.3074729442596436,
      "learning_rate": 5.085332727549075e-08,
      "loss": 1.5426,
      "step": 28500
    },
    {
      "epoch": 2.96,
      "eval_loss": 1.8063405752182007,
      "eval_runtime": 366.2442,
      "eval_samples_per_second": 23.389,
      "eval_steps_per_second": 23.389,
      "step": 28500
    }
  ],
  "logging_steps": 10,
  "max_steps": 28905,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 7.524131927237591e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
